[
  {
    "content": " AI 发展日新月异, 以下项目是目前 (2024-11-23) 搜集整理的非常棒的项目/应用/工具/资源… 后面新添加, 都会标注日期.\n内容主要分为 项目的官方网站, 项目的 GitHub 主页, 项目的 Hugging Face Space (可在线试用), AIGC 相关网站, 相关文档资料. 它们之间可能会有重叠的项目, 但非常少, 我做了去重, 确保唯一性.\n项目的官方网站 项目的 GitHub 主页 Hugging Face Space AIGC 相关网站 相关文档资料 ",
    "description": "",
    "tags": null,
    "title": "ACGC 项目, 应用, 工具, 资源集",
    "uri": "/01_aigc_object/"
  },
  {
    "content": "ComfyUI 教程资源 ",
    "description": "",
    "tags": null,
    "title": "ComfyUI 教程",
    "uri": "/02_comfyui/"
  },
  {
    "content": "搜索问答 Kimi\nchatgpt\n秘塔\nperplexity\nMeta AI\n腾讯元宝\n豆包 - 抖音旗下 AI 智能助手\nGoogle AI Studio\nClaude\n知乎直答\n360搜\nPoe\nHuggingChat\n视频, 语音, 绘图等综合 智谱清言\n即梦AI - 一站式AI创作平台\n可灵 AI - 新一代 AI 创意生产力平台\n海螺 AI\n跃问\nLuma Dream Machine | AI Video Generator\nKREA AI - AIGC集合-风格-图有免费\nHome - Leonardo.Ai\nAI Test Kitchen\nLimeWire\nLe Chat - Mistral AI\nWHEE - 高品质的AI素材生成器\n视频 kaze.ai - AI-powered Free Online Removing Watermark and Logos Tool 2024-11-27\nVidu，让想象发生\nHailuo AI Video Generator - Reimagine Video Creation\nRunway\n讲故事的方式发生了转变LTX工作室 — Storytelling Transformed | LTX Studio\nNoisee AI 音乐生成MV\nPika\nGenmo. Create videos and images with AI.\nHome | PixVerse\nViggle AI\n万德动力 — Wonder Dynamics\nHeyGen - AI Spokesperson Video Creator\nAiuni\nDomoAI: video to video, video to animation and more\nFlair\nWarpvideo AI: Change Video Style with AI\nHedra 数字人\nAI 擁抱 - 免費線上 AI 擁抱影片生成器\nMOKI - 我用AI做短片\nMeshcapade | 编辑人物动作\nBoomCut - 爆剪辑 - 小影科技旗下 AI 内容创意产品与服务平台\n绘画设计 Create stunning visuals in seconds with AI.\n超能画布首页\nAdobe Firefly\nDesign - Playground\nSkybox AI 360°全景\nMagic Studio：利用 AI 制作精美图像\nmidjourney\nRemove Background from Image for Free – remove.bg\nCraiyon, formerly DALL-E mini\nCreate - Artbreeder\nNightCafe Creator\nProjects - Recraft\nBlendbox.ai 多图组合\nIdeogram 画布\nLogo-creator.io – Generate a logo\n在线抠图软件_图片去除背景 | remove.bg – remove.bg\n触手AI\n3D Meshy - Free 3D Models Generated from Images and Text\nImmersity AI | Convert Image and Video to 3D\nTripo AI - 用文字或图片免费生成3D模型\n语音, 音乐 Suno\n海绵音乐\nFree Text to Speech \u0026 AI Voice Generator | ElevenLabs\nUdio AI Music Generator - Make Original Tracks in Seconds\nStable Audio - Generate\n在线免费文本转语音 - TTS-Online | 多种声音与二次元语音\nSoundboard - TUNA - Download Unlimited Free Meme Sounds\n节奏生成器-Beat Blender 音乐\n网易天音 - 一站式AI音乐创作工具 - 官网\n提示词 promptoMANIA:绘画提示生成器\nLexica\nPromptHero - 提示词大全\n代码 MarsCode - AI IDE\nCursor\nbolt.new\nScriptEcho | AI生成生产级代码 |\n其他 NotebookLM | Note Taking \u0026 Research Assistant Powered by AI\n扣子 - AI 智能体开发平台\nFigma\nIlluminate | Learn Your Way\nChat Nio\nLlamaOCR.com – Document to markdown\nNeo AI engineer\nExcalidraw\n等待中的项目 Baking Gaussian Splatting into Diffusion Denoiser for Fast and Scalable Single-stage Image-to-3D Generation 2024-11-27\nFugatto, World’s Most Flexible Sound Machine, Debuts | NVIDIA Blog 2024-11-27\nFashion-VDM: Video Diffusion Model for Virtual Try-On\nInverse Painting: Reconstructing The Painting Process\n首页 |剧集主管 — Home | Showrunner\n悠船\nVideo Ocean视频大模型 - 人人皆导演\nPersonaTalk: Bring Attention to Your Persona in Visual Dubbing\nMarDini: Masked Auto-Regressive Diffusion for Video Generation at Scale – Meta AI Research\n炉米Lumi\nloopyavatar.github.io/?ref=aihub.cn\nGoogle Vids：在线视频创建和编辑器 | Google Vids谷歌工作区 — Google Vids: Online Video Creator and Editor | Google Workspace\nSkyReels\nURAvatar: Universal Relightable Gaussian Codec Avatars\nMikuDance\nAdd-it\nDanceFusion: A Spatio-Temporal Skeleton Diffusion Transformer for Audio-Driven Dance Motion Reconstruction.\nAnimateAnything\nMIMO\nInstructAvatar\n模型, 资源, 工作流 Discovery | OpenArt\nShakker - Generative AI design tool with diverse models\n首页 · 魔搭社区\nComfy Workflows\nOpenModelDB\nFREE online image generator and model hosting site! | Tensor.Art\nCivitai: The Home of Open-Source Generative AI\nCodeWithGPU | 能复现才是好算法\nLiblibAI-哩布哩布AI - 中国领先的AI创作平台\nComfyUI工作流 - 在线运行，速度快，不报错\nFREE online image generator and model hosting site! | Tensor.Art\nCephalon Cloud 端脑云 - AIGC 应用平台\n",
    "description": "",
    "tags": null,
    "title": "项目的官方网站",
    "uri": "/01_aigc_object/01_object/"
  },
  {
    "content": "视频 k4yt3x/video2x: A machine learning-based lossless video super resolution framework. Est. Hack the Valley II, 2018. 2024-11-27\nfacefusion/facefusion: Industry leading face manipulation platform 2024-11-27\nyangchris11/samurai: Official repository of “SAMURAI: Adapting Segment Anything Model for Zero-Shot Visual Tracking with Motion-Aware Memory”\nalibaba/Tora: The official repository for paper “Tora: Trajectory-oriented Diffusion Transformer for Video Generation”\naigc-apps/CogVideoX-Fun: 📹 A more flexible CogVideoX that can generate videos at any resolution and creates videos from images.\naigc-apps/EasyAnimate: 📺 An End-to-End Solution for High-Resolution and Long Video Generation Based on Transformer Diffusion\nGitHub - HVision-NKU/StoryDiffusion: Create Magic Story!\nhpcaitech/Open-Sora: Open-Sora: Democratizing Efficient Video Production for All\nVision-CAIR/MiniGPT4-video\nhkchengrex/Cutie: [CVPR 2024 Highlight] Putting the Object Back Into Video Object Segmentation\nPicsart-AI-Research/StreamingT2V: StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text\naigc-apps/EasyAnimate: 📺 An End-to-End Solution for High-Resolution and Long Video Generation Based on Transformer Diffusion\nTencent/MimicMotion: High-Quality Human Motion Video Generation with Confidence-aware Pose Guidance\njianchang512/pyvideotrans: Translate the video from one language to another and add dubbing. 将视频从一种语言翻译为另一种语言，并支持api调用\nHillobar/Rope: GUI-focused roop\nGitHub - sczhou/CodeFormer: [NeurIPS 2022] Towards Robust Blind Face Restoration with Codebook Lookup Transformer\nHuanshere/VideoLingo: Netflix-level subtitle cutting, translation, alignment, and even dubbing - one-click fully automated AI video subtitle team | Netflix级字幕切割、翻译、对齐、甚至加上配音，一键全自动视频搬运AI字幕组\njy0205/Pyramid-Flow: Code of Pyramidal Flow Matching for Efficient Video Generative Modeling\nVision-CAIR/LongVU\nDoubiiu/ToonCrafter: [SIGGRAPH Asia 2024, Journal Track] ToonCrafter: Generative Cartoon Interpolation\nVectorSpaceLab/Video-XL: 🔥🔥First-ever hour scale video understanding models\nanliyuan/Ultralight-Digital-Human: 一个超轻量级、可以在移动端实时运行的数字人模型\nantgroup/echomimic_v2: EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation\nZejun-Yang/AniPortrait: AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animation\nfudan-generative-vision/hallo2: Hallo2: Long-Duration and High-Resolution Audio-driven Portrait Image Animation\nantgroup/echomimic: EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditioning\nLordLiang/DrawingSpinUp: (SIGGRAPH Asia 2024) This is the official PyTorch implementation of SIGGRAPH Asia 2024 paper: DrawingSpinUp: 3D Animation from Single Character Drawings\nHelloVision/HelloMeme: The official HelloMeme GitHub site\nKmcode1/SG-I2V: This is the official implementation of SG-I2V: Self-Guided Trajectory Control in Image-to-Video Generation.\nfacebookresearch/sapiens: High-resolution models for human tasks.\nAlonzoLeeeooo/StableV2V: The official implementation of the paper titled “StableV2V: Stablizing Shape Consistency in Video-to-Video Editing”.\ngenmoai/mochi: The best OSS video generation models\nTHUDM/CogVideo: text and image to video generation: CogVideoX (2024) and CogVideo (ICLR 2023)\nCyberAgentAILab/TANGO: Official implementation of the paper “TANGO: Co-Speech Gesture Video Reenactment with Hierarchical Audio-Motion Embedding and Diffusion Interpolation”\nIDEA-Research/MotionCLR: [Arxiv 2024] MotionCLR: Motion Generation and Training-free Editing via Understanding Attention Mechanisms\nJi4chenLi/t2v-turbo: Code repository for T2V-Turbo and T2V-Turbo-v2\nLightricks/LTX-Video: Official repository for LTX-Video\nComfyUI EvilBT/ComfyUI_SLK_joy_caption_two: ComfyUI Node 2024-11-27\nhuchenlei/ComfyUI-layerdiffuse: Layer Diffuse custom nodes 2024-11-27\nkijai/ComfyUI-IC-Light: Using IC-LIght models in ComfyUI 2024-11-27\nkijai/ComfyUI-CogVideoXWrapper\nLightricks/ComfyUI-LTXVideo: LTX-Video Support for ComfyUI\nsmthemex/ComfyUI_EchoMimic: You can using EchoMimic in ComfyUI\nAIFSH/ACE-ComfyUI\nlogtd/ComfyUI-MochiEdit: ComfyUI nodes to edit videos using Genmo Mochi\nkijai/ComfyUI-SUPIR: SUPIR upscaling wrapper for ComfyUI\nHelloVision/ComfyUI_HelloMeme: Official comfyui repository of Hellomeme\nalimama-creative/SDXL_EcomID_ComfyUI\nAIGODLIKE/AIGODLIKE-ComfyUI-Studio: Improve the interactive experience of using ComfyUI, such as making the loading of ComfyUI models more intuitive and making it easier to create model thumbnails\nssitu/ComfyUI_UltimateSDUpscale: ComfyUI nodes for the Ultimate Stable Diffusion Upscale script by Coyote-A.\nGourieff/comfyui-reactor-node: Fast and Simple Face Swap Extension Node for ComfyUI\nlldacing/ComfyUI_BiRefNet_ll\nAIGODLIKE/ComfyUI-BlenderAI-node: Used for AI model generation, next-generation Blender rendering engine, texture enhancement\u0026generation (based on ComfyUI)\nsmthemex/ComfyUI_Hallo2: ComfyUI_Hallo2: Long-Duration and High-Resolution Audio-driven Portrait Image Animation\nkijai/ComfyUI-Florence2: Inference Microsoft Florence2 VLM\nCY-CHENYUE/ComfyUI-Molmo: Generate detailed image descriptions and analysis using Molmo models in ComfyUI.\nyolain/ComfyUI-Easy-Use: In order to make it easier to use the ComfyUI, I have made some optimizations and integrations to some commonly used nodes.\nsipherxyz/comfyui-art-venture\nGiusTex/ComfyUI-DiffusersImageOutpaint: Diffusers Image Outpaint for ComfyUI\nXLabs-AI/x-flux-comfyui\nT8star1984/Comfyui-Aix-NodeMap: Comfyui’s latest node organization and annotation, continuously updated, and supported by the Aix team/comfyui最新节点整理及注释，持续更新，AIX团队\nT8star1984/Comfyui-Aix-NodeMap: Comfyui’s latest node organization and annotation, continuously updated, and supported by the Aix team/comfyui最新节点整理及注释，持续更新，AIX团队\nlogtd/ComfyUI-Fluxtapoz: Nodes for image juxtaposition for Flux in ComfyUI\nWASasquatch/was-node-suite-comfyui: An extensive node suite for ComfyUI with over 210 new nodes\ncubiq/ComfyUI_IPAdapter_plus\ncubiq/ComfyUI_InstantID\ncubiq/ComfyUI_InstantID\nZHO-ZHO-ZHO/ComfyUI-InstantID: Unofficial implementation of InstantID for ComfyUI\nkijai/ComfyUI-MochiWrapper\nkijai/ComfyUI-LivePortraitKJ: ComfyUI nodes for LivePortrait\nPowerHouseMan/ComfyUI-AdvancedLivePortrait\nTemryL/ComfyUI-IDM-VTON: ComfyUI adaptation of IDM-VTON for virtual try-on.\ncity96/ComfyUI-GGUF: GGUF Quantization support for native ComfyUI models\nFizzleDorf/ComfyUI_FizzNodes: Custom Nodes for Comfyui\nbalazik/ComfyUI-PuLID-Flux: PuLID-Flux ComfyUI implementation\nkijai/ComfyUI-PyramidFlowWrapper\nstavsap/comfyui-ollama\nltdrdata/ComfyUI-Manager: ComfyUI-Manager is an extension designed to enhance the usability of ComfyUI. It offers management functions to install, remove, disable, and enable various custom nodes of ComfyUI. Furthermore, this extension provides a hub feature and convenience functions to access a wide range of information within ComfyUI.\nerosDiffusion/ComfyUI-enricos-nodes: Compositor Node experiments\nStartHua/Comfyui_CXH_joy_caption: Recommended based on comfyui node pictures:Joy_caption + MiniCPMv2_6-prompt-generator + florence2\nZHO-ZHO-ZHO/ComfyUI-YoloWorld-EfficientSAM: Unofficial implementation of YOLO-World + EfficientSAM for ComfyUI\nlogtd/ComfyUI-Fluxtapoz: Nodes for image juxtaposition for Flux in ComfyUI\nGreenLandisaLie/AuraSR-ComfyUI: ComfyUI implementation of AuraSR\nJonseed/ComfyUI-Detail-Daemon: A port of muerrilla’s sd-webui-Detail-Daemon as a node for ComfyUI, to adjust sigmas that control detail.\ntaabata/ComfyCanvas: Canvas to use with ComfyUI\njtydhr88/ComfyUI-Hunyuan3D-1-wrapper: ComfyUI Hunyuan3D-1-wrapper is a custom node that allows you to run Tencent/Hunyuan3D-1 in ComfyUI as a wrapper.\nsmthemex/ComfyUI_Sapiens: You can call Using Sapiens to get seg，normal，pose，depth，mask\n1038lab/ComfyUI-RMBG: A ComfyUI node for removing image backgrounds using RMBG-2.0.\nTTPlanetPig/Comfyui_Object_Migration: This is a study aim to transfer the single concept by using DIT model self-attention capablity\nDoctorDiffusion/ComfyUI-BEN: Background Erase Network - Remove backgrounds from images within ComfyUI.\nmarduk191/ComfyUI-Fluxpromptenhancer: A Prompt Enhancer for flux.1 in ComfyUI\nLightricks/ComfyUI-LTXVideo: LTX-Video Support for ComfyUI\nWebUI open-webui/open-webui: User-friendly AI Interface (Supports Ollama, OpenAI API, …)\ncontinue-revolution/sd-webui-segment-anything: Segment Anything for Stable Diffusion WebUI\nlllyasviel/stable-diffusion-webui-forge\naigc-apps/sd-webui-EasyPhoto: 📷 EasyPhoto | Your Smart AI Photo Generator.\nLLM THUDM/GLM-4-Voice: GLM-4-Voice | 端到端中英语音对话模型\noobabooga/text-generation-webui: A Gradio web UI for Large Language Models.\njanhq/jan: Jan is an open source alternative to ChatGPT that runs 100% offline on your computer. Multiple engine support (llama.cpp, TensorRT-LLM)\nollama/ollama: Get up and running with Llama 3.2, Mistral, Gemma 2, and other large language models.\nbinary-husky/gpt_academic: 为GPT/GLM等LLM大语言模型提供实用化交互接口，特别优化论文阅读/润色/写作体验，模块化设计，支持自定义快捷按钮\u0026函数插件，支持Python和C++等项目剖析\u0026自译解功能，PDF/LaTex论文翻译\u0026总结功能，支持并行问询多种LLM模型，支持chatglm3等本地模型。接入通义千问, deepseekcoder, 讯飞星火, 文心一言, llama2, rwkv, claude2, moss等。\nSillyTavern/SillyTavern: LLM Frontend for Power Users.\nmendableai/firecrawl: 🔥 Turn entire websites into LLM-ready markdown or structured data. Scrape, crawl and extract with a single API.\nInternLM/InternLM: Official release of InternLM2.5 base and chat models. 1M context support\n训练脚本 kohya-ss/sd-scripts\ncocktailpeanut/fluxgym: Dead simple FLUX LoRA training UI with LOW VRAM support\nkijai/ComfyUI-FluxTrainer\nReleases · bmaltais/kohya_ss\nAkegarasu/lora-scripts: LoRA \u0026 Dreambooth training scripts \u0026 GUI use kohya-ss’s trainer, for diffusion model.\nNerogar/OneTrainer: OneTrainer is a one-stop solution for all your stable diffusion training needs.\n图像设计 erwold/qwen2vl-flux 2024-11-27\nYuanshi9815/OminiControl: A minimal and universal controller for FLUX.1. 2024-11-27\nlllyasviel/sd-forge-layerdiffuse: [WIP] Layer Diffusion for WebUI (via Forge) 2024-11-27\nali-vilab/ACE: All-round Creator and Editor\nmit-han-lab/hart: HART: Efficient Visual Generation with Hybrid Autoregressive Transformer\nZhengPeng7/BiRefNet: [CAAI AIR'24] Bilateral Reference for High-Resolution Dichotomous Image Segmentation\nYangLing0818/IterComp: IterComp: Iterative Composition-Aware Feedback Learning from Model Gallery for Text-to-Image Generation\nxinsir6/ControlNetPlus: ControlNet++: All-in-one ControlNet for image generations and editing!\nKwai-Kolors/Kolors: Kolors Team\nXiaojiu-z/Stable-Hair: Stable-Hair: Real-World Hair Transfer via Diffusion Model\nyisol/IDM-VTON: [ECCV2024] IDM-VTON : Improving Diffusion Models for Authentic Virtual Try-on in the Wild\nbcmi/libcom: Image composition toolbox: everything you want to know about image composition or object insertion\nPixArt-alpha/PixArt-alpha: PixArt-α: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis\nblack-forest-labs/flux: Official inference repo for FLUX.1 models\nStability-AI/sd3.5\nlllyasviel/Omost: Your image is almost there!\ngligen/GLIGEN: Open-Set Grounded Text-to-Image Generation\nTencent/HunyuanDiT: Hunyuan-DiT : A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding\nlllyasviel/IC-Light: More relighting!\ntencent-ailab/IP-Adapter: The image prompt adapter is designed to enable a pretrained text-to-image diffusion model to generate images with image prompt.\npiddnad/DDColor: [ICCV 2023] Official implementation of “DDColor: Towards Photo-Realistic Image Colorization via Dual Decoders”\ncumulo-autumn/StreamDiffusion: StreamDiffusion: A Pipeline-Level Solution for Real-Time Interactive Generation\nToTheBeginning/PuLID: [NeurIPS 2024] Official code for PuLID: Pure and Lightning ID Customization via Contrastive Alignment\nKDE/krita: Krita is a free and open source cross-platform application that offers an end-to-end solution for creating digital art files from scratch built on the KDE and Qt frameworks.\nAcly/krita-ai-diffusion: Streamlined interface for generating images with AI in Krita. Inpaint and outpaint with optional text prompt, no tweaking required.\ninstantX-research/InstantID: InstantID: Zero-shot Identity-Preserving Generation in Seconds 🔥\njbilcke-hf/FacePoke: Select a portrait, click to move the head around (please use your own space / GPU!)\ncatcathh/UltraPixel: Implementation of UltraPixel: Advancing Ultra-High-Resolution Image Synthesis to New Peaks\nZeyi-Lin/HivisionIDPhotos: ⚡️HivisionIDPhotos: a lightweight and efficient AI ID photos tools. 一个轻量级的AI证件照制作算法。\nVectorSpaceLab/OmniGen: OmniGen: Unified Image Generation. https://arxiv.org/pdf/2409.11340\nshallowdream204/DreamClear: [NeurIPS 2024🔥] DreamClear: High-Capacity Real-World Image Restoration with Privacy-Safe Dataset Curation\nNVlabs/consistory\ninstantX-research/Regional-Prompting-FLUX: Training-free Regional Prompting for Diffusion Transformers 🔥\nali-vilab/In-Context-LoRA: Official repository of In-Context LoRA for Diffusion Transformers\nmit-han-lab/nunchaku: SVDQuant: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion Models\nChenyangSi/FreeU: FreeU: Free Lunch in Diffusion U-Net (CVPR2024 Oral)\nmagic-quill/MagicQuill: Official Implementations for Paper - MagicQuill: An Intelligent Interactive Image Editing System\nNutlope/logocreator: A free + OSS logo generator powered by Flux on Together AI\nNVlabs/Sana: SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformer\nJackAILab/ConsistentID: Customized ID Consistent for human\nDepthAnything/Depth-Anything-V2: [NeurIPS 2024] Depth Anything V2. A More Capable Foundation Model for Monocular Depth Estimation\ntryonlabs/FLUX.1-dev-LoRA-Outfit-Generator: FLUX.1-dev LoRA Outfit Generator can create an outfit by detailing the color, pattern, fit, style, material, and type.\n语音, 音乐 netease-youdao/EmotiVoice: EmotiVoice 😊: a Multi-Voice and Prompt-Controlled TTS Engine\nhaidog-yaqub/EzAudio: High-quality Text-to-Audio Generation with Efficient Diffusion Transformer\n2noise/ChatTTS: A generative speech model for daily dialogue.\nBytedanceSpeech/seed-tts-eval\nRVC-Project/Retrieval-based-Voice-Conversion-WebUI: Easily train a good VC model with voice data \u003c= 10 mins!\nGitHub - yxlllc/DDSP-SVC: Real-time end-to-end singing voice conversion system based on DDSP (Differentiable Digital Signal Processing)\nvoicepaw/so-vits-svc-fork: so-vits-svc fork with realtime support, improved interface and more features.\nGitHub - RVC-Boss/GPT-SoVITS: 1 min voice data can also be used to train a good TTS model! (few shot voice cloning)\nSWivid/F5-TTS: Official code for “F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching”\nmisya11p/amt-apc: AMT-APC: AMT-APC: Automatic Piano Cover by Fine-Tuning an Automatic Music Transcription Model\nWEIFENG2333/AsrTools: ✨ AsrTools: 智能语音转文字工具 | 高效批处理 | 用户友好界面 | 无需 GPU |支持 SRT/TXT 输出 | 让您的音频瞬间变成精确文字！\nopen-mmlab/Amphion: Amphion (/æmˈfaɪən/) is a toolkit for Audio, Music, and Speech Generation. Its purpose is to support reproducible research and help junior researchers and engineers get started in the field of audio, music, and speech generation research and development.\nfishaudio/fish-speech: Brand new TTS solution\n3D VAST-AI-Research/TripoSR 2024-11-27\nmicrosoft/MoGe: MoGe: Unlocking Accurate Monocular Geometry Estimation for Open-Domain Images with Optimal Training Supervision\nHengyiWang/spann3r: 3D Reconstruction with Spatial Memory\nTencent/Hunyuan3D-1\nwenqsun/DimensionX: DimensionX: Create Any 3D and 4D Scenes from a Single Image with Controllable Video Diffusion\n文本处理 zyddnys/manga-image-translator: Translate manga/image 一键翻译各类图片内文字 https://cotrans.touhou.ai/\nchidiwilliams/buzz: Buzz transcribes and translates audio offline on your personal computer. Powered by OpenAI’s Whisper.\nAgentEra/Agently-Daily-News-Collector: An open-source LLM based automatically daily news collecting workflow showcase powered by Agently AI application development framework.\nLC044/WeChatMsg: 提取微信聊天记录，将其导出成HTML、Word、Excel文档永久保存，对聊天记录进行分析生成年度聊天报告，用聊天数据训练专属于个人的AI聊天助手\ngabrielchua/open-notebooklm: Convert any PDF into a podcast episode!\ngetomni-ai/zerox: Zero shot pdf OCR with gpt-4o-mini\nopendatalab/PDF-Extract-Kit: A Comprehensive Toolkit for High-Quality PDF Content Extraction\nNutlope/llama-ocr: Document to Markdown OCR library with Llama 3.2 vision\nopendatalab/MinerU: A high-quality tool for convert PDF to Markdown and JSON.一站式开源高质量数据提取工具，将PDF转换成Markdown和JSON格式。\n其他 Ucas-HaoranWei/GOT-OCR2.0: Official code implementation of General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model\ndeepseek-ai/DeepSeek-VL: DeepSeek-VL: Towards Real-World Vision-Language Understanding\ndynobo/normcap: OCR powered screen-capture tool to capture information instead of images\nmodelscope/DiffSynth-Studio: Enjoy the magic of Diffusion models!\nabi/screenshot-to-code: Drop in a screenshot and convert it to clean code (HTML/Tailwind/React/Vue)\nstackblitz/bolt.new: Prompt, run, edit, and deploy full-stack web applications\nlean-dojo/LeanCopilot: LLMs as Copilots for Theorem Proving in Lean\ngeekan/MetaGPT: 🌟 The Multi-Agent Framework: First AI Software Company, Towards Natural Language Programming\nprinceton-nlp/SWE-agent: [NeurIPS 2024] SWE-agent takes a GitHub issue and tries to automatically fix it, using GPT-4, or your LM of choice. It can also be employed for offensive cybersecurity or competitive coding challenges.\nOpenCodeInterpreter/OpenCodeInterpreter: OpenCodeInterpreter is a suite of open-source code generation systems aimed at bridging the gap between large language models and sophisticated proprietary systems like the GPT-4 Code Interpreter. It significantly enhances code generation capabilities by integrating execution and iterative refinement functionalities.\nIkaros-521/AI-Vtuber: AI Vtuber是一个由 【ChatterBot/ChatGPT/claude/langchain/chatglm/text-gen-webui/闻达/千问/kimi/ollama】 驱动的虚拟主播【Live2D/UE/xuniren】，可以在 【Bilibili/抖音/快手/微信视频号/拼多多/斗鱼/YouTube/twitch/TikTok】 直播中与观众实时互动 或 直接在本地进行聊天。它使用TTS技术【edge-tts/VITS/elevenlabs/bark/bert-vits2/睿声】生成回答并可以选择【so-vits-svc/DDSP-SVC】变声；指令协同SD画图。\nGitHub - 3b1b/manim: Animation engine for explanatory math videos\nGitHub - ManimCommunity/manim: A community-maintained Python framework for creating mathematical animations.\nGitHub - KindXiaoming/pykan: Kolmogorov Arnold Networks\nGitHub - PeterH0323/Streamer-Sales: Streamer-Sales 销冠 —— 卖货主播大模型，一个能够根据给定的商品特点对商品进行解说并激发用户的购买意愿的卖货主播模型\nFujiwaraChoki/MoneyPrinter: Automate Creation of YouTube Shorts using MoviePy.\nprinceton-nlp/SWE-agent: SWE-agent takes a GitHub issue and tries to automatically fix it, using GPT-4. It solves 12.29% of bugs in the SWE-bench evaluation set (comparable to Devin) and take just 1.5 minutes to run (7x faster than Devin).\nharry0703/MoneyPrinterTurbo: 利用AI大模型，一键生成高清短视频 Generate short videos with one click using AI LLM.\nidootop/mi-gpt: 🏠 将小爱音箱接入 ChatGPT 和豆包，改造成你的专属语音助手。\nwan-h/awesome-digital-human-live2d: Awesome Digital Human\nopenai/swarm: Educational framework exploring ergonomic, lightweight multi-agent orchestration. Managed by OpenAI Solution team.\nmeta-llama/llama-recipes: Scripts for fine-tuning Meta Llama with composable FSDP \u0026 PEFT methods to cover single/multi-node GPUs. Supports default \u0026 custom datasets for applications such as summarization and Q\u0026A. Supporting a number of candid inference solutions such as HF TGI, VLLM for local or cloud deployment. Demo apps to showcase Meta Llama for WhatsApp \u0026 Messenger.\nHqWu-HITCS/Awesome-Chinese-LLM: 整理开源的中文大语言模型，以规模较小、可私有化部署、训练成本较低的模型为主，包括底座模型，垂直领域微调及应用，数据集与教程等。\nHannibal046/Awesome-LLM: Awesome-LLM: a curated list of Large Language Model\nexcalidraw/excalidraw: Virtual whiteboard for sketching hand-drawn like diagrams\nmeltylabs/melty: Chat first code editor. To download the packaged app:\ngpt-omni/mini-omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex Capabilities。\n",
    "description": "",
    "tags": null,
    "title": "项目的 GitHub 主页",
    "uri": "/01_aigc_object/02_github/"
  },
  {
    "content": "项目的 Hugging Face Space OminiControl - a Hugging Face Space by Yuanshi 2024-11-27\nACE-Chat - a Hugging Face Space by scepter-studio\nMoGe - a Hugging Face Space by Ruicheng\nEzAudio - a Hugging Face Space by OpenSound\nNaturalSpeech3 FACodec - a Hugging Face Space by amphion\nIDM VTON - a Hugging Face Space by yisol\nAnimateDiff-Lightning - a Hugging Face Space by ByteDance\nOmost - a Hugging Face Space by lllyasviel\nCLIP Interrogator - a Hugging Face Space by pharmapsychotic\nPyramid Flow - a Hugging Face Space by Pyramid-Flow\nJoy Caption Alpha Two - a Hugging Face Space by fancyfeast\nIC Light V2 - a Hugging Face Space by lllyasviel\nMaskGCT TTS Demo - a Hugging Face Space by amphion\nOmniGen - a Hugging Face Space by Shitao\nMotionCLR - a Hugging Face Space by EvanTHU\nSeedEdit-APP-V1.0 - a Hugging Face Space by ByteDance\nFramer - a Hugging Face Space by wwen1997\nBRIA RMBG 2.0 - a Hugging Face Space by briaai\nMinerU - a Hugging Face Space by opendatalab\nQwen Turbo 1M Demo - a Hugging Face Space by Qwen\nDimensionX - a Hugging Face Space by fffiloni\nPhotoMaker V2 - a Hugging Face Space by TencentARC\nOOTDiffusion - a Hugging Face Space by levihsu\nmoondream2 - a Hugging Face Space by vikhyatk\n",
    "description": "",
    "tags": null,
    "title": "Hugging Face Space",
    "uri": "/01_aigc_object/03_hugging/"
  },
  {
    "content": "AIGC 相关网站 Discover and download free videos - Pixabay\nDanbooru: Anime Image Board\nDiscover the Best GPTs\nAI工具集 | 700+ AI工具集合官网，国内外AI工具集导航大全\nSupertools | Best AI Tools Guide\nAIGC导航 | 1500+全品类AIGC创作工具_探索更多可能！\n插画交流网站[pixiv]\nArtStation - Explore\nAIbase - 智能匹配最适合您的AI产品和网站\nNewsfeed - Sketchfab\nAI Model \u0026 API Providers Analysis | Artificial Analysis\nxAI\nGGAC数字艺术平台\nWeird Wonderful AI Art | ART of the future - now!\n相关文档资料 使用 diffusers 训练你自己的 ControlNet 🧨\nStable Diffusion QR Code 101\nE-Hentai/태그 - 나무위키\n魔咒百科词典\nSo-VITS-SVC 4.1 整合包完全指南\nStable Diffusion 3.5 Prompt Guide — Stability AI\n使用 ChatGPT 进行写作的学生指南 |开放人工智能 — A Student’s Guide to Writing with ChatGPT | OpenAI\nrichards199999/Thinking-Claude: Let your Claude able to think\nhesamsheikh/ml-retreat: Machine Learning Journal for Intermediate to Advanced Topics.\nMidjourney Documentation and User Guide\n归档(可以不用看) Resources for GAN Artists\nDisco Diffusion Portrait Study (by @enviraldesign) - Google 文档\nalibaba/animate-anything: Fine-Grained Open Domain Image Animation with Motion Guidance\nGitHub - prophesier/diff-svc: Singing Voice Conversion via diffusion model\nTencentARC/GFPGAN: GFPGAN aims at developing Practical Algorithms for Real-world Face Restoration.\nguide to installing disco v5+ locally on windows\nclip_interrogator.ipynb - Colaboratory\nA Traveler’s Guide to the Latent Space\nCoar’s Disco Diffusion Guide\nDisco Diffusion Illustrated Settings\nAi generative art tools\nAI绘画的关键词（群友们的画 ）\nArtist Studies by @remi_durant\nCLIP Prompt Engineering for Generative Art - matthewmcateer.me\n数据集-LAION-400-MILLION OPEN DATASET | LAION\n",
    "description": "",
    "tags": null,
    "title": "AIGC 相关网站",
    "uri": "/01_aigc_object/04_web/"
  },
  {
    "content": "相关文档资料 使用 diffusers 训练你自己的 ControlNet 🧨\nStable Diffusion QR Code 101\nE-Hentai/태그 - 나무위키\n魔咒百科词典\nSo-VITS-SVC 4.1 整合包完全指南\nStable Diffusion 3.5 Prompt Guide — Stability AI\n使用 ChatGPT 进行写作的学生指南 |开放人工智能 — A Student’s Guide to Writing with ChatGPT | OpenAI\nrichards199999/Thinking-Claude: Let your Claude able to think\nhesamsheikh/ml-retreat: Machine Learning Journal for Intermediate to Advanced Topics.\nMidjourney Documentation and User Guide\n归档(可以不用看) Resources for GAN Artists\nDisco Diffusion Portrait Study (by @enviraldesign) - Google 文档\nalibaba/animate-anything: Fine-Grained Open Domain Image Animation with Motion Guidance\nGitHub - prophesier/diff-svc: Singing Voice Conversion via diffusion model\nTencentARC/GFPGAN: GFPGAN aims at developing Practical Algorithms for Real-world Face Restoration.\nguide to installing disco v5+ locally on windows\nclip_interrogator.ipynb - Colaboratory\nA Traveler’s Guide to the Latent Space\nCoar’s Disco Diffusion Guide\nDisco Diffusion Illustrated Settings\nAi generative art tools\nAI绘画的关键词（群友们的画 ）\nArtist Studies by @remi_durant\nCLIP Prompt Engineering for Generative Art - matthewmcateer.me\n数据集-LAION-400-MILLION OPEN DATASET | LAION\n",
    "description": "",
    "tags": null,
    "title": "相关文档资料",
    "uri": "/01_aigc_object/05_doc/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "关于我",
    "uri": "/about/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Categories",
    "uri": "/categories/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Tags",
    "uri": "/tags/"
  }
]
