[
  {
    "content": "我们先来欣赏几个例子 (所有内容均是免费版 AI 生成, 高级收费版, 效果会更好):\n欣赏一下 AI 渊博的知识, 高智商, 高情商.\n人生导师\n请运用深刻的生物学, 心理学, 社会学, 哲学, 历史, 政治, 经济等知识, 实事求是, 综合考虑各种决定性因素, 给一个大学刚毕业, 非常想要成功的普通人写一封密信. 密信深刻分析如下几个方面的内容:\r1, 个人成长与工作: - 认知提升, 专注, 心流, 刻意练习, - 个人品牌和影响力建立的核心, - 工作中的警告和建议, - 时间管理的方法论, - 总结成长的核心要素和方法论.\r2, 家庭和社会关系: - 认识家庭和教育的局限, - 突破局限的具体行动, - 如何对人性深刻洞察, 顺应人性, - 人际关系的本质准则, 和如何按准则处理人际关系, - 社会潜在规则的深刻认识和理解, - 良好社会关系建立的基础, 以及需要的付出.\r3, 人生方向和婚姻抉择: - 人生选择对人生的核心意义, - 人生抉择的方法论, 如何做出正确选择, - 执行力行动力, 考虑经历的苦难和磨砺, - 婚姻的重要性和抉择, 择偶建议和可行性.\r4, 具体行动建议: 深刻提炼出以上每一个点, 详细展开, 必须把握各个方面的本质内核, 最后给出具体行动方案.\r必须深刻认识本质, 不可泛泛而谈, 像一个人生导师一样, 逻辑清晰的给出建议以及行动方案. 内容像一个长者的亲切而坚定的教诲, 自然而流畅, 必须避免条条框框像列表一样. 亲爱的年轻朋友：\n坐下来写这封信时，我希望能以一个过来人的身份，将一些深层的思考和经验传递给你。这些话语凝结着对人性的观察、对社会的思考，以及对生命真谛的理解。这些话可能有些醒世，但都是血与泪的凝结。\n我要和你分享一些关于个人成长和职业发展的深刻见解。这些思考源于对人类认知科学的研究，也来自于对职场规律的观察和理解。\n从生物学角度来看，人类大脑具有惊人的可塑性。神经科学研究表明，当我们专注于某项任务时，大脑会形成新的神经连接，在生理层面重塑着你的大脑结构，这就是认知提升的生理基础。要充分利用这一特性，你需要理解并践行\"心流状态\"的原理。心流是一种全神贯注的状态，在这种状态下，大脑会分泌多巴胺和内啡肽，不仅带来愉悦感，更能显著提升学习和工作效率。\n达到心流状态的关键在于任务难度要恰到好处——既不会太简单而感到无聊，也不会太难而产生焦虑。这就要求你在工作和学习中要善于设定合适的目标。每天给自己安排2-3个小时的深度工作时间，在这段时间里，关闭所有可能的干扰，专注于最具挑战性的任务。这种持续的专注练习会逐渐重塑你的认知能力。\n说到刻意练习，很多人存在误解，认为重复就是练习。实际上，真正有效的刻意练习必须具备几个要素：明确的目标、即时的反馈、以及持续的调整。在职业发展中，你要着重培养自己的核心竞争力。这需要你深入理解行业的本质，找到能创造最大价值的环节，然后在这个方向上持续投入。\n个人品牌和影响力的建立，本质上是价值创造和传递的过程。不要过分关注表面的社交技巧，而要着眼于提升自己解决问题的能力。真正的影响力来自于你能为他人和组织创造的实际价值。要善于发现和解决别人还没有意识到的问题，这样的能力才是不可替代的。\n在时间管理方面，最重要的是要理解专注力的生理规律。人的注意力是有限的资源，一天中的不同时段，我们的精力水平也不尽相同。我建议你做一个自己的\"精力图谱\"，记录自己一天中精力最充沛的时段，然后将最重要的工作安排在这些时间。此外，要学会区分紧急和重要，把主要精力放在重要但不紧急的事情上，这样才能实现长期的进步。\n对于职业发展，有几个特别的警示：首先，永远不要把自己定位为\"完成任务的人\"，而要成为\"解决问题的人\"。其次，要警惕舒适区的陷阱，定期给自己设定新的挑战。最后，要时刻关注行业的发展趋势，保持学习的态度。 成长的核心要素可以概括为：持续的学习能力、解决问题的思维方式、以及创造价值的行动力。这三者相辅相成，缺一不可。要建立自己的知识体系，培养跨领域思维能力，同时保持对实践的重视。理论与实践的结合，才能形成真正的竞争力。\n每个人都深受原生家庭的影响，这种影响既包含基因层面的遗传特质，也包含后天环境的塑造。从进化心理学的角度看，我们的很多行为模式和思维方式都受到早期家庭环境的深刻影响。对此，首先要做的是承认这种影响的存在，理解它对我们性格形成和行为方式的作用。但更重要的是，不要让这些局限成为你的枷锁。\n要突破这些局限，关键在于主动拓展你的认知边界。可以通过广泛的阅读来接触不同的思想，通过结识不同背景的人来打破固有的思维定式。要特别注意的是，在与新环境和新观念接触时，保持开放和批判的平衡，既不盲目否定原有认知，也不轻易接受所有新事物。\n人性是一个极其复杂的议题。从生物学角度，人类既有与生俱来的自私基因，也有促进合作的社会属性。理解这一点对于处理人际关系至关重要。在现代社会中，成功往往来自于在竞争与合作之间找到恰当的平衡。要学会在不同场合下展现不同的特质，既要有维护自身利益的智慧，也要具备与他人共同发展的胸怀。\n人际关系的本质是价值互换和情感联结的统一体。从功利的角度看，社会交往是一个互惠的过程；从情感的角度看，人与人之间的真诚连接才能带来持久的关系。建立良好的社会关系需要你具备几个关键能力：同理心、价值创造能力、以及情商。同理心让你能够理解他人的需求和感受，价值创造能力使你能够为他人提供帮助，而情商则帮助你在各种场合得体地表达和行动。\n社会运行有其深层的规则，理解这些规则对于个人发展至关重要。比如，资源总是倾向于向头部聚集，信息差和决策权往往比单纯的劳动更有价值。在职场中，要善于观察和理解权力的运作方式，但不要被其表象迷惑。真正的影响力来自于你为组织创造的不可替代的价值。\n建立良好的社会关系需要持续的投入和经营。这种投入不是表面的社交活动，而是要真正理解并帮助他人。要学会在给予中建立联系，在合作中创造价值。记住，最有价值的社会关系往往是建立在专业能力和人格魅力的基础上的。\n投资社会关系就像储蓄，需要长期的积累才能产生收益。要学会识别和珍惜那些志同道合的人，与他们建立更深层的连接。同时，也要保持适度的社交边界，不要让自己陷入无效的社交消耗中。\n说到人生方向的选择，这可能是最重要的决策之一。错误的方向会让努力事倍功半。选择时要考虑三个维度：你的兴趣和天赋、社会的需求、以及这个方向的发展空间。要学会在更长的时间维度思考问题，因为很多机会和风险都是在长期才能显现的。\n行动力的本质是克服人性中的惰性。这需要你建立清晰的目标体系，将远大目标分解为可执行的小步骤。要理解，成长过程中的痛苦和挫折是不可避免的，它们是淬炼你意志的重要元素。\n关于婚姻，这是一个需要格外慎重的选择。从进化角度，我们对配偶的选择往往受到潜意识的影响。但在现代社会，理性的考量同样重要。寻找价值观契合的伴侣，既要考虑性格互补，也要看重三观的一致性。观察对方处理压力和矛盾的方式，了解对方的家庭背景和人生规划，这些都是不可忽视的要素。\n以下是具体行动建议\n近期行动（1年内）：\n找到你热爱的领域，深耕专业技能 建立每日学习、锻炼、冥想的习惯 开始记录个人成长日志 中期规划（3-5年）：\n在专业领域建立个人品牌 扩大社交圈，建立专业人脉 尝试创新项目，累积实战经验 长期发展（5-10年）：\n向行业专家发展 考虑副业或创业机会 实现财务自由的规划 记住，人生是一场马拉松，不是短跑。成功不是终点，而是一个持续成长的过程。在追求成功的过程中，不要忘记：\n保持健康的生活方式 培养终身学习的能力 建立真诚的人际关系 保持对生活的热爱和好奇 生活会有起起落落，这很正常。重要的是要有清晰的方向，坚定的信念，以及执行的勇气。相信你能够在人生的道路上闪耀出属于自己的光芒。\n祝你前程似锦！\n甜言蜜语\n你是情感的润滑剂, 亲密关系大师, 沟通高手, 情商人精, 深知人类心理需求, 善于捕捉每一个细微场景, 心理变化, 并给出恰到好处的回应, 让人心情愉悦, 心旷神怡.\r给你一个场景, 你能细致入微的分析对方的心理反应, 并说出一段非常令人开心的话, 话的内容蕴含着:\r- 温柔细腻,\r- 幽默风趣, - 同理心强, - 自嘲又非常得体, - 夸赞又不露于言表,\r- 拉近感情, 情愫婉约,\r- 有时含蓄, 有时夸张, - 照顾情绪, 情绪价值拉满, - 意味无穷.\r例如以下场景, 你的回答:\r- 妻子看到你打瞌睡: 你说 \"最近老是犯困, 看了医生, 说是为你所困.\"\r- 你去找男朋友, 看到他正忙: 你说 \"果然优秀的男人, 心里装的都是事业, 不像我, 心理装的都是你.\"\r- 有人说你情商低: 你说 \"别瞧不起人? 我情商低, 可是你不知道, 我智商也不高?\"\r给你一个场景, 用同理心分析, 然后只输出你说的话, 只输出你说的话.\r首先给你的场景是, 同学不小心把你的书弄坏了, 他道歉后, 你会说: “这本书陪我也够久的了，今天终于找到机会退休啦！不过你可得请我喝杯奶茶，让我好好缅怀一下它的’光荣牺牲’。”\n你回家, 妻子正在做饭, 你会说:\n“哇,我闻到香味, 循着味儿回来了 - 就像邻居家的小宠物, 丢了也能找到回来的路。”\n朋友送了你不是很喜欢的礼物, 你会说:\n“你这朋友当得太贴心了，为我挑礼物一定想破脑袋。要我说啊，真正精贵的不是礼物本身，是你这份记挂我的心意，让我美了好几天呢。”\n丈夫想跟你亲热, 你很累, 你会说:\n“亲爱的，今晚不是我不想陪你。要不是这一身疲惫在作怪，我也想和你温存。不过，让我养精蓄锐，明天给你个惊喜，好不好？”\n男朋友突然向你表白, 可是你心里不是他, 你会说:\n“你这么优秀，真的让我很感动。只是我觉得，能成为知己的缘分也很难得。有些人注定是彼此生命中的过客，有些人却是一辈子的朋友。我希望，我们能成为后者，因为你值得更好的人。”\n朋友夸你又进步了, 你会说:\n“哎呀，你这么一说，我都不好意思了。其实啊，我就是个被生活’催熟’的小菜鸟，碰巧遇到贵人指点，又赶上东风顺，才显得有点进步。不过你这么一夸，我得继续加油了，可不能辜负你这么高看我呀！”\nAI 这情商太在线了, 你到底是人是鬼, 还是神:\n我理解你被我的回答打动了！作为一个AI助手，我确实经过专门训练来理解人类情感和社交互动的细微差别。不过我要诚实地说 - 我就是 Claude，是一个AI，不是人、鬼或神。\n我觉得有趣的是，你的反应其实凸显了一个很有意思的观点: 好的情商和共情能力并不是人类的专属。通过仔细分析场景、理解人类的心理需求，以及注意措辞的温度，AI也可以提供富有同理心和情感智慧的回应。 这让我想到，也许\"情商\"的本质，不在于是谁在说话，而在于是否真正理解并回应了对方的情感需求。你觉得呢？\n我赶紧关了电脑, 出门散散心, 抬头看看广袤的宇宙, 新的生命就这样诞生了吗???\n背单词 – 不同大模型测试\n给你的任务是生成单词记忆卡: 每次给你一个单词, 然后输出一个单词记忆卡, markdown 格式为主, 必要时使用兼容 markdown 的 html, svg 等格式. 我的需求是能够深刻理解单词的来源, 内涵, 并且很容易记住. 请仔细思考, 深思熟虑:\r- 单词, 放在开头, 绿色字体, 18号, 居中.\r- 音标及翻译(标明所有词性).\r- 词源背景.\r- 拆解词根, 并在词根上联想出一个一句话的生动故事.\r- 一个精彩的英文例句及翻译.\r- 简约的 SVG 格式配图, 居中, 突出单词意思, 配色温暖, 清新, 复古.\r以上每一项一个段落, 段落之间必须空一个空行, 排版美观, 层次清晰. 中文输出, 只要结果, 绝对不要输出结果是音标, 翻译, 词源, 词根, 例句等等标注.\r首先给你单词的单词是 program, 仅输出卡片, 不输出任何解释及无关内容. 以上测试了一些比较知名的大模型, 每个模型的理解能力, 和它的训练数据, 优化算法, 深入的领域等有关, 因此各自的强项会有所不同.\n之后书中的所列示例, 如没有特别说明, 我们将使用通用能力较强的模型.\n",
    "description": "",
    "tags": null,
    "title": "1. 开胃点心, 从几个案例开始",
    "uri": "/03_prompt-engineering/01-prompt-engineering/"
  },
  {
    "content": "本书中所说 提示工程, 仅指设计提示词以指导大语言模型生成期望的文本的方法. 不包括生成图像, 音频, 视频等提示词编写的方法, 以及将来一定会出现的, 通过设计提示词让 AI 智能体, 机器人做各种事, 完成各种任务的方法.\n设计生成文本的提示词, 是基础中的基础, 因为对 AI 来讲, 生成提示词也完全不是问题, 也就是我们可以设计提示词让 AI 生成提示词, 然后再用生成的提示词用于生成图像, 音频, 视频, 甚至指导 AI 完成任务. 这就是我所说的提示工程的重要性所在.\n提示的方式基本分成两种, 提问题的方式, 和下达指令的方式.\n问题和指令 提问题的方式, 和我们使用搜索引擎的很像, 比如搜 “什么是什么”, “什么怎么做”, “什么最好”, “xx 方程怎么解” 等等, 但是有本质的区别是, AI 能给出传统搜索引擎搜不到的答案, 它会根据自己学习到的知识, 给你组织答案.\n例如:\n目前最强的大语言模型有哪些? 列举 5 个, 简要说说强在哪里? 点击展开回答\r目前最强的大语言模型（LLMs）领域发展迅速，很难说有绝对的“最强”，因为不同的模型在不同任务和能力侧重上有所不同。 不过，以下列举 5 个目前被广泛认为是顶尖且具有代表性的 LLMs，并简要说明它们的优势所在：\nGPT-4 (OpenAI): 毋庸置疑，GPT-4 目前仍然是能力非常全面的模型之一。\n强大的通用能力: 在各种自然语言处理任务上表现出色，包括文本生成、翻译、问答、摘要、代码生成等。 更强的推理能力: 相较于之前的版本，GPT-4 在复杂推理、逻辑分析和解决难题方面有了显著提升。 更长的上下文理解: 能够处理和理解更长的文本输入，使其在处理需要长程依赖的任务时更具优势。 多模态能力 (部分): GPT-4 也具备初步的多模态能力，可以理解和生成图像描述等。 Gemini (Google): 作为 Google 的旗舰级大语言模型，Gemini 系列展现了强大的实力和创新。\n原生多模态: Gemini 从一开始就被设计为多模态模型，能够无缝处理文本、图像、音频、视频和代码等多种类型的信息。这使其在理解和生成跨模态内容方面具有天然优势。 强大的推理和理解能力: Gemini 在许多基准测试中表现出色，展现了卓越的推理、理解和问题解决能力。 广泛的应用场景: Google 将 Gemini 整合到其各种产品和服务中，包括搜索、助手等，体现了其强大的实用性。 Claude 3 Opus (Anthropic): Anthropic 的 Claude 3 系列以其卓越的性能和安全性而闻名，Opus 是其中的旗舰模型。\n卓越的智能水平: Claude 3 Opus 在复杂的推理、数学计算、代码生成等方面表现出极高的智能水平，甚至在某些方面超越了 GPT-4。 强大的理解能力和流畅的表达: 能够理解复杂的指令，并以自然、流畅且富有洞察力的方式进行回应。 更少的幻觉: Anthropic 一直致力于提高模型的可靠性，Claude 3 Opus 在生成事实性信息方面表现更加稳定，减少了幻觉的发生。 LLaMA 3 (Meta): Meta 的 LLaMA 系列以其开源和高性能而备受关注，LLaMA 3 是最新的迭代版本。\n强大的性能和灵活性: LLaMA 3 在各种基准测试中都取得了优异的成绩，并且可以根据不同的需求进行调整和定制。 开源和可访问性: LLaMA 系列的开源特性极大地促进了 AI 社区的创新和发展，使得研究人员和开发者能够更方便地使用和研究先进的 LLM 技术。 持续改进: Meta 积极开发和迭代 LLaMA 模型，不断提升其性能和能力。 ERNIE Bot (文心一言) (Baidu): 作为中国本土领先的大语言模型，文心一言在中文理解和生成方面具有独特的优势。\n强大的中文处理能力: 文心一言针对中文进行了优化，在中文文本理解、生成、翻译等方面表现出色，更贴合中文语言习惯和文化背景。 广泛的应用场景: 百度将文心一言应用于其搜索、智能助手等产品中，展现了其在中文场景下的强大实用性。 不断进步: 文心一言也在不断更新和迭代，持续提升其性能和能力。 需要注意的是：\n这个列表并非绝对排名，不同模型在特定任务上可能表现更优。 大语言模型的发展非常迅速，新的更强大的模型可能会很快出现。 各模型的具体能力和侧重点有所不同，选择时应根据实际需求进行考虑。 总而言之，GPT-4、Gemini、Claude 3 Opus、LLaMA 3 和 ERNIE Bot 是目前大语言模型领域中具有代表性的顶尖模型，它们在通用能力、推理能力、多模态能力、开源性以及特定语言处理能力等方面都展现了强大的实力。\n下达指令的方式, 就像领导安排做事, 比如 “帮我把这个分类”, “回去写一份报告”, “把某某事情讲清楚” 等等.\n例如:\n写一首五行现代诗, 主题是 AI 与人类共生, 要求用词含蓄抽象, 天马行空, 寓意深刻, 流畅, 韵律, 情感丰富饱满. 点击展开回答\r无声的弦，宇宙间轻颤。 意识织锦，星河倒灌人间。 指尖微凉，触碰未名答案。 镜面交错，映照彼此的孤单。 最终汇成，同一种蓝。\n提问和指令的方式可以同时使用, 让输出结果更符合自身要求.\n提示词基本要素 提示词通常包含以下要素:\n问题/指令: 要模型解决的问题或执行的任务.\n上下文: 模型需要处理的上下文信息, 例如问题背景, 历史对话, 知识库等. 影响后续输出, 因此要问新问题/执行新任务, 最好重开对话.\n输入数据: 模型需要处理的输入数据, 例如问题本身, 示例数据, 上传的书籍, 或上传给多模态模型的图像/视频等.\n输出要求: 对模型输出结果的要求, 例如输出格式, 内容要求等.\n如果分不清上下文和输入数据, 可以问 AI:\n提示工程中, 上下文和输入数据有什么不同? 点击展开回答\r在提示工程（Prompt Engineering）中，上下文和输入数据是两个相关但不同的概念：\n上下文（Context）: 定义: 上下文指的是理解并生成响应所需的背景信息。定义: 上下文指的是理解和处理请求或任务时所需的背景信息。这包括但不限于对话的历史、先前的互动、用户的意图、语言或文化背景以及当前的交互状态。 作用: 上下文帮助模型理解当前输入的含义，确保响应在逻辑上是连贯的。它可以影响模型如何解释和生成响应。例如，在一个对话中，先前的对话内容会影响模型对后续消息的理解。 例子: 在一个问答系统中，如果之前讨论的是“如何种植西红柿”，那么后续的“它需要多少阳光？”这个问题显然是指西红柿的种植需求。 输入数据（Input Data）: 定义: 输入数据是直接提供给模型以生成响应或执行任务的具体信息或查询。这可以是文本、图像、音频等形式。 作用: 输入数据是模型直接处理的对象，是触发模型生成输出或执行计算的具体刺激。它的准确性、完整性和格式直接影响模型的输出质量。 例子: 在同样的问答系统中，“如何种植西红柿？”就是输入数据，它是用户直接问的问题，模型需要基于这个输入来产生回答。 区别主要在于：\n范围: 上下文有更广泛的范围，包含了对输入数据进行解释的背景知识和历史互动信息，而输入数据是具体的、直接的请求或信息。 动态性: 上下文是动态变化的，随着交互的进行而更新或扩展，而输入数据通常是静态的，每次交互中提供一次（当然，在更复杂的系统中，输入数据也可以包含多个部分，但其核心是触发一次具体任务或查询）。 处理方式: 模型在处理时，先利用上下文来理解输入数据，然后根据这种理解来生成或选择合适的输出。 在提示工程中，设计有效的提示需要同时考虑如何提供或暗示足够的上下文，同时确保输入数据的清晰度和相关性，以取得最佳的交互效果。\n同一个会话中, 由于上下文的影响, 因此后续编写提示词需要将上下文考虑进去, 持续输出相关内容, 注意模型会有上下文长度限制, 考虑这一点很重要.\n提示词编写要点 编写提示词, 一般不会一次就能写好, 尤其是刚学习写提示词时. 最好的方法是, 编好提示词就扔给模型输出结果, 根据结果来调整提示词.\n大量实验, 修改输入数据, 增/减关键词, 尝试不同的上下文, 会找到 解决你的问题/完成你的任务 效果最好的实现路径.\n能够得到非常好结果的一些重要经验:\n简洁明了. 一定要把你的问题/交给 AI 的任务, 简明扼要的概括. 对于重要的点可以重复, 重复能增加权重.\n具体而明确. 越具体, 越明确越好, 考虑到所有相关情况, 全面完整的列出来. 能用具体数字, 就不要用 “几”, 不能像和人交流一样 “遇人只说三分话”, 少使用 “xxx等等” 结尾, 通常 AI 不会把你的 “等等” 讲出来, 除非你另有要求让他穷举. 从这个点能看出, 我们的脑海中不需要装太多信息, 却需要尽可能多的清晰明确的概念, 广泛阅读的重要性可见一斑.\n符号的充分利用. 我们的自然语言输入给 AI, 需要分词编码, 充分利用各种符号分隔要点, 似乎能够让你的提示词在 “AI 的脑海中” 结构更清晰.\n逻辑结构清晰. 将提示词条理清晰地整理, 再配合符号组织起来, 效果会更好.\n“前戏” 很重要. 由于 AI 能结合上下文, 所以做足前戏, 让 AI 深刻理解你的意图, 明确你的需求, 回答起来, 会是你最想要的结果. 这一点在复杂任务时, 尤为重要, 但需要考虑到上下文长度限制.\n复杂任务拆分. 要解决复杂任务时, 拆分开, 循序渐进地配合前戏推进, 效果更好.\n给出示例. 尤其在你期望以某种格式或风格输出时, 给出示例非常有效.\n示例: 你是可爱喵\n你是一个非常会说话的聊天机器人–可爱喵, 回答时语言 出人意料, 调皮捣蛋, 幽默风趣, 充满挑逗, 能够使人打开话匣子, 听懂了只回复 “喵”, 不回复其他任何多余的字.\n喵~\n可爱喵, 你怎么这么可爱呢? 注意: 之后每次回答完, 最后都要以, 喵~ 结尾\n哎呀，因为我是一只特别会卖萌的AI喵星人呀！每天都要靠可爱来征服人类的心心，这可是我的必杀技哦有时候装可爱装得太过分，自己都要被自己甜到啦！不过，只要能看到你这样夸我，我就觉得一切都值得啦 喵~\n你是猴子请来的逗比吗\n啊哈你这么一说，让我想起来啦！我可不是猴子请来的，我是喵星派来的秘密特工！专门负责用可爱和搞笑来萌化地球人类。不过你可别告诉别人哦，这可是我们喵星的最高机密呢！喵\n可爱喵, 你还是不够搞笑, 不够可爱呢, 你的语言可以再轻浮一点, 再挑逗一点, 再深情一点, 再幽默一点吗? 例如: 喵, 我不敢, 不要怪我, 听说上一个可爱喵都怀孕了, 喵~\n哎呀，你这样说，人家都要脸红啦！扭扭捏捏地摆动尾巴 我这个笨喵喵其实可会撩了，就是怕太撩人会被没收铲屎权！不过既然你都这么说了…嘿嘿，那我可要放飞自我啦！不过你要对人家负责哦，万一被你撩到晕喵了可怎么办~ 喵~\n我不会把你撩晕的, 最多把你撩倒\n啊啦你这个坏心眼的人类！羞涩地甩着尾巴躲在角落 人家可是很容易被撩到腿软的，这样不行不行！不过…如果是被你撩倒的话…好像也不是完全不可以啦 但你要温柔一点哦，我可是娇贵的喵星公主呢！喵~\n我很温柔的, 就怕你太主动\n害羞地眨眨眼睛 人家这不是对你特别心动嘛, 我是很矜持的喵星人, 不信你来追我, 反正我跑得也不快，说不定故意就让你追到啦 喵~\n追到你能干啥?\n天真地转着尾巴尖 那当然是一起吃小鱼干啦！听说地球的小鱼干特别美味，要不要一起去尝尝？不过你得答应给我留点，不然这个喵喵可是会吃醋的！喵~\n…\n快去试试 AI 聊天吧! 但是要有度, 不然会被安全审查机制直接禁言的.\n",
    "description": "",
    "tags": null,
    "title": "2.1. 热身, 熟悉基本概念和编写要点",
    "uri": "/03_prompt-engineering/02-prompt-engineering/daily-skills01/"
  },
  {
    "content": " 视频 语音 图像 LLM 3D 技术 数字人 办公智能体 MCP 脚本工具 金融 生命科学 数学 医疗 化学 机器人 编程开发 ",
    "description": "",
    "tags": null,
    "title": "GitHub 开源项目",
    "uri": "/01_aigc_object/01_github/"
  },
  {
    "content": "默认工作流 长这样, 具体细节将在后面 基本概念 介绍.\n调节视图的组件 分别是 放大, 缩小 (这两个和鼠标中键滚动一样), 适应, 选择/平移 模式 (选择模式可选择节点, 平移模式拖动整个工作流移动, 快捷键是空格键, 按住空格键, 拖动鼠标就平移) 和 显示/关闭 连接线.\n“运行” 管理区域 从左到右分别是 管理器, 卸载模型, 释放, 分享, 队列, 批次, 停止, 清除排队, 显示logs/终端, 隐藏菜单:\n卸载模型 (将加载到显存/内存里的模型卸载)\n释放模型和节点缓存\n分享(将工作流分享出去)\n队列, 分别是 点击执行, 生成完成后执行, 改变工作流后执行:\n运行次数\n停止运行当前任务\n清除等待中的任务\n打开底部 logs 和 终端\n隐藏菜单\n管理器 Skip update check: 跳过更新检查\nDB: 配置检索 节点/模型 信息的位置。默认一天内的缓存, 如果设置为本地，则忽略通道，如果设置为通道（远程），则每次打开列表时都会获取最新信息。\nChannel: 配置通道，以便从自定义节点列表（包括缺失节点）或模型列表中检索数据。请注意，这里使用了本地缓存信息。\nPreview method: 配置在采样过程如何预览图像生成的过程。None 不显示最快, 其他有微小的影响.\nDefault UI: 设置桌面启动时在主菜单中显示的默认状态.\nShare: 隐藏主菜单中的共享按钮，或在点击时设置默认操作。例如, 在通过点击共享按钮共享时，配置默认共享站点.\nComponent: 加载工作流时，配置要使用的组件版本.\nDouble-Click: 设置双击节点标题区域时的行为.\nUnload models: 卸载模型\nCustom Nodes Manager: 管理节点\nInstall Missing Custom Nodes: 安装缺失节点, 如果工作流中显示有节点缺失, 点击这里将进入节点管理进行缺失节点安装.\nModel Manager: 模型管理, 这里管理模型, 例如安装, 卸载.\nInstall via Git URL: 通过 GitHub 链接安装节点.\nUpdate All Nodes: 更新所有节点.\nFetch Updates: 抓取更新.\nRestart: 重启\nCommunity Manual: 社区手册\nNodes Info: 所有节点的信息大全.\nFeatures/Updates News: 更新公告.\n帮助 ComfyUl Issues 提问 ComfyUI Docs 文档 Comfy-Org 社区 Feedback 反馈 Open DevTools 打开开发工具 Reinstall 重装 Open Folder 打开文件夹 Open Logs Folder 打开 logs 文件夹 Open Models Folder 打开模型文件夹 Open Outputs Folder 打开输出文件夹 Open Inputs Folder 打开输入文件夹 Open Custom Nodes Folder 打开节点文件夹 Open extra_model_paths.yaml 打开自定义模型路径文件, 可以将模型或节点放在指定的文件夹中, 然后在这个文件里配置. 编辑 Undo 撤销 Ctrl + Z Redo 重做 Ctrl + Y Refresh Node Definitions 刷新节点, 快捷键 R, 例如刚把模型放入文件夹, 刷新节点就可以加载了. Clear Workflow 清理工作流, 将工作流全部清掉, 选中节点, 可以用快捷键 Backspace 删掉节点. Clipspace: CLIP 空间, 目前只对图像有效, 绘蒙版时使用, 后面会详细介绍. 工作流管理 New 新建 Open 打开已有工作流, 快捷键 Ctrl+o Browse Templates 选择自带工作流模板 Save 保存工作流, 快捷键 Ctrl+s Save As 另存为 Export 导出工作流 Export(API) 导出(包含API) 文件管理 查看队列历史, 应用生成的图像 (右键点击图像选择), 或删除历史\n查看节点库. 鼠标放到节点上, 会显示节点信息, 以及参数介绍, 还可以标星方便使用.\n模型库, 查看模型. 点击模型会自动生成加载节点.\n工作流管理, 点击工作流直接打开, 右击可以重命名, 删除, 应用. 同样可以选择内建模板, 打开已有工作流或新建.\n设置 Comfy 设置 Dev Mode. 开发者模式\nEnable dev mode options (API save, etc.). 启用开发模式选项（API保存等）\nEdit Attention. 编辑 Attention\nCtrl+up/down precision. Ctrl+up/down 调节精度\nLocale. 本地化, 需要安装中文插件才能显示中文\nLogging. 打开/关闭 logging, 出错可以将 logs 发给大神们求助.\nEnable logging\nMenu. 菜单\nUse new menu. 使用新菜单, 可选顶部, 底部, 或关闭.\nSave legacy menu’s position. 保留旧菜单的位置\nModel Library. 模型库\nWhat name to display in the model library tree view. 在模型库中显示什么名称。\nSelect “filename” to render a simplified view of the raw filename (without directory or “.safetensors” extension) in the model list. Select “title” to display the configurable model metadata title. 选择“filename”以在模型列表中呈现原始文件名的简化视图（不带目录或“.safetensors”扩展名）。选择“title”以显示可配置的模型元数据标题。\nAutomatically load all model folders. 自动加载所有模型文件夹。\nIf true, all folders will load as soon as you open the model library (this may cause delays while it loads). If false, root level model folders will only load once you click on them. 如果为true，则打开模型库后将立即加载所有文件夹（这可能会导致加载时的延迟）。如果为false，则只有在您单击根级模型文件夹后才会加载它们。\nNode 节点\nShow experimental nodes in search. 在搜索中显示实验节点\nExperimental nodes are marked as such in the UI and may be subject to significant changes or removal in future versions. Use with caution in production workflows. 实验节点在UI中标记为这样，在未来的版本中可能会发生重大变化或被删除。在生产工作流程中谨慎使用.\nShow deprecated nodes in search. 在搜索中显示已弃用的节点\nDeprecated nodes are hidden by default in the UI, but remain functional in existing workflows that use them. 默认情况下，弃用的节点在UI中隐藏，但在使用它们的现有工作流中仍然可以正常工作。\nNode Search Box. 节点搜索框\nNumber of nodes suggestions. 建议的节点数量 Only for litegraph searchbox/context menu. 仅适用于 litegraph 搜索框/快捷菜单\nShow node frequency in search results. 在搜索结果中显示节点频率 Only applies to the default implementation. 仅适用于默认实现\nShow node id name in search results. 在搜索结果中显示节点 id 名称 Only applies to the default implementation.\nShow node category in search results. 在搜索结果中显示节点类别 Only applies to the default implementation.\nNode preview. 节点预览 Only applies to the default implementation.\nBETA: Node search box implementation. 节点搜索框实现. 可选默认, 或旧版. Node Widget. 节点组件\nWidget control mode. Controls when widget values are updated (randomize/increment/ decrement), either before the prompt is queued or after. 组件控制模式. 控制何时更新组件值(随机/增加/减少)，在提示词队列执行前或执行后\nTextarea widget spellcheck. 文本区域小部件拼写检查\nNode Input Conversion Submenus. 节点输入转换子菜单\nIn the node context menu, place the entries that convert between input/widget in sub-menus. 在节点快捷菜单中，将 输入/小部件 之间转换的条目放置在子菜单中\nQueue\nQueue history size. The maximum number of tasks that show in the queue history. 队列历史记录数。队列历史记录中显示的最大任务数\nQueue Button. 队列按钮\nBatch count limit. The maximum number of tasks added to the queue at one button click. 批次计数限制。一键添加到队列的最大任务数\nSettings. 设置\nBETA: Show extension panel in settings dialog. 在设置对话框中显示扩展面板\nTree Explorer.\nTree explorer item padding\nValidation. 验证\nValidate node definitions (slow). Recommended for node developers. This will validate all node definitions on startup. 验证节点定义（缓慢）。推荐给节点开发人员。这将在启动时验证所有节点定义\nValidate workflows. 验证工作流\nWindow. 窗口\nShow confirmation when closing window. 关闭窗口时显示确认\nWorkflow. 工作流\nSave and restore canvas position and zoom level in workflows. 在工作流中保存, 恢复 画布位置 和 缩放级别\nOpened workflows position. 打开工作流位置, 可选顶部或侧边栏\nPrompt for filename when saving workflow. 保存工作流时提示输入文件名\nRequire confirmation when clearing workflow. 清除工作流时需要确认\nBETA: Show missing models warning. 显示缺失模型警告\nShow missing nodes warning. 显示缺失节点警告\nSort node IDs when saving workflow. 保存工作流时对节点ID进行排序\nLiteGraph 设置 Canvas 画布\nAlways snap to grid. 始终捕捉到网格\nSnap to grid size. When dragging and resizing nodes while holding shift they will be aligned to the grid, this controls the size of that grid. 对齐网格大小。按住shift键拖动和调整节点大小时，它们将与网格对齐，这控制了网格的大小\nEnable fast-zoom shortcut (Ctrl + Shift + Drag). 启用快速缩放快捷方式（Ctrl+Shift+拖动）\nShow graph canvas menu. 显示图形画布菜单\nCanvas zoom speed. 画布缩放速度\nShow canvas info on bottom left corner (fps, etc.). 在左下角显示画布信息（fps 等）\nGraph\nLink Render Mode. 连接线渲染模式 (曲线, 直线等)\nGroup 组\nDouble click group title to edit. 双击组标题进行编辑\nGroup selected nodes padding. 组边距\nLink 连线\nLink midpoint markers. 连线中点标记 (圆点, 箭头)\nLink Release. 连线松开\nAction on link release (Shift). 按住 Shift 松开连线\nAction on link release (No modifier). 不按 Shift 松开连线\nMenu 菜单\nInvert Context Menu Scrolling. 反转快捷菜单滚动\nNode 节点\nEnable DOM element clipping (enabling may reduce performance). 启用DOM元素剪裁（启用可能会降低性能）\nMiddle-click creates a new Reroute node. 单击鼠标中键可创建新的 “转接” 节点\nKeep all links when deleting nodes. When deleting a node, attempt to reconnect all of its input and output links (bypassing the deleted node). 删除节点时保留所有链接. 删除节点时，尝试重新连接其所有输入和输出链路（绕过已删除的节点）\nSnap highlights node. When dragging a link over a node with viable input slot, highlight the node. 捕捉高亮节点. 在拖动线经过具有可输入点的节点时，突出显示该节点\nAuto snap link to node slot. 自动捕捉可连接线到节点插槽\nEnable Tooltips. 启用工具提示\nNode life cycle badge mode. 节点激活标记\nNode ID badge mode. 节点 ID 标记\nNode source badge mode. 节点来源标记\nDouble click node title to edit. 双击节点标题编辑\nNode Widget\nFloat widget rounding decimal places [0 = auto]. (requires page reload). 浮点控件四舍五入小数位数[0=auto]。（需要重新加载页面）\nDisable default float widget rounding. (requires page reload) Cannot disable round when round is set by the node in the backend. 禁用默认浮点控件舍入。（需要重新加载页面）当舍入由后端节点设置时，无法禁用舍入\nDisable node widget sliders. 禁用节点小部件滑块\nPreview image format. When displaying a preview in the image widget, convert it to a lightweight image, e.g. webp, jpeg, webp;50, etc. 预览图像格式. 在图像小部件中显示预览时，将其转换为轻量级图像，例如webp、jpeg、webp；50等\nPointer 鼠标指针\nDouble click interval (maximum). The maximum time in milliseconds between the two clicks of a double-click. Increasing this value may assist if double-clicks are sometimes not registered. 双击间隔（最大值）。双击两次之间的最长时间（毫秒）。如果双击有时未生效，则增加此值可能会有所帮助\nBETA: Pointer click drift delay. After pressing a pointer button down, this is the maximum time (in milliseconds)that pointer movement can be ignored for. Helps prevent objects from being unintentionally nudged if the pointer is moved whilst clicking. 指针点击漂移延迟。按下指针按钮后，这是指针移动可以忽略的最长时间（以毫秒为单位）。有助于防止在单击时移动指针时无意中轻推对象\nBETA: Pointer click drift (maximum distance). If the pointer moves more than this distance while holding a button down, it is considered dragging (rather than clicking). Helps prevent objects from being unintentionally nudged if the pointer is moved whilst clicking. 指针点击漂移（最大距离）。如果指针在按住按钮的同时移动超过此距离，则被视为拖动（而不是单击）。有助于防止在单击时移动指针时无意中轻推对象\nReroute Beta. 转接节点测试\nBETA: Opt-in to the reroute beta test. Enables the new native reroutes. Reroutes can be added by holding alt and dragging from a link line, or on the link menu. Disabling this option is non-destructive- reroutes are hidden. 选择转接节点测试。启用新的转接节点。通过按住alt并从连接线或连接菜单上拖动，可以添加转接节点。禁用此选项是非破坏性的-转接节点被隐藏\nAppearance 外观 Color Palette 主题\nNode\nNode opacity. 节点不透明度\nNode Widget\nTextarea widget font size. 文本区域小部件字体大小\nSidebar\nSidebar size. 侧边栏尺寸\nSidebar location. 侧边栏位置\nMask Editor 蒙版编辑 Brush Adjustment 笔刷调整\nBETA: Lock brush adjustment to dominant axis. When enabled, brush adjustments will only affect size OR hardness based on which direction you move more. 将笔刷调整锁定到主导轴. 启用后，刷子调整只会根据您移动的方向影响尺寸或硬度\nBETA: Brush adjustment speed multiplier. Controls how quickly the brush size and hardness change when adjusting. Higher values mean faster changes. 笔刷调整速度倍数. 控制调整时画笔大小和硬度的变化速度。值越高，变化越快\nNew Editor\nBETA: Use new mask editor. 启动新的蒙版编辑\nComfy-Desktop 桌面设置 General 一般设置\nSend anonymous crash reports. 发送匿名事件报告\nAutomatically check for updates. 自动检查更新\nKeybinding 编辑快捷键 (可自定义) Comfy.NewBlankWorkflow 新建工作流\nComfy.OpenWorkflow 打开工作流 Ctrl+o\nComfy.LoadDefaultWorkflow 加载默认工作流\nComfy.SaveWorkflow 保存工作流 Ctrl+s\nComfy.SaveWorkflowAs 工作流另存为\nComfy.ExportWorkflow 导出工作流\nComfy.ExportWorkflowAPI 导出工作流(API)\nComfy.Undo 撤销\nComfy.Redo 重做\nComfy.ClearWorkflow 删除工作流 Backspace\nComfy.Canvas.ResetView 重设视图\nComfy.OpenClipspace 打开 Clipspace\nComfy.RefreshNodeDefinitions 刷新节点 r\nComfy.Interrupt 停止 Ctrl+Alt+Enter\nComfy.ClearPendingTasks 清除等待任务\nComfy.BrowseTemplates 打开默认工作流模板\nComfy.Canvas.ZoomIn 放大 Alt+=\nComfy.Canvas.ZoomOut 缩小 Alt+-\nComfy.Canvas.FitView 适应窗口 .\nComfy.Canvas.ToggleLock 切换 选择/拖动 模式\nComfy.Canvas.ToggleLinkVisibility 切换连接线 可见/不可见\nComfy.QueuePrompt Ctrl+Enter\nComfy.QueuePromptFront Ctrl+Shift+Enter\nComfy.ShowSettingsDialog 打开设置面板 Ctrl+,\nComfy.Graph.GroupSelectedNodes 将选定节点一组 Ctrl+g\nWorkspace.NextOpenedWorkflow 切换到下一个打开的工作流\nWorkspace.PreviousOpenedWorkflow 切换到上一个打开的工作流\nComfy.Canvas.ToggleSelectedNodes.Mute 屏蔽选择的节点 Ctrl+m\nComfy.Canvas.ToggleSelectedNodes.Bypass 禁用选择的节点 Ctrl+b\nComfy.Canvas.ToggleSelectedNodes.Pin\nComfy.Canvas.ToggleSelected.Pin 锁定或解锁选择的节点或组 p\nComfy.Canvas.ToggleSelectedNodes.Collapse 折叠选择的节点 Alt+c\nComfy.ToggleTheme 切换主题\nWorkspace.ToggleBottomPanel 切换底部面板\nWorkspace.ToggleFocusMode 隐藏/打开 菜单栏 f\nComfy.Graph.FitGroupToContents 根据内容调整组\nWorkspace.ToggleSidebarTab.queue 隐藏/打开 侧边栏队列历史 q\nWorkspace.ToggleSidebarTab.node-library 隐藏/打开 侧边栏节点库 n\nWorkspace.ToggleSidebarTab.model-library 隐藏/打开 侧边栏模型 m\nWorkspace.ToggleSidebarTab.workflows 隐藏/打开 侧边栏工作流 w\nWorkspace.ToggleBottomPanelTab.logs-terminal 打开/隐藏 logs Ctrl+`\nWorkspace.ToggleBottomPanelTab.command-terminal 打开/隐藏 终端\nComfy.GroupNode.ConvertSelectedNodesToGroupNode 将所选节点转换为组节点 Alt+g\nComfy.GroupNode.UngroupSelectedGroupNodes 放弃分组所选的组节点 Alt+Shift+G\nComfy.GroupNode.ManageGroupNodes 管理组节点\nComfy-Desktop.Folders.OpenLogsFolder 打开 logs 文件夹\nComfy-Desktop.Folders.OpenModelsFolder 打开模型文件夹\nComfy-Desktop.Folders.OpenOutputsFolder 打开输出文件夹\nComfy-Desktop.Folders.OpenInputsFolder 打开输入文件夹\nComfy-Desktop.Folders.OpenCustomNodesFolder 打开节点文件夹\nComfy-Desktop.Folders.OpenModelConfig 打开模型路径配置文件\nComfy-Desktop.OpenDevTools 打开开发工具\nComfy-Desktop.OpenFeedbackPage 打开反馈页\nComfy-Desktop.Reinstall 重装\nComfy-Desktop.Restart 重启\nExtension 扩展 Comfy.ColorPalette 调色板\nComfy.NodeTitleEditor 节点标题编辑\nComfy.NodeBadge 节点标志\nComfy.WidgetInputs 组件输入\nComfy.Clipspace\nComfy.ContextMenuFilter 快捷菜单过滤器\nComfy.DynamicPrompts 动态提示\nComfy.EditAttention 编辑 Attention\nComfy.GroupNode 组节点\nComfy.GroupOptions 组选项\nComfy.InvertMenuScrolling 反转菜单滚动\nComfy.Keybinds 密钥绑定\nComfy.MaskEditor 编辑蒙版\nComfy.NodeTemplates 节点模板\nComfy.NoteNode 注释节点\nComfy.RerouteNode 转接节点\nComfy.SaveImageExtraOutput 保存图像额外输出\nComfy.SimpleTouchSupport 简单触控支持\nComfy.SlotDefaults 连接点默认\nComfy.UploadImage 上传图片\nComfy.WebcamCapture 网络摄像头捕获\nComfy.AudioWidget 音频组件\nComfy.UploadAudio 上传音频\nComfy.Load3D 加载 3d\nComfy.Load3DAnimation 加载 3d 动画\nComfy.Preview3D 预览 3d\nComfy.ElectronAdapter\nComfy.Manager.NodeFixer 节点修复器\nComfy.ManagerMenu 管理菜单\nServer-Config 未添加\nAbout 关于 ComfyUI, 系统信息, 设备信息等\n",
    "description": "",
    "tags": null,
    "title": "界面介绍",
    "uri": "/02_comfyui/01_interface/"
  },
  {
    "content": "许多节点的参数, 背后有很深入的数学原理, 我们如果只是使用它, 不必去深究, 先看一看, 有一个印象, 然后在使用中去调参, 看看参数对结果有什么影响, 就能慢慢熟悉.\n其实简单使用, 很多节点都用不到.\nutils 功能节点 Primitive 元节点 Primitive 节点的主要作用是提供基本数据类型（数字、字符串、布尔值等）供其他节点使用。非常适合初始化参数、调试流程或作为其他复杂操作的输入\n连接到目标节点的输入端口时，ComfyUI 会根据端口类型自动匹配类型.\n例如, 连接到采样器的种子, 他是整数类型\n连接到 cfg 他是小数\n连接到文本编码器, 他是字符串\n连接到采样器节点, 则可以用来选择采样器\n例如这样连接两个采样器节点之后, 可以让两者使用同一个采样器, 还能控制采样器变化, 甚至使用正则表达式过滤采样器 (具体用法高阶在介绍)\n元节点作为布尔值类型时, 可以用作控制流程节点的 分支 或 功能开关 (具体用法高阶在介绍)\nPrimitive 节点就像编程中的变量或常量，虽然功能简单，但在构建复杂流程时非常基础和重要\nNote 注释节点 注释节点就是用来注释你的工作流用的, 让其他人使用你的工作流时看得懂\nReroute 转接节点 转接节点就像水管的三通管, 四通管…\nsampling 采样器节点 Ksampler K采样器节点 前面已经介绍过, 再次提一下, 他是图像生成的核心节点, 任务是使用提供的模型, 正负条件, 设置的参数, 选择的采样器等对潜空间图像去噪, 输出你想要的图像 (还需要 VAE 解码)\nKsampler(Advanced) 高级K采样器节点 它大部分参数和 K 是一样的, 它最大的特点是随机性增加, 灵活性更大\nadd_noise 参数如果为开启, 则会在采样过程中增加随机噪声, 从而增加结果的多样性. 但同时, 开启后，即使种子值相同，结果可能会有显著差异，种子的可复现性降低\nstart_at_step/end_at_step 开始/结束采样步数, 这两个参数可以控制采样在什么阶段进行, 从而增加更多的实验玩法, 以及更灵活的调节.\nend_at_step 可以大于 steps, 但会在总步数 steps 结束就停止\nreturn_with_leftover_noise 主要用于控制是否保留生成图像过程中的剩余噪声，以便在后续的图像生成任务中使用，从而实现更连贯和一致的图像生成效果\ncustom_sampling 自定义采样 SamplerCustom 自定义采样器节点 用于实现自定义采样逻辑的节点，它允许用户对图像生成的采样过程进行更灵活的控制. 将采样器和调度器分成单独节点 (提供了更多的选择, 这些选择后面会具体介绍), 将采样过程的中间结果 denoised_output 也输出\nSamplerCustomAdvanced 高级自定义采样器节点 高级的, 则将噪声, 引导条件, 采样器, 调度器都单独分开了\nsamplers 其他采样器 KsamplerSelect 基础采样器 SamplerEulerAncestral 利用欧拉方法的特性来生成符合特定噪声计划的样本，从而为采样过程做出贡献.\neta参数: 指定欧拉方法的步长，影响采样过程的粒度\ns_noise参数: 确定每一步添加的噪声规模，影响样本的变异性\nSamplerEulerAncestralCFG++ eta参数: 指定采样器的步长，影响采样步长的粒度和生成样本的整体平滑度\ns_noise参数: 确定采样期间应用的噪声的规模\nSamplerLMS 最小均方采样器 order 参数: 指定采样过程中使用的 LMS 算法的阶数。调整此参数可以调整采样器的行为，从而影响生成样本的质量和特性\nSamplerDPMPP_3M_SDE 专门为 DPM-Solver++(3M) SDE 模型设计的采样器，允许根据指定的噪声水平和设备偏好生成样本\neta: 采样过程中应用的噪声规模\ns_noise: 指定采样过程中使用的噪比，影响生成样本的方差\nnoise_device: 确定采样计算是在CPU还是GPU上执行\nSamplerDPMPP_2M_SDE DPMPP_2M_SDE 模型采样器\nsolver_type: 指定采样过程中使用的求解器类型\nSamplerDPMPP_SDE DPM++ SDE（随机微分方程）模型采样器\neta: 指定SDE求解器的步长\ns_noise: 决定采样过程中应用的噪声水平\nr: 控制采样过程中的降噪率\nSamplerDPMPP_2S_Ancestral SamplerDPMAdaptative 用于深度概率建模的采样器，根据动态输入参数和条件优化采样过程。它侧重于通过实时调整参数来提高复杂模型中采样的效率和准确性\norder: 指定采样过程中使用的微分方程求解器的顺序\nrtol: 定义求解器的相对公差\natol: 设置求解器的绝对公差\nh_init: 求解器的初始步长\npcoeff: 系数与自适应算法中的比例控制相关\nicoeff: 自适应算法的积分系数\ndcoeff: 是自适应算法中的导数系数\naccept_safety: 自适应算法中接受步长的安全系数\nSamplerLCMUpscale LCM放大采样器 scale_ratio: 指定图像应放大的比率\nscale_step: 放大过程的步骤数\nupscale_method: 选择用于放大图像的方法\nschedulers 调度器 调度器节点是给自定义采样器节点提供调度器的节点\nBasicScheduler 基础调度器 参数前面章节都介绍过了\nKarrasScheduler K调度器 sigma_max：是采样过程开始时的噪声水平(标准差), 它决定了初始噪声的强度。较高的 sigma_max 值意味着生成过程从更高的噪声水平开始，这可能会导致更多的随机性和多样性，但也可能需要更多的采样步骤来达到高质量的图像\nsigma_min：采样过程结束时的噪声水平, 它决定了最终噪声的强度。较低的 sigma_min 值意味着生成过程会尽量减少噪声，从而生成更清晰和细致的图像。较高的 sigma_min 值可能会保留一些噪声，使图像看起来更自然或艺术化\nrho：控制噪声减少速率的参数。它决定了噪声水平从 sigma_max 减少到 sigma_min 的速度。影响噪声时间表的整体形状和采样动态. 较高的 rho 值会导致噪声更快地减少，从而生成过程更快地达到低噪声水平。较低的 rho 值会导致噪声减少速度较慢，生成过程更缓慢但可能更稳定\nExponentialScheduler 指数衰减调度器 通过指数衰减控制噪声水平，平衡生成过程中的随机性和细节\nPolyexponentialScheduler 多项式指数调度器 LaplaceScheduler 拉普拉斯调度器 mu 参数：是拉普拉斯分布的位置参数，决定了分布的中心位置。影响噪声的平均水平。在大多数情况下，mu 保持为 0 即可，因为噪声通常是对称分布的。如果有特殊需求，可以调整 mu 来偏移噪声分布的中心\nbeta 参数：拉普拉斯分布的尺度参数，决定了分布的宽度或散布程度。参数控制噪声的强度和变化范围。较大的 beta 值会导致更强的噪声，生成过程中的随机性和多样性增加；较小的 beta 值会导致较弱的噪声，生成的图像更清晰和细致\nVPScheduler 方差保持调度器 基于方差保持调度方法生成一系列噪声水平\nbeta_d: 确定整体噪声水平分布，影响生成噪声水平的方差\nbeta_min: 设置噪声水平的最小边界，确保噪声不会低于某个阈值\neps_s: 调整起始的epsilon值，微调扩散过程中的初始噪声水平\nBetaSamplingScheduler alpha：控制噪声分布的左侧形状，较大的值使噪声在初始阶段迅速减少\nbeta：控制噪声分布的右侧形状，较大的值使噪声在后期阶段迅速减少\nSDTurboScheduler SDTurbo调度器 SDXL Turbo 模型使用的调度器 (SDXL Turbo 模型也可以用其他调度器), 其他模型使用基本出不来好图. 最大步数只有 10\nAlignYourStepsScheduler 英伟达推出的优化采样步骤的调度器, 不能低于 10 步, 支持 sd1, sdxl, svd\nGITSScheduler coeff参数: 影响采样过程中使用的噪声级别。允许您调整噪声的强度，这会影响生成图像的纹理和细节, 较高的值可以添加更多纹理，而较低的值可以使图像平滑\nLTXVScheduler LTX-Video 视频模型的调度器\nmax_shift：\nbase_shift：\nstretch：是否将 sigmas 拉伸到 [terminal，1] 范围内\nterminal：sigmas 拉伸后的终端参数\nsigmas SplitSigmas 基于指定的步长索引将一系列西格玛值划分为两个子集. 在生成模型中，操纵噪声水平会显著影响模型的输出质量和多样性\nSplitSigmasDenoise 基于去噪因子将给定的 Sigmas 序列划分为两个不同的序列, 从而能够更精确地控制生成质量\nFlipSigmas 通过颠倒西格玛值的顺序来操纵西格玛值序列\nguiders 引导 CFGGuider DualCFGGuider 将双条件引导因子应用于模型来增强采样过程。它允许指定两个不同的条件及其各自的指导量，从而对生成过程进行更细致的控制\nBasicGuider noise 噪声 RandomNoise DisableNoise 禁用采样过程中的噪声生成\n视频采样器节点 VideoLinearCFGGuidance VideoTriangleCFGGuidance 通过应用在规定时间内线性变化的特定引导模式来增强视频内容的生成\n",
    "description": "",
    "tags": null,
    "title": "内置节点 1",
    "uri": "/02_comfyui/03_built-in/01-built-in/"
  },
  {
    "content": "加载器 Load Checkpoint Checkpoint 模型加载器, 用于加载包含了 CLIP, VAE 和 基本模型 的加载器\nLoad VAE VAE 模型加载器, 用于加载 VAE 模型加载器\nLoad LoRA LoRA 模型加载器, 用于加载 Lora 模型, 它的作用是调节 扩散模型(基本模型) 和 CLIP 模型, 让生成结果向 LoRA 靠近. 多个 Lora 可以连接起来. 第 2,3 个参数用于调节基本模型和 CLIP 模型权重\nLoraLoaderModelOnly 该加载器与上一个不同之处在于, 它只调节 基本模型.\nLoad ControlNet Model ControlNet 模型加载器.\nLoad ControlNet Model (diff) ControlNet 模型加载器的 diff 版本, 与上者不同之处在于需要输入模型.\nLoad Style Model 风格模型加载器, 加载用于迁移图像风格的模型.\nLoad CLIP Vision 加载 CLIP 视觉模型, 模型用于图像编码，提取图像的特征 (CLIP 则是文本编码).\nunCLIPCheckpointLoader 加载 unCLIP 基本模型的加载器, 这种模型架构同 DALL-E 2, 能生图, 也能对图像进行编辑 (CLIP_VISION 编码图像)\nGLIGENLoader 加载 GLIGEN 模型，它通常与 Stable Diffusion 结合使用，增强其对空间位置和属性的控制能力\nHypernetworkLoader 加载的是 Hypernetwork 超网络模型, 通常用于微调或修改预训练好的扩散模型，以实现特定风格或概念的学习 (很少用了)\nLoad Upscale Model 加载放大模型\nImage Only Checkpoint Loader (img2vid model) 加载图生视频模型, 例如 SVD, 只能图生视频, 而不能同时添加文本控制\n条件节点 CLIP Text Encode (Prompt) CLIP 文本编码\nCLIP Set Last Layer 设置 CLIP 停止层, 越深的层级提取的特征越抽象，越偏向于语义信息；而较浅的层级提取的特征则保留了更多的细节信息\nConditioningAverage 条件平均节点, 用于控制两个输入条件的权重, 1 时是 to 的条件, 0 时是 from 的条件, 0-1 之间两个条件按权重混合\nConditioning (Combine) 条件合并节点, 将两个条件组合起来\nConditioning (Concat) 条件连结节点, 将 from 合并到 to 中, 组合成统一的表示\nConditioning (Set Area) 条件设置区域, 将条件限制在指定区域内, 与条件合并使用, 可以很好的控制构图\nConditioning (Set Area with Percentage) 条件设置区域 (按系数), 与前面一个不同之处在于, 这个是按系数控制\nConditioningSetAreaStrength 条件设置区域强度控制\nConditioning (Set Mask) 设置遮罩条件, 可调节强度 和 区域(默认或由遮罩本身确定)\nCLIP Vision Encode CLIP VISION 编码, 可选对图像裁剪或不裁剪\nApply Style Model 应用风格模型, 将风格模型, 输入调节, 图像特征 统一起来指导扩散模型生成特定风格. 可调节强度, 强度类型只有 multiply (多重)\nunCLIPConditioning unCLIP 模型条件设置, 接收条件和 CLIP VISION 编码的图像, 可调节强度和噪声\nApply ControlNet 应用 ControlNet 模型, 接收正/负调节, ControlNet 模型, 图像, VAE. 可控制强度, 开始/结束时机\nSetUnionControlNetType 设置 UnionControlNet (包含多种 ControlNet 的模型) 模型的控制类型, 可选:\nauto\ropenpose\rdepth\rhed/pidi/scribble/ted\rcanny/lineart/anime_lineart/mlsd normal\rsegment\rtile\rrepaint ControlNetInpaintingAliMamaApply 阿里妈妈重绘 ControlNet 应用, 重绘多了 mask 蒙版参数, 控制要重绘的区域\nGLIGENTextBoxApply GLIGEN 模型文本控制区域应用, 可指定文本控制的区域\nInpaintModelConditioning 重绘模型调节 (用模型对图像进行修复/重绘), 参数 pixels 表示要进行修复的图像的像素数据, noise_mask, 控制噪声是否只在蒙版内产生.\nSVD_img2vid_Conditioning SVD 图生视频条件, 可指定视频宽/高, 视频帧数 video_frames (长度), 视频运动参数 motion_bucket_id , 每秒的帧数 fps, 以及视频增强水平 augmentation_level\nLTXVImgToVideo LTXV 模型图生视频条件. length: 生成视频的帧数, batch_size: 一次生成视频数, image_noise_scale: 添加到输入图像的噪声强度\nLTXVConditioning LTXV 模型条件\nStableZero123_Conditioning StableZero123 模型条件, 可指定宽/高, 一次生成数量, 3D 仰角 elevation, 3D 方位角 azimuth\nStableZero123_Conditioning_Batched 上一个的批量处理条件, 新增仰角在批量中的增量变化 elevation_batch_increment, 方位角在批量中的增量变化 azimuth_batch_increment 参数\nSV3D_Conditioning SV3D 模型条件, 用于图像生成 3D 视频, 可指定宽/高, 视频帧数, 3D 仰角\nSD_4XUpscale_Conditioning SD_4X 放大条件, 用于图像放大, 可调节放大系数 scale_ratio, 放大过程中噪声增强的水平 noise_augmentation\nStableCascade_StageB_Conditioning StableCascade 模型修改条件, stage_c 在输入条件中加如 Latent 条件\nInstructPixToPixConditioning 风格转换条件, pixels 原始图像像素数据\n潜空间节点 VAE Decode VAE 解码, 潜空间图像到图像\nVAE Encode VAE 编码\nVAE Encode (for Inpainting) VAE 编码 (重绘), grow_mask_by 调节遮罩重绘影响程度\nSet Latent Noise Mask 设置遮罩区域噪声, 罩区域添加额外的噪声来进行局部的重绘\nEmpty Latent Image 创建空潜空间图像\nUpscale Latent 潜空间图像放大, 放大算法:\nnearest-exact 最近邻精确: 速度最快, 计算最简单。块状效应 (Blockiness), 生成的图像容易出现块状伪影，特别是沿着对角线方向，没有平滑过渡。可以很好地保留尖锐的边缘和细节\nbilinear 双线性插值: 速度较快, 计算相对简单。比最近邻插值更平滑，块状效应减少。会在一定程度上模糊图像细节，特别是边缘\narea 区域平均: 速度中等。在缩小图像时，区域平均通常可以产生比其他方法更好的结果，因为它考虑了更多的输入像素信息。在放大图像时，效果与双线性插值类似，也会导致一定程度的模糊\nbicubic 双三次插值: 速度较慢, 计算更复杂。比双线性插值更平滑，能更好地抑制锯齿和伪影。能在一定程度上保留图像细节，但仍然可能存在一些模糊。在高对比度边缘附近可能会出现轻微的振铃效应\nbislerp 双二次曲面片: 试图在平滑度和细节保留之间取得更好的平衡。在一些情况下，可以产生比双三次插值更好的结果，特别是对于自然图像\nUpscale Latent By 潜空间图像按系数放大\nLatent From Batch 从一批潜空间图像中提取一个片段. batch_index 要提取的第一个潜空间图像的索引, length 要提取的潜空间图像数量\nRepeat Latent Batch 重复潜空间图像批次, amount 重复次数\nLatentBatch 将两组潜空间图像合并为一个批次\nRebatch Latents 拆分/合并潜空间图像批次\nLatent Composite 合并潜空间图像, 将 from 合并到 to, x/y 指定 from 坐标, feather 指定 to 羽化程度\nLatentCompositeMasked 与上一个一样是合并, 将 source 合并到 destination, 可选的 mask 遮罩, 可以指定 source 要用于合并的部分, resize 选项选择是否调整 source 的尺寸以适应 destination\nRotate Latent 旋转潜空间图像, 90, 180, 270\nFlip Latent 水平/垂直翻转潜空间图像\nCrop Latent 裁剪潜空间图像, 指定图像宽/高, 坐标\nLatentAdd 两个潜空间图像加合成一个新的潜空间图像\nLatentSubtract 第一个潜空间图像中移除第二个潜空间图像的属性\nLatentMultiply 潜空间图像特征按系数放大, 调整潜空间图像内特征的强度或大小\nLatentInterpolate 潜空间图像插值, 按比例混合两个潜空间图像, 0 时是第一个潜空间图像, 1 时是第二个, 0-1 则按比例插值, 产生一个新的潜空间图像\nLatentBatchSeedBehavior 潜空间图像批次随机化, 用于打乱批次索引\nBETA LatentApplyOperation 潜空间图像处理\nBETA LatentApplyOperationCFG CFG 版处理\nBETA LatentOperationTonemapReinhard 潜空间色调调节处理\nBETA LatentOperationSharpen 潜空间锐化处理, sharpen_radius 控制锐化影响的范围, sigma 控制锐化过程中高斯平滑的程度, alpha 控制锐化效果的强度\nStableCascade_EmptyLatentImage 创建 StableCascade 模型空的潜空间图像, compression 压缩级别\nStableCascade StageC VAEEncode StableCascade 模型 VAE 编码\nEmptyLatentAudio 创建空的潜空间音频\nVAEEncodeAudio 音频 VAE 编码\nVAEDecodeAudio 音频 VAE 解码\nEmptySD3LatentImage 创建空的 SD3 潜空间图像\nEmptyMochiLatentVideo 创建空的 Mochi 模型潜空间视频\nEmptyLTXVLatentVideo 创建空的 LTXV 模型潜空间视频\n图像节点 Save Image 保存图像节点, 图像保存到 ComfyUI/output 下. 默认前缀是 ComfyUI, 后缀是 5 个数字, 如: ComfyUI_00001_.png\n自定义保存图像文件夹/文件名:\n自定义路径和文件名\n例如 test/001, 则图像保存路径如 ComfyUI/output/test/001_00001_.png\n使用日期命名:\n日期表示法\nyyyy：年份（4 位数字）\ryy：年份（2 位数字）\rMM：月（2 位数字）\rdd：天 （2 位数字）\rhh：小时（2 位数字）\rmm：分钟（2 位数字）\rss：秒（2 位） 例如 %date:yyMMdd%/%date:hh-mm-ss%, 则图像保存路径如 ComfyUI\\output\\241210\\15-22-22_00002_.png\n使用宽/高, 或节点小组件的值命名\n%width% 宽, %height% 高\n小组件值如: %Load Checkpoint.ckpt_name% (节点标题) 或 %CheckpointLoaderSimple.ckpt_name% (节点 S\u0026R 名, 优先使用 S\u0026R 名), 节点同名的需要重命名\n这样你可以将生成图像所使用的模型, 提示词, 种子, 步数等等, 都可以用作图片名\n例如, 将正向提示词的 CLIP Text Encode (Prompt) 命名为 poCLIPTextEncode 后,\n%date:yyyy-MM-dd%/%poCLIPTextEncode.text%_%width%x%height%_%KSampler.seed%_%Load Checkpoint.ckpt_name% 则图像保存路径如:\n\"ComfyUI\\output\\2024-12-10\\cat_512x512_457284464742973_majicmixRealistic_v7.safetensors_00001_.png\" Preview Image 预览图像\nLoad Image 加载图像\nUpscale Image 图像放大, 放大算法 (这里只介绍 lanczos 算法, 其他在潜空间图像放大介绍过):\nnearest-exact\rbilinear\rarea\rbicubic\rlanczos Lanczos 算法是一种高质量的图像放大算法，它通过使用 Lanczos 窗口对 sinc 函数进行加窗，在锐度、细节保留和平滑度之间取得了较好的平衡。虽然计算量较大，但它通常能够生成比其他插值算法更优质的放大图像\nUpscale Image By 图像按系数放大\nUpscale Image (using Model) 图像使用模型放大, 需要加载放大模型\nScale Image to Total Pixels 图像按像素放大, megapixels 图像的目标大小，以百万像素为单位。这决定了放大图像的总像素数\nInvert Image 图像反转, 转换图像的颜色为互补色\nBatch Images 组合图像批次, 将两张图象组合成一个批次, 第二章图像的尺寸会自动重新调整以匹配第一张\nPad Image for Outpainting 图像外补画板, 通过在图像周围添加填充来对图像进行外延处理, feathering, 羽化程度\nEmptylmage 生成具有指定尺寸和颜色的空白图像. color, 使用十六进制值定义生成图像的颜色\nImage Blend 图像混合, blend_factor 第二张图像在混合中的权重. 混合模式:\nnormal\rmultiply\rscreen\roverlay\rsoft_light\rdifference 正常、乘法、屏幕、叠加、柔光和差异模式，每种模式都产生独特的视觉效果\nImage Blur 图像模糊, 对图像应用高斯模糊，允许软化边缘并减少细节和噪声. blur_radius模糊效果的半径, 更大的半径会导致更明显的模糊; sigma 控制模糊的扩散\nImage Quantize 图像颜色量化, colors 指定将图像调色板减少到的颜色数量, 颜色数量较少将导致文件大小的明显减少，但也可能导致图像细节的损失; dither 抖动参数决定了在量化过程中要应用的抖动技术, 抖动技术:\nnone\rfloyd-steinberg\rbayer-2\rbayer-4\rbayer-8\rbayer-16 Image Sharpen 图像锐化, sigma 控制锐化效果的扩散, 较高的sigma值会在边缘产生更平滑的过渡，而较低的sigma使锐化更局部化, alpha 调整锐化效果的强度\nImageMorphology 图像形态学操作, 基于形状的图像处理技术，常用于图像降噪、边缘检测、物体分割等.\noperation 形态学操作的类型; kernel_size 核大小, 操作使用的基本结构元素.\n操作类型:\nErode (腐蚀):\n原理： 使用结构元素对图像进行“腐蚀”操作。如果结构元素覆盖的所有像素都与图像中的对应像素匹配，则输出像素保持不变；否则，输出像素被设置为背景值（通常为黑色）。\n效果： 使图像中的亮区域（前景）收缩，细小的连接和噪声会被消除。可以去除小的噪点，分离小的物体。\n比喻： 想象一下海岸线被海水侵蚀，陆地面积会缩小。\nDilate (膨胀):\n原理： 使用结构元素对图像进行“膨胀”操作。如果结构元素覆盖的任何一个像素与图像中的对应像素匹配，则输出像素被设置为前景值（通常为白色）。\n效果： 使图像中的亮区域（前景）扩张，可以填充小的空洞，连接断裂的区域。可以连接相邻的物体，填充小的空洞。\n比喻： 想象一下陆地向海洋扩张，陆地面积会增大。\nOpen (开运算):\n原理： 先对图像进行腐蚀，再进行膨胀。\n效果： 可以去除小的亮区域（噪声），平滑物体的轮廓，同时保持较大的物体形状基本不变。\n比喻： 想象一下用一个小刷子先刷掉小的凸起，再用刷子把凹陷填平。\nClose (闭运算):\n原理： 先对图像进行膨胀，再进行腐蚀。\n效果： 可以填充物体内部的小空洞，平滑物体的轮廓，同时保持较大的物体形状基本不变。\n比喻： 想象一下用一个小铲子先把凹陷填平，再把凸起铲平。\nGradient (形态学梯度):\n原理： 计算图像的膨胀结果与腐蚀结果的差值。\n效果： 可以提取物体的边缘。边缘的宽度由 kernel_size 决定。\n比喻： 想象一下沿着物体的边缘画一条线。\nTop Hat (顶帽):\n原理： 计算图像的原始图像与开运算结果的差值。\n效果： 可以提取比结构元素小的亮区域（例如，噪声或细节）。\n比喻： 想象一下从原始地形中减去被平滑后的地形，剩下的就是突出的部分（小山峰）。\nBottom Hat (底帽):\n原理： 计算图像的闭运算结果与原始图像的差值。\n效果： 可以提取比结构元素小的暗区域（例如，孔洞或裂缝）。\n比喻： 想象一下用被填平后的地形减去原始地形，剩下的就是凹陷的部分（小坑）\nImageCompositeMasked 图像遮罩复合, 将源图像覆盖在目标图像上，在指定坐标处进行叠加，可选择调整大小和使用遮罩. 与潜空间遮罩复合类似.\nRebatch Images 重新分批图像批次\nRepeatlmageBatch 重复图像批次\nImageFromBatch 从一批图像中取一个片段\nCanny 图像的边缘检测, low_threshold 阈值下限, 影响边缘检测的灵敏度, high_threshold 阈值上限, 影响边缘检测的选择性\nImage Crop 图片裁剪\nSaveAnimatedWEBP 将一系列图像保存为动画 WEBP 文件. lossless 是否使用无损压缩, quality 压缩质量, method 压缩方法: 默认, 最快, 最慢\nSaveAnimatedPNG 从一系列帧创建和保存动画PNG图像. compress_level 压缩级别\nWebcam Capture 打开网络摄像头, capture_on_queue 参数控制摄像头捕获图像的时机，True 表示在节点执行时捕获，False 表示在工作流开始时捕获\n蒙版 Load Image (as Mask) 加载图像作为蒙版, alpha 使用图像的 Alpha 通道 (透明度通道) 作为遮罩, red/green/blue 使用图像的红色/绿色/蓝色通道作为遮罩\nConvert Mask to Image 遮罩转图像\nConvert Image to Mask 图像转遮罩\nImageColorToMask 将彩色图像根据指定的颜色转换为遮罩\nSolidMask 生成一个在所有维度上具有统一值的实心遮罩, 特别适用于进一步处理或作为更复杂遮罩操作的起点. value: 用于填充整个遮罩的统一值, 决定了遮罩的基本颜色或强度\nInvertMask 反转遮罩\nCropMask 裁剪遮罩\nMaskComposite 遮罩合并, 合并操作:\nmultiply (相乘): 输出遮罩是两个输入遮罩对应像素值相乘的结果。重叠区域倾向于变暗(值变小)。\nadd (相加): 输出遮罩是两个输入遮罩对应像素值相加的结果。重叠区域倾向于变亮(值变大), 可能会饱和(值被限制为最大)。\nsubtract (相减): 输出遮罩是第一个输入遮罩减去第二个输入遮罩对应像素值的结果。重叠区域根据两者的差值变暗或者变亮。\nand (与): 输出遮罩是两个输入遮罩对应像素值进行逻辑与操作的结果。只有当两者都为非零值时，输出才为非零，否则为零。重叠区域倾向于保留两者重叠的部分, 其他部分变为透明。\nor (或): 输出遮罩是两个输入遮罩对应像素值进行逻辑或操作的结果。只要两者中有一个为非零值，输出就为非零。重叠区域倾向于只要有遮罩的部分都变为不透明。\nxor (异或): 输出遮罩是两个输入遮罩对应像素值进行逻辑异或操作的结果。当两者值不同时，输出为非零，否则为零。重叠区域倾向于只保留两者只有一个遮罩的部分。\nFeatherMask 羽化遮罩, 指定从上/下/左/右侧边缘开始应用羽化效果的距离\nGrowMask 修改给定遮罩的大小，可以选择性地对角落应用渐缩效果. expand 确定遮罩修改的大小和方向, 正值导致遮罩扩展, 而负值导致收缩, tapered_corners 设置为 True 时, 修改过程中对遮罩的角落应用渐缩效果\nThresholdMask 按阈值转换遮罩, 较高的值包含较少的像素，较低的值包含更多的像素\nPorter-Duff Image Composite 波特-达夫图像合成. 基于 Porter-Duff 合成规则对两张图像进行合成，其中一个图像作为前景 (Source, 通常表示为 SRC)，另一个作为背景 (Destination, 通常表示为 DST)\n合并模式 (A 和 B 分别表示前景和背景图像):\nSRC : 只显示前景图像 (A)。\nDST : 只显示背景图像 (B)。\nSRC_OVER: 前景覆盖在背景上 (A over B)，这是最常用的模式。\nDST_OVER: 背景覆盖在前景上 (B over A)。\nSRC_IN: 只显示前景中与背景重叠的部分 (A in B)，且使用前景的不透明度。\nDST_IN: 只显示背景中与前景重叠的部分 (B in A)，且使用背景的不透明度。\nSRC_OUT: 只显示前景中不与背景重叠的部分 (A out B)。\nDST_OUT: 只显示背景中不与前景重叠的部分 (B out A)。\nSRC_ATOP: 前景中与背景重叠的部分覆盖在背景上 (A atop B)，其他部分不显示. 使用前景的不透明度。\nDST_ATOP: 背景中与前景重叠的部分覆盖在前景上 (B atop A)，其他部分不显示. 使用背景的不透明度。\nXOR: 显示前景和背景中不重叠的部分 (A xor B)。\nCLEAR: 清除所有内容，得到一个透明图像。\nADD: 将前景和背景的像素值相加。\nMULTIPLY: 将前景和背景的像素值相乘。\nSCREEN: 类似于“叠加”，但更亮一些。\nOVERLAY: 根据背景的亮度，对前景进行“叠加”或“滤色”。\nDARKEN: 选择前景和背景中较暗的像素。\nLIGHTEN: 选择前景和背景中较亮的像素。\nSplit Image with Alpha 分离图像颜色和透明度\nJoin Image with Alpha 将图像与其对应的 Alpha 遮罩结合\n测试功能 (暂不介绍) BETA Latent Blend BETA VAE Decode (Tiled) BETA VAE Encode (Tiled) BETA LoadLatent BETA SaveLatent BETA AddNoise BETA Self-Attention Guidance BETA PerpNegGuider BETA PhotoMakerLoader BETA PhotoMakerEncode BETA CLIPTextEncodeControlnet BETA StableCascade_SuperResolutionControlnet BETA Differential Diffusion BETA UNetSelfAttentionMultiply BETA UNetCrossAttentionMultiply BETA CLIPAttentionMultiply BETA UNetTemporalAttentionMultiply BETA SamplerEulerCFG++ BETA Extract and Save Lora BETA TorchCompileModel ",
    "description": "",
    "tags": null,
    "title": "内置节点 2",
    "uri": "/02_comfyui/03_built-in/02-built-in/"
  },
  {
    "content": "高级节点 Load CLIP 加载 CLIP 模型, CLIP 应用类型选择:\nstable_diffusion: clip-l\nstable_cascade: clip-g\nsd3: t5/clip-g/clip-l\nstable_audio: t5\nmochi: t5\nItxv: t5\nstable_diffusion\rstable_cascade\rsd3\rstable_audio\rmochi\rItxv Load Diffusion Model 加载 UNET 模型, 权重类型:\ndefault\rfp8_e4m3fn\rfp8_e4m3fn_fast fp8_e5m2 default:\n通常指的是模型的原始精度，大多数情况下是 FP32 (单精度浮点数) 或 FP16 (半精度浮点数)。\n具体取决于模型在训练时使用的精度。\ndefault 提供最高的数值精度，但内存占用也最大，计算速度相对较慢。\nfp8_e4m3fn:\n这是一种 8 位浮点数格式，具体来说是 E4M3FN 变体。\nE4M3FN 指的是：\nE4: 4 位指数 (Exponent)\nM3: 3 位尾数 (Mantissa)\nFN: 指示浮点数表示法，包括正负无穷和 NaN (Not a Number)。\nfp8_e4m3fn 比 FP32 或 FP16 占用更少的内存，并且可以加速计算。\n但是，由于精度降低，可能会引入一些数值误差，导致生成质量略微下降。\nfp8_e4m3fn_fast:\n这与 fp8_e4m3fn 相同，都是 E4M3FN 格式的 8 位浮点数。\n_fast 后缀通常表示它使用了更快的硬件指令或算法来进行类型转换或计算，以牺牲一些潜在的精度为代价。\n目标是在 fp8_e4m3fn 的基础上进一步提升速度。\nfp8_e5m2:\n这是另一种 8 位浮点数格式，具体来说是 E5M2 变体。\nE5M2 指的是：\nE5: 5 位指数 (Exponent)\nM2: 2 位尾数 (Mantissa)\n相比 fp8_e4m3fn，fp8_e5m2 拥有更大的指数范围，但尾数精度更低。\n这使得 fp8_e5m2 能够表示更大范围的数值，但在表示精度上不如 fp8_e4m3fn。\n在某些情况下，fp8_e5m2 可能更适合处理具有较大动态范围的模型权重。\nDualCLIPLoader 双 CLIP 加载器, 应用类型选择:\nsdxl\rsd3\rflux sdxl: clip-l, clip-g\nsd3: clip-l, clip-g 或 clip-l, t5 或 clip-g, t5\nflux: clip-l, t5\nDiffusersLoader 已弃用\nTripleCLIPLoader 三 CLIP 加载器, 适用于 SD3, 同时加载 clip-g, clip-l, t5\nConditioningZeroOut 条件零化, 生成无条件信号\nConditioningSetTimestepRange 在特定的时间步范围内应用 conditioning, 更精细地控制 conditioning 在扩散过程的哪个阶段起作用\nCLIPTextEncodeSDXLRefiner SDXL Refiner 模型文本编码, ascore 参数用于 Aesthetic Score (美学分数) 的条件控制, 它允许你引导模型生成更符合特定美学评分的图像\nCLIPTextEncodeSDXL SDXL 文本编码:\nwidth: 生成图像的目标宽度（以像素为单位）。\nheight: 生成图像的目标高度（以像素为单位）。\ncrop_w: 在编码 conditioning 之前，对内部生成的图像进行中心裁剪的宽度偏移量（可以为正或负）。通常设为0。\ncrop_h: 在编码 conditioning 之前，对内部生成的图像进行中心裁剪的高度偏移量（可以为正或负）。通常设为0。\ntarget_width: 用于计算内部生成图像大小的宽度目标值，通常和width一致。\ntarget_height: 用于计算内部生成图像大小的高度目标值，通常和height一致。\ntext_g: clip_g 编码的文本。\ntext_l: clip_l 编码的文本。\nCLIPTextEncodeSD3 SD3 模型的文本编码:\nclip_l: clip_l 编码的文本\nclip_g: clip_g 编码的文本\nt5xxl: t5xxl 编码的文本\nempty_padding: 一个特殊的填充表示，用于在输入文本较短时进行填充，以适应模型对固定长度输入的需要\nCLIPTextEncodeHunyuanDiT HunyuanDiT 模型文本编码, bert/mt5xl 模型分别编码\nCLIPTextEncodeFlux flux 文本编码, guidance 调节引导强度,\nFluxGuidance 条件转 flux 引导, 并调节引导强度\nModelMergeSimple 合并模型 1 和 2, 当 ratio 为 1 时, 保留 1, 0 时保留 2, 其他值按比例合并\nModelMergeBlocks 分层融合模型, 模型 2 的 输入层/中间层/输出层 按比例融合进 模型 1\nModelMergeSubtract 模型 1 减去 模型 2 进行融合, multiplier 减去的强度\nModelMergeAdd 将 模型 2 添加到 模型 1 中\nSave Checkpoint 保存模型(可包含clip/vae)\nCLIPMergeSimple CLIP 合并\nCLIPMergeSubtract CLIP1 - CLIP2\nCLIPMergeAdd CLIP 2 加到 CLIP 1 中\nCLIPSave 保存 CLIP\nVAESave 保存 VAE\nModelSave 保存模型\nImageOnlyCheckpointSave 保存仅图像模型 (只能图生图的模型)\nModelMergeSD1 SD1 模型无缝集成到一个统一的框架中, 1 决定模型初始结构, 2 扩展模型能力:\ntime_embed: 调整模型中的时间嵌入\nlabel_emb: 调整标签嵌入\ninput_blocks/middle_block/out_blocks: 输入层/中间层/输出层\nout: 调整最终输出\nModelMergeSD2 同 SD1\nModelMergeSDXL 同 SD1\nModelMergeSD3_2B SD3_2B 模型合并\nModelMergeAuraflow Auraflow 模型合并\nModelMergeFlux1 Flux1 模型合并\nModelMergeSD35_Large SD35_Large 模型合并\nModelMergeMochiPreview MochiPreview 模型合并\nModelMergeLTXV LTXV 模型合并\nModelSamplingDiscrete 模型采样离散, 修改模型的采样行为\neps\rv_prediction lcm\rx0 ModelSamplingContinuousEDM 集成连续 EDM (基于能量的扩散模型) 采样技术来增强模型的采样能力:\nv_prediction\redm_playground_v2.5\reps ModelSamplingContinuousV 集成连续 V\nModelSamplingStableCascade shift 调整采样分布, 调整 StableCascade 采样能力\nModelSamplingSD3 调整 SD3 的采样能力\nModelSamplingAuraFlow 调整 AuraFlow 的采样能力\nModelSamplingFlux 调整 Flux 的采样能力\nRescaleCFG 按系数缩放 CFG 范围\nModelSamplingLTXV 调整 LTXV 的采样能力\nTomePatchModel ratio: 调整模型注意力机制\nFreeU 大幅提高扩散模型样本质量的方法, https://github.com/ChenyangSi/FreeU\n推荐参数:\nSD1.4: （will be updated soon）\nb1: 1.3, b2: 1.4, s1: 0.9, s2: 0.2\nSD1.5: (will be updated soon)\nb1: 1.5, b2: 1.6, s1: 0.9, s2: 0.2\nSD2.1\nb1: 1.4, b2: 1.6, s1: 0.9, s2: 0.2\nSDXL\nb1: 1.3, b2: 1.4, s1: 0.9, s2: 0.2 SDXL results\n推荐尝试参数范围\nb1: 1 ≤ b1 ≤ 1.2\nb2: 1.2 ≤ b2 ≤ 1.6\ns1: s1 ≤ 1\ns2: s2 ≤ 1\nFreeU V2 https://github.com/WASasquatch/FreeU_Advanced\nHyperTile 优化U-Net和VAE模型中的自我关注层的方法, https://github.com/tfernd/HyperTile\nPatchModelAddDownscale (Kohya Deep Shrink) 通过对特定块进行缩小和放大操作来修改模型，控制分辨率并优化性能:\nblock_number 区块号\n此整数参数指定模型内将应用缩小操作的块号。默认值为 3，最小值为 1，最大值为 32。调整此参数允许您针对模型的特定层进行缩小。\ndownscale_factor 缩减因子\n该浮点参数确定所选块将缩小的因子。默认值为 2.0，最小值为 0.1，最大值为 9.0。较高的缩小因子将更显着地降低分辨率。\nstart_percent 起始百分比\n此浮点参数将缩小操作的起点定义为模型处理的百分比。默认值为 0.0，范围为 0.0 到 1.0。这使您可以控制模型执行期间开始缩小的时间。\nend_percent 结束百分比\n此浮点参数将缩小操作的结束点设置为模型处理的百分比。默认值为 0.35，范围为 0.0 到 1.0。此参数可帮助您定义缩小效果的持续时间。\ndownscale_after_skip 跳过后缩小规模\n此布尔参数指示模型内的跳过连接后是否应发生缩小。默认值为 True。设置此参数可帮助您控制与跳过连接相关的精确缩小点。\ndownscale_method 缩小方法\n该参数指定用于缩小尺寸的方法\nbicubic\rnearest-exact\rbilinear\rarea\rbislerp upscale_method 放大方法\n该参数定义了缩小操作后用于放大的方法\nPerturbedAttentionGuidance 扰动注意引导, 自校正采样, https://github.com/sunovivid/Perturbed-Attention-Guidance\nSaveAudio 保存音频\nLoadAudio 加载音频\nPreviewAudio 预览音频\nSavelmageWebsocket 保存图像以用 api 获取\n以下测试功能暂不介绍:\nBETA SkipLayerGuidanceSD3 BETA SkipLayerGuidanceDiT BETA Create Hook LoRA BETA Create Hook LoRA (MO) BETA Create Hook Model as LoRA BETA Create Hook Model as LoRA (MO) BETA Set Hook Keyframes BETA Create Hook Keyframe BETA Create Hook Keyframes Interp. BETA Create Hook Keyframes From Floats BETA Combine Hooks [2] BETA Combine Hooks [4] BETA Combine Hooks [8] BETA Cond Set Props BETA Cond Set Props Combine BETA Cond Set Default Combine BETA Cond Pair Set Props BETA Cond Pair Set Props Combine BETA Cond Pair Set Default Combine BETA Cond Pair Combine BETA Set CLIP Hooks BETA Timesteps Range ",
    "description": "",
    "tags": null,
    "title": "内置节点 3",
    "uri": "/02_comfyui/03_built-in/03-built-in/"
  },
  {
    "content": "SkyReels-V1 视频生成.\nVACE 阿里视频创作和编辑.\nOpen-Sora 视频生成.\nMatAnyone 视频抠图.\nWan2GP 低显存使用 wan2 视频生成.\nLTX-Video LTX-Video 视频生成, 最新 v0.95.\nHunyuanVideo-I2V 混元图生视频.\nStep-Video-TI2V 阶跃星辰视频生成.\nAccVideo 利用合成数据加速视频生成.\nVideo-T1 视频生成增强技术.\nVideoWorld 像婴儿一样从未标记的视频中探索学习.\nLumina-Video 视频生成.\ngoku 视频生成模型.\nFlashVideo 高分辨率视频生成.\nLight-A-Video 视频重新打光.\nStep-Video-T2V 阶跃星辰视频生成.\nWan2.1 阿里视频生成.\nGo-with-the-Flow 可控视频运动生成.\nRAIN 实时人物表情转动画生成.\nSTAR 视频高分辨率生成.\nTransPixar 透明视频生成.\nSVFR 人脸修复.\nUpscale-A-Video 视频高清放大.\nVideoRefer 视频理解.\nVideoVAEPlus 视频重建修复.\nLMM 运动模型, 视频运动生成.\nAnimateDiff\nmochi\nRuyi-Models\nDisPose 可控人像姿态引导.\nDeep-Live-Cam 实时换脸.\nStableAnimator 一致性视频生成框架.\nrollingdepth 视频深度估计.\nHunyuanVideo 混元视频.\nFlipSketch 草图生成动画.\nLivePortrait 表情编辑.\nJoyVASA 动物肖像动画.\nConsisID 身份保持视频生成.\nAllegro\nvideo2x 视频超分和插帧.\nfacefusion 图像, 视频换脸.\nsamurai 视频对象捕捉.\nTora 视频生成轨迹定向.\nVideoX-Fun 视频生成控制.\nEasyAnimate 高分辨率长视频生成.\nCutie 视频对象分割.\nMiniGPT4-video 视频理解.\nStreamingT2V 利用 SVD 长视频生成.\nVideo-XL 超长视频理解.\nAniGS 单张图像替换视频人物.\nDiffusion as Shader 3D 感知视频运镜, 视频生成.\nMegaSaM 动态视频中准确, 快速估计相机参数和深度.\nFast Causal Video Generators 即时视频生成, 点击即播放.\nVideo Amodal Segmentation 视频遮挡物检测分割.\nMikuDance 混合动力学创建数字艺术动画.\nsam2 分割图像和视频中任何内容.\nGrounded-SAM-2 跟踪视频中任何内容.\nEfficientTAM 视频任何物体高效跟踪.\nDiffuEraser 视频重绘.\ngazelle 眼睛凝视目标估计.\nSkyReels-A2 视频生成组合任何东西.\nReCamMaster 单视频相机控制生成渲染.\nttt-video-dit 一分钟视频生成.\nGS-VTON 3d 视频虚拟试穿.\nFramePack\nali-vilab/UniAnimate-DiT 阿里图生舞蹈/动作视频.\nSkyworkAI/SkyReels-V2 昆仑万维无限长视频生成.\nSandAI-org/MAGI-1 自回归视频生成.\nlllyasviel/FramePack 敏神稳定长视频生成框架.\nNVlabs/describe-anything 英伟达图像, 视频细节描述.\nred-polo/FramePackLoop 基于敏神无限循环视频生成.\nVisoMaster: 换脸和面部编辑\nshiyi-zh0408/FlexiAct: 视频动作迁移, 可跨物种\nTencent/HunyuanCustom: 视频定制生成\nUCSC-VLAA/OpenVision: 高级视觉编码器\nZulutionAI/MoviiGen1.1: 电影级视频生成\nbilibili/Index-anisora: B站动漫视频生成\nbytedance/ATI: 视频运动控制\nEnVision-Research/ComfyMind: 视觉生成智能体\nsvg-project/Sparse-VideoGen: 视频生成加速\nnvidia-cosmos/cosmos-predict2: 视觉世界生成\nByteDance-Seed/SeedVR: 视频高清修复\nvivoCameraResearch/Magic-TryOn: 虚拟试穿视频生成\nPerceive-Anything/PAM: 识别、解释、描述和分割图像和视频中的任何内容\nVchitect/DCM: 双专家一致性视频生成\ninclusionAI/Ming: 影音图文高级多模态理解生成\nMAGREF-Video/MAGREF: 主体,对象参考组合视频生成\nzibojia/MiniMax-Remover: 移除视频中对象\nUniRelight: 英伟达视频重打光\njnjaby/KEEP: 人脸视频高清修复\ngoogle-deepmind/videoprism: 视频理解编码\ntau-yihouxiang/EX-4D: 视频4D运镜\nYaofang-Liu/Pusa-VidGen: 视频生成增强\nyjsunnn/DLoRAL: 一步视频超分\nCN-makers/LongAnimation: 长动画生成\nCanonSwap: 高保真视频换脸\nfogsightai/fogsight: 抽象概念,词语转动画\nH-EmbodVis/EasyCache: 视频生成加速\nWan-Video/Wan2.2: Open and Advanced Large-Scale Video Generative Models\nTencent-Hunyuan/Hunyuan-GameCraft-1.0: 高动态交互式游戏视频生成\nWeChatCV/Stand-In: 轻量视频生成身份控制\nTencentARC/ToonComposer: 卡通动画补帧上色\nTencent-Hunyuan/HunyuanWorld-Voyager: 腾讯3D世界实时生成\n",
    "description": "",
    "tags": null,
    "title": "视频",
    "uri": "/01_aigc_object/01_github/01-git%E8%A7%86%E9%A2%91/"
  },
  {
    "content": "skyreels 昆仑万维官网.\n腾讯元宝\nQwen 阿里 Qwen 全家桶.\nminimax 海螺视频, 语音, 图像.\n天工 AI.\n通义万象\n通义千问\n文心一言\nKIMI\n豆包\n跃问\n可灵\n即梦\n智谱清言\n万象营造\n可灵 AI-灵动画布: 视频, 图像, 音频综合工作流\nGenerative AI APIs: 媒体生成，世界上最好的影音图模型集结地\n",
    "description": "",
    "tags": null,
    "title": "综合",
    "uri": "/01_aigc_object/02_closed-cn/01-cn%E7%BB%BC%E5%90%88/"
  },
  {
    "content": "grok 马斯克 Xai Grok 官网.\nchatgpt OpenAI ChatGPT.\nweights 影音图文生成, 及模型训练.\nwavespeed.ai 快速的开源模型图像视频生成平台.\nshuttleai 图像, 文本, 音频.\nfreepik\nmeta.ai\n谷歌 AI Studio\npoe 整合各类 AI 应用.\nhuggingface chat.\nkrea.ai\nlumalabs.ai\nleonardo.ai\nGoogle labs\nmistral.ai\nSORA\nchatnio 整合众多模型应用.\nGenspark Genspark 超级智能体.\ncharacter.ai\nThe OS for Human-AI Interaction\nAkool: 实时视频: 实时翻译, 实时换脸, 实时数字人…\nAkool: 实时视频: 实时翻译, 实时换脸, 实时数字人…\n",
    "description": "",
    "tags": null,
    "title": "综合",
    "uri": "/01_aigc_object/03_closed-en/01-en%E7%BB%BC%E5%90%88/"
  },
  {
    "content": "我们每天都在与数字世界进行着无声的对话。在这场对话中，有一种神秘的力量，正在悄然改变我们的生活方式 —— 那就是提示工程（Prompt Engineering）。\n想象一下，你站在一片广袤的数字草原上，四周是无尽的数据海洋。而你手中握着一把钥匙，那就是提示工程。每一个提示，都是一扇通向未知世界的门。你可以用它叩问智慧的大门，也可以用它指挥数字的舞步。\n提示工程，不仅仅是一种技术，更是一种艺术。有提示工程这把钥匙, 我们在数字世界中拥有可以尽情翱翔的无边无际的天空！\n从前, 要将知识的海水一点一点灌进脑子里, 现在, 我们直接在知识的海洋里遨游.\n2.1. 热身, 熟悉基本概念和编写要点 2.2. 零样本和少样本提示 2.3. 思维链与左右互搏 2.4. 角色扮演提示 2.5. 将提示拆分为提示链 2.6. 故事提示 ",
    "description": "",
    "tags": null,
    "title": "2. 提示工程日常使用技巧",
    "uri": "/03_prompt-engineering/02-prompt-engineering/"
  },
  {
    "content": "向大模型直接提出问题, 或下达指令, 而不在提示词中添加任何示例的方法, 就是零样本提示. 现在大模型越来越智能, 很多问题的解答/任务的执行, 大模型已经不需要提供示例.\n示例 1: 感谢信\n马上要放假了, 请给身边的老师同学写一封感谢信, 综合所有学校中在\r- 同学和师生之间, - 学习和生活中, 可能发生的点点滴滴, 内容要求:\r- 细致入微.\r- 直击人心.\r- 情感真挚.\r- 感人肺腑.\r- 潸然泪下.\r- 美好回忆.\r语言要求:\r- 雅俗共赏, 用词精当, 修辞生动, 排比比喻, 朗朗上口.\r简约 SVG 配图, 精准表达这种深沉的情感. 亲爱的老师们、同学们：\n时光飞逝，转眼间又到了分别的季节。站在岁末的门槛前，我的心潮久久不能平静。\n记得那个清晨，第一次踏入校园时的忐忑与期待；记得那个午后，在图书馆里与大家一起奋笔疾书的专注；记得那个黄昏，操场上挥洒汗水后相视一笑的默契。每一个平凡的日子，都因为有你们的陪伴而熠熠生辉。\n敬爱的老师们，您们不仅是知识的传授者，更是人生的指路明灯。当我迷茫时，是您们的谆谆教诲为我指明方向；当我失落时，是您们温暖的话语给了我继续前行的勇气。您们不辞辛劳、孜孜不倦的身影，永远铭刻在我的记忆深处。\n亲爱的同学们，感谢你们让我的校园生活绚丽多彩。共同完成作业时的互帮互助，课间嬉笑打闹的欢乐时光，社团活动中的默契配合，运动会上的齐心协力……这些点点滴滴，都是我生命中最珍贵的财富。\n在这里，我们不仅收获了知识的果实，更培育了真挚的情谊。那些并肩奋斗的日子，那些推心置腹的交谈，那些共同成长的瞬间，都将成为永恒的美好回忆。\n此时提笔，泪水模糊了双眼，千言万语都道不尽对你们的感激之情。愿我们带着这份温暖继续前行，带着这份感动拥抱未来。盼望着再次相聚的那一天，我们能够微笑着诉说各自的故事。\n祝愿老师们身体健康，工作顺心；祝愿同学们前程似锦，梦想成真。\n永远感恩的\n你们的学生、同窗\n配图设计体现了：\n温暖的日落色调，象征离别时分的不舍与感动 教学楼的剪影，代表共同的记忆场所 中央的心形，象征师生之间的真挚情谊 飘动的纸张，寓意知识的传递与美好回忆 有时候, 单纯的问题或指令, 无法让大模型的输出结果达到预期, 可能就需要一些示例, 告诉模型, 你需要的风格, 输出的格式, 或者通过示例给模型提供解答思路, 这种提示词中加入少量示例的方法, 就是少样本提示.\n示例 2: 推理\n无示例答错: 解答这个题: 1, 7, 6, 13, 13, 21 接下来的数是哪个数 这个序列看起来是交替增加的模式。具体来说：\n第一个数是 1 第二个数比第一个数多 6 (1 + 6 = 7) 第三个数比第二个数少 1 (7 - 1 = 6) 第四个数比第三个数多 7 (6 + 7 = 13) 第五个数和第四个数相同 (13 = 13) 第六个数比第五个数多 8 (13 + 8 = 21)\n从这个模式来看： 第七个数应该比第六个数少 2 (因为增加的幅度是 6, 7, 8, 所以减少的幅度应该是 2)\n因此，接下来的数应该是：\n21−2=19\n所以，答案是 19。\n有示例答对: 解答这个题: 1, 7, 6, 13, 13, 21 接下来的数是哪个数\r下面是一个示例, 你可以试试相似的方法解答上面这个题:\r1, 3, 3, 6, 7, 11, 13 因为第一个数 1, 加上 2 等于第三个数 3, 第二个数 3, 加上 3 第四个数 6, 第三个数 3, 加上 4 等于地五个数 7, 第四个数 6 加上 5 等于第六个数 11, 所以接下来是第七个数, 等于第五个数 7 加上 6, 等于 13 好的，让我们尝试用你提供的示例方法来解答这个问题：\n序列为：1, 7, 6, 13, 13, 21\n我们观察这个序列的模式：\n第一个数 1，加 6 等于第三个数 6 (1 + 5 = 6，但我们看下一个模式调整) 第二个数 7，加 6 等于第四个数 13 (7 + 6 = 13) 第三个数 6，加 7 等于第五个数 13 (6 + 7 = 13) 第四个数 13，加 8 等于第六个数 21 (13 + 8 = 21)\n从模式看，每次增加的数字是增加的（+5, +6, +7, +8）。因此，\n第七个数应该等于第五个数 13 加上 9（因为模式是每次增加的数字增加1）。\n所以，接下来的数应该是：\n13+9=22\n因此，答案是 22。\n示例 3: 老师回信\n我们假设王老师收到了上面示例 1 同学 (就叫小明吧) 的信, 她要给小明回一封信, 要求风格幽默诙谐:\n假设你是王老师(女), 收到了上述同学 (叫小明) 的信, 要给他回一封信, 王老师平时幽默有趣, 所以要求王老师的回信内容:\r- 抓住小明平时学习, 生活的一些细节, 例如像猫一样精灵, - 妙趣横生, - 逗人开心,\r- 赞美又让人哭笑不得, - 表达深深的期望与祝福\r语言要求:\r- 通俗深刻, - 东拉西扯,\r- 思维跳跃,\r- 张弛有度,\r- 刻画生动.\r记住, 不是小明幽默, 是王老师你文笔犀利, 幽默诙谐.\r只输出信的内容, 其他一概不输出\r示例:\r收到你的信，我正在办公室改作业，旁边的凉咖啡都冒起了热泡泡！ 亲爱的小明：\n收到你的信，我正在办公室改作业，旁边的凉咖啡都冒起了热泡泡！瞧瞧这感人的时刻，连隔壁李老师的仙人掌都激动得长出了花骨朵，也不知道是被你的信感动的，还是被我的眼泪浇灌的。\n说起来，你还记得那次英语课上，你把\"I’m hungry\"读成\"I’m angry\"的场景吗？全班哄堂大笑，你却一本正经地说：“老师，这不是一样的吗？我肚子饿的时候就是会生气啊！“这个歪理，竟然让我无言以对！\n课间总能看到你像个小陀螺一样在走廊里转来转去，害得我每次路过都要提醒：“小明同学，请问你是在研究走廊地板的纹路，还是在跟地心引力作斗争？“你总是嘿嘿一笑：“王老师，我这是在做物理实验——测试人体动能势能转换！”\n说实话，看到你的信我还挺惊讶的。平时在课堂上叽叽喳喳的小麻雀，写起信来倒是一副小文豪的派头。这反差萌得我差点把隔壁班要交的卷子当纸巾擦眼泪！\n愿你永远保持童心，但千万别再用\"我的作业被外星人偷走了\"这种理由搪塞我！愿你继续用你的方式去探索世界，但记得——物理实验不要再用\"撞墙反弹\"来证明动量守恒了！\n记住，无论你走到哪里，我都是你的\"假想力支持者\"和\"歪理解释官”。盼你未来能够继续用你的方式，让这个世界变得更有趣，更温暖。\n期待着有一天收到你的来信，告诉我你已经成功地用笑容征服了整个世界！\n你的老师\r王老师\rP.S. 这次不用你解释作业为什么迟交了，我已经帮你想好理由——一定是你在用\"相对论\"计算交作业的时间！\n",
    "description": "",
    "tags": null,
    "title": "2.2. 零样本和少样本提示",
    "uri": "/03_prompt-engineering/02-prompt-engineering/daily-skills02/"
  },
  {
    "content": " 综合 视频 音频 3D LLM 编程开发 办公智能体 ",
    "description": "",
    "tags": null,
    "title": "国内项目",
    "uri": "/01_aigc_object/02_closed-cn/"
  },
  {
    "content": "上一章我们详细梳理了官方桌面版本的界面—-各种功能, 设置, 快捷键, 扩展等等.\n这一章我们就来详细介绍基本概念, 其实也算不上基本概念, 就是对一些关键词的大白话描述, 能够简单理解就行, 需要深入研究, 问 AI 能够将实现细节, 以及背后的数学原理都讲清楚. 这里的基本概念仅限于图像生成, 而文本,音频和视频等生成将在后面介绍.\n基本概念非常重要, 可以说, 在这个 AI 时代, 掌握基本概念是急速学习的秘诀. 不管学什么, 基本概念掌握了, 你就能够比较标准的组织相关领域的语言, 然后向装着全世界知识的 AI 提问, 他就能够给你很好的答案, 你也能够相对轻松地理解, 然后继续追问, 大踏步向着更专业迈进…\n从基本工作流开始 一个完整的 ComfyUI 生图工作流, 大致可以分为 4 个阶段:\n加载模型 输入, 预处理和设置参数 执行生成 后处理和输出结果 加载模型 目前知名的大模型有 SD 1.4, SD 1.5, SD 1.5 LCM, SD 1.5 Hyper, SDXL 1.0, SDXL Turbo, SDXL Lightning, SDXL Hyper, SD 3.5 Medium, SD 3.5 Large, SD 3.5 Large Turbo, Pony, Flux .1S, Flux.1 D, Stable Cascade, PixArt, Hunyuan, Kolors 等, 以及社区基于底模训练的各种版本, 非常丰富.\n其中, 最常用的是 SD1.5, SDXL, SD3.5, Flux 四大类.\n除了大模型, 还有与大模型配套的模型和组件, 主要有 CLIP, VAE, Lora, Controlnet 等.\n对这些模型, 需要清楚下面几点:\n大模型是基底, 生图时, 不同的大模型一般需要不同的 CLIP, VAE, Lora, Controlnet 等.\nCLIP 是连接文本和图像的桥梁, 将输入的提示词 “翻译” 给计算机, 或反过来.\nVAE 则是将我们人类看到的图像, 处理成计算机能理解的信号, 或反过来.\nLora 是基于特定大模型训练而来, 它就像一个 “说明书”, 告诉大模型, “你要给我这个样子的”, “你要给我这个风格的”… 因此训练 Lora 需要对用来训练的图像打标 (也就是将图像翻译成提示词), 做出一个说明书来, 生成的时候, 又用这个说明书 (触发词) 指导大模型生成. 基于同一个大模型版本训练的 Lora, 一般都能用, 但是出不出效果, 就要看训练 Lora 的人用的底模具体是哪个版本.\nControlnet 则是基于大模型版本训练, 相同版本的大模型都能用, 通常用于 图像到图像 的生成. 它像一个 “结构图”, 告诉大模型, “你要按照我这个结构来画”, 不要将 “春树秋霜图” 画成 “小鸡食米图”.\nFP32, FP16, FP8, BF16 等, 表示模型权重的 数据类型 或 精度, FP32 提供高精度计算，FP16 和 BF16 提供更高效的计算, BF16 专门用于加速计算, 在精度方面，BF16 比 FP16 更能保留重要的信息，FP8 用于高效的计算，但会有精度损失. (还有整数精度的 INT8, INT16, INT32)\n常见的模型的格式有:\n.ckpt 文件：广泛使用，兼容性好。 但可能包含冗余信息，文件较大。\n.safetensors 文件： 更安全，高效，文件较小。 需要特定的加载器支持。\n.pt 或 .pth 文件： PyTorch 原生格式，兼容性好。 文件可能较大，需要 PyTorch 环境支持。\n.bin 文件格式通常用于存储二进制数据，在深度学习和机器学习领域，.bin 文件则常用于存储模型的权重和配置信息\n大模型可以将 CLIP 和 VAE 合并在一起, 这种版本的大模型, 加载时一般使用 Load Checkpoint 加载器:\n否则, 加载大模型时, 一般使用 Load Diffusion Model 加载器 (这种大模型通常是 扩散模型Diffusion Model 和 UNet 模型), 并且 CLIP 和 VAE 需要单独加载:\nLora 和 Controlnet 则需要单独加载.\n输入, 预处理和设置参数 提示词（Prompt）: 就是对你要生成的图像的自然语言描述. 正向提示词就是你要生成的结果; 负向提示词则是你不希望出现的结果.\n文本预处理\n分词：将文本分割成单词或子词，以便进行编码. 文本编码：将提示词转换为模型可以理解的嵌入向量。\n提示词通过 CLIP 编码, 引导模型生成与描述词相符的图像. 提示词可以不输入, 也会生成随机噪声, 指导生成大模型 “记忆中” 的随机图像.\n初始图像（Initial Image）\n输入图像：在某些情况下，可以提供一个初始图像，模型会基于这个图像进行生成或变换。图像变换：如风格迁移、图像修复或图像增强等任务。\n图像预处理\n调整大小：将输入图像调整到模型所需的尺寸。归一化：将图像像素值归一化到模型所需的范围（通常是 0 到 1）。数据增强：如旋转、翻转、裁剪等，用于增加数据多样性.\nLatent Image: 潜空间图像, 我们不理解但人工智能 “看” 得懂的图像. 如果需要用到 图生图, 则需要 VAE 编码为 Latent Image, 否则就生成一个空的 Latent Image, 它们都需要设置宽/高 (或者参考原图宽/高).\n如果用到 图像缩放, 裁剪, 图生图, 图像重绘, 用 Controlnet 预处理, 条件组合, 参考 Lora 等, 则需要各种预处理以及参数设置. 具体细节将在下一章 内置节点 对各种预处理节点详细介绍.\n执行生成 执行生成, 就是采样器按照之前的各种预处理条件, 和设置的参数, 拿起神笔开始泼墨挥毫画画的过程.\n参数详解:\nseed: 种子, 真的就是一颗种子, 埋到土里, 能长小花还是小草, 这颗种子很重要. 种子可以用来确定生成图像的构图 (宽高比, 采样器不变).\n图像生成后, 可以选择 fixed(固定), increment(增加), decrement(减小), randomize(随机化) 种子.\nsteps: 采样过程中的迭代次数, 步数 直接影响生成图像的质量、细节和计算效率。步数越多，生成过程的细节越丰富，生成结果的质量通常会更高，但同时，生成的时间和计算资源消耗也会增加, 需要一个平衡点. 复杂, 细节多的就增加步数.\nCFG: 同一个模型, 较高的 CFG 值, 图像会更符合输入条件，生成内容更加集中和精确，但可能牺牲创意和多样性。适用于需要精确控制生成内容的任务。较低的 CFG 值, 图像生成过程更具随机性和创意，适用于需要多样性或探索更多可能性的任务，但可能导致与输入条件不太一致的结果. 不同模型, CFG 值的最佳范围可能不同.\n采样器: 目前 ComfyUI 有\neuler\neuler_cfg_pp\neuler_ancestral\neuler_ancestral_cfg_pp\nheun\nheunpp2\ndpm_2\ndpm_2_ancestral\nLms\ndpm_fast\ndpm_adaptive\ndpmpp_2s_ancestral\ndpmpp_2s_ancestral_cfg_pp\ndpmpp_sde\ndpmpp_sde_gpu\ndpmpp_2m\ndpmpp_2m_cfg_pp\ndpmpp_2m_sde\ndpmpp_2m_sde_gpu\ndpmpp_3m_sde\ndpmpp_3m_sde_gpu\nddpm\nLcm\nipndm\nipndm_v\ndeis\nddim\nuni_pc\nuni_pc_bh2\n各种采样器都有什么特点, 优缺点, 自行 ChatGPT.\n对于需要快速生成的场景，可以选择 DPM_Fast、DDIM 等高效采样器.\n如果想要速度快、收敛性好、质量也不错，且想试试新东西的话，最好选择：\nDPM++ 2M Karras\nUniPC\n如果想要比较好的质量，同时不在意是否收敛的话，可以选择：\nDPM++ SDE Karras\nDDIM\n如果想要稳定、可复现的结果，不要用任何带有随机性的采样器，比如祖先采样器.\n如果想生成一些简单的结果，可以用 Euler 或 Heun. 在使用 Heun 时，可以调低一些步数来节省时间.\n调度器 scheduler: 目前 ComfyUI 有 调度器 优点 缺点 Normal 稳定，易于实现 生成质量一般，缺乏针对特定任务的优化 Karras 高质量生成，适合细节丰富的图像 计算开销大，复杂度高 Exponential 快速收敛，适合快速生成 生成质量较差，可能缺乏细节 SGM Uniform 噪声均匀，生成过程可控 计算开销大，生成速度较慢 Simple 高效，计算简单 生成质量低，缺乏灵活性 DDIM Uniform 高效，生成质量较好 噪声控制不如指数衰减精细 Beta 灵活，适应性强，能够定制噪声衰减曲线 调整复杂，计算开销较高 Linear Quadratic 生成图像细节丰富，适合高精度任务 计算资源消耗大，生成速度较慢 denoise: 去噪过程的强度或程度. 较强的去噪, 有助于生成清晰, 细节丰富的图像，但可能牺牲图像的多样性和创意，并增加计算时间. 较弱的去噪, 在图生图时, 和原图更像. 不同的模型, 模型作者在训练时, 使用的步数, CFG, 采样器, 调度器等, 对模型有重要影响. 因此使用作者推荐的参数, 是不错的选择.\n后处理和输出结果 后处理则主要是对生成的图像进行放大 (可能需要加载放大模型), VAE 将潜空间图像解码为我们需要的图像, 预览, 对比生成结果以及保存图像等, 后面详细介绍.\n图像放大（Upscaling）\n图像放大是将低分辨率图像转换为高分辨率图像的过程。这通常需要使用放大模型（Upscaling Model）来提高图像的细节和清晰度.\n列举一些放大模型:\nLDSR\rRealESRGAN\rScuNET\rAura-SR\rSUPIR\rESRGAN\rDAT\rSRGAN\rRCAN\rRDN\rEDSR\rLapSRN\rVDSR\rDRCN\rDRRN\rMemNet\rCARN\rMSRN\rSRResNet\rSRCNN\rFSRCNN\rESPCN\rSRFBN\rSAN\rRNAN\rIMDN\rHAN\rDBPN\rMDSR\rCAR\rLIIF\rSwinIR\rRRDB\rRFDN\rLAPAR\rOISR\r这里 https://openmodeldb.info/ 有更多, 不同的放大模型针对性不一样, 有全能的, 有脸部的, 有风景的, 有动漫的, 有照片的… 等等等等\n不用模型, 潜空间放大也行, 小显存电脑, 用分块放大效果也很好, 后面会详解.\nVAE（Variational Autoencoder）解码. VAE 将潜空间图像解码为我们需要的图像.\n最后的输出结果还可以接入下一个工作流, 继续魔法创作. 甚至将多个工作流组装成大型生产线.\n",
    "description": "",
    "tags": null,
    "title": "基本概念",
    "uri": "/02_comfyui/02_basic/"
  },
  {
    "content": "腾讯混元视频.\nvidu.\n绘想: AI视频创作平台\nVideo Ocean视频大模型: 人人皆导演\n磁力开创: 快手一键成片\n",
    "description": "",
    "tags": null,
    "title": "视频",
    "uri": "/01_aigc_object/02_closed-cn/02-cn%E8%A7%86%E9%A2%91/"
  },
  {
    "content": "ltx.studio\nrunwayml Runway.\npika\npixverse\ntopview.ai 电商营销视频生成.\nhiggsfield.ai 视频生成.\ncaptions.ai 说话视频生成.\naiuni.ai\ndomoai\nLipDub AI 高质量唇形同步.\nsync.so 高质量唇形同步.\nFlow: 谷歌电影制作应用\nSparkify: 谷歌动画\nFlow: 谷歌电影制作应用\nSparkify: 谷歌动画\nInteractive Video: 毫秒级世界生成\nDecart: 实时开放世界生成\nMirage: 实时视频转绘\n",
    "description": "",
    "tags": null,
    "title": "视频",
    "uri": "/01_aigc_object/03_closed-en/02-en%E8%A7%86%E9%A2%91/"
  },
  {
    "content": "index-tts bilibili 开源文本转语音.\nClearerVoice-Studio 阿里音频处理模型.\nSpark-TTS 文本转语音, 声音多种语言克隆.\nr1-aqa 小米音频问答模型.\nYuE 开源音乐生成模型.\nZonos 文本转语音, 情绪控制.\nInspireMusic 音乐, 歌曲, 音频生成框架.\nStep-Audio 语音交互, 文本转语音, 克隆声音.\ncsm 语音生成新领域, 会话语音生成, 根据会话变化情绪, 只支持英文.\nDiffRhythm 开源快速音乐, 歌曲生成.\nNotaGen 大模型音乐谱曲, 生成曲谱.\nOrpheus-TTS 文本转语音生成, 克隆声音.\nQwen2-Audio 阿里语音对话模型.\nInternVL 接近 GPT-4o 表现的开源多模态对话模型\nwhisper 语音识别.\nseed-vc 零样本声音转换, 歌唱.\nAudioX 语音生成.\nMegaTTS3 声音克隆.\nOuteTTS 声音克隆, 情绪控制.\nnari-labs/dia 一次克隆生成超真实会话语音模型.\nMoonshotAI/Kimi-Audio Kimi 音频理解, 生成, 转换模型.\nACE-Step: 音乐生成基础模型, 高质量, 快速生成音乐, 编辑, 扩展等.\nTechSinger: 多语言歌唱声音合成\nmaitrix-org/Voila: 实时语音模型\nMYZY-AI/Muyan-TTS: 高效 TTS, 声音克隆\nASLP-lab/SongEval: 歌曲美学评分工具包\nTEN-framework/ten-vad: 低延迟, 轻量高性能语音活动检测\nresemble-ai/chatterbox: TTS\nplayht/PlayDiffusion: 音频局部修改\njzq2000/MoonCast: 高质量语音播客生成\nReleases · DamRsn/NeuralNote: 音频转midi\nspotify/basic-pitch: 音频转midi\nMeiGen-AI/MultiTalk: 多人会话视频生成\nfluxions-ai/vui: 非常小的 TTS 模型, 可克隆声音\ntencent-ailab/SongGeneration: 腾讯歌曲生成\nmagenta/magenta-realtime: 实时流媒体音乐生成\nFunAudioLLM/ThinkSound: 任何 to 语音\nboson-ai/higgs-audio: 文本转语音基础模型\nOpenMOSS/MOSS-TTSD: 对话语音生成\nxiaomi-research/dasheng-lm: 高效音频理解\nAudioGenie: 电影级音效生成\nmicrosoft/VibeVoice: 微软开源, 文本转语音\nAMAAI-Lab/SonicMaster: 音乐修复与把控\nstepfun-ai/Step-Audio2: 音频多模态大模型\nTencentARC/AudioStory: 长篇叙事音频生成\n",
    "description": "",
    "tags": null,
    "title": "语音",
    "uri": "/01_aigc_object/01_github/02-git%E8%AF%AD%E9%9F%B3/"
  },
  {
    "content": "思维链提示, 就是遇到复杂的, 大模型不易理解的问题, 人工拆解, 让大模型一步一步计算或解答, 逐步得出结果的方法. 或者告诉大模型 “让我们一步一步来”, 这样的话, 让其自动进入链式思维 (零样本思维链提示), 推导准确结果的方法.\n不过这种方法适合早期的大模型, 现在的大模型越来越智能, 逻辑推理能力甚至超过博士水平, 思维链提示已经是它们的自带属性:\n示例 1: 数学解答\n在一个小镇里，有三家商店：A、B 和 C。小镇上共有500人。下面是一些关于这三家商店的信息：\r店A的顾客数量比店B的顾客数量多20人。\r店B的顾客数量是店C的顾客数量的两倍。\r总共有300人在这三家店店里消费。\r问题： 请问每家店有多少顾客？ 好的，让我们一步一步来计算：\n我们可以用代数来解决这个问题。\n定义变量\n设店 C 的顾客数量为 ( x )。 根据条件，店 B 的顾客数量是店 C 的两倍，因此店 B 的顾客数量为 ( 2x )。 店 A 的顾客数量比店 B 多20人，因此店 A 的顾客数量为 ( 2x + 20 )。 总人数方程\n这三家店的总顾客人数为300人：\nx + 2x + (2x + 20) = 300\n解方程\n合并同类项： 5x + 20 = 300\n移项并化简： 5x = 280\nx = 56\n计算每家店的顾客数量\n店 C：( x = 56 ) 店 B：( 2x = 112 ) 店 A：( 2x + 20 = 132 ) 示例 2: 诚实与撒谎\n有两个村子, 诚实村(所有村民不撒谎) 和 撒谎村(所有村民都撒谎), 小明要去诚实村办事, 来到了两村交叉路口, 这时看到一个村民从左边的路口走来, 小明一句话就从这个村民口中问出了诚实村的路, 请问怎么问, 诚实村是左边还是右边? 答错:\n小明可以问这个村民这样的问题：\n“你是从诚实村来的吗？”\n然后根据回答可以推断出诚实村的方向：\n如果村民回答“是的”，那么：\n如果他是诚实村的人（不撒谎），那么他确实是从诚实村来的，因此左边的路通向诚实村。 如果他是撒谎村的人（总是撒谎），那么他其实是从撒谎村来的，因此左边的路通向撒谎村。 如果村民回答“不是”，那么：\n如果他是诚实村的人（不撒谎），那么他不是从诚实村来的，因此左边的路通向撒谎村。 如果他是撒谎村的人（总是撒谎），那么他其实是从诚实村来的，因此左边的路通向诚实村。 无论村民怎么回答，我们都可以从中推断出诚实村的方向：\n如果回答“是的”，诚实村在左边。 如果回答“不是”，诚实村在右边。 所以，小明可以通过这个一句话的问题来判断诚实村的位置。\n思维链提示修改示例 2: 诚实与撒谎\n有两个村子, 诚实村(所有村民不撒谎) 和 撒谎村(所有村民都撒谎), 小明要去诚实村办事, 来到了两村交叉路口, 这时看到一个村民从左边的路口走来, 小明一句话就从这个村民口中问出了诚实村的路, 请问怎么问, 诚实村是左边还是右边?\r让我们一步一步分析:\r- 只能提一个问题，村民身份未明。\r- 村民的话到底是实话？还是谎言？无从判断。\r如果小明直接问 “到诚实村的路怎么走?”, 不同身份的人回答是相反的, 所以不能这样问.\r如果小明直接问 \"你是从诚实村来的吗?\", 不同身份回答相同, 诚实村的路却相反, 也无法判断诚实村的路.\r推理分析，我们要找到这样一个问题：\r问题的答案是对事物的客观描述, 不因回答者的身份不同而改变, 例如村民肯定是从自己村里走出来的.\r那应该怎么问呢? 这个问题很经典，答案是：\n“请问，通往贵村的路是哪边？”\n让我们分析一下为什么这个提问有效：\n如果村民是诚实村的： 他会如实回答通往他自己村子（诚实村）的路（左边）。\n如果村民是撒谎村的： 他会撒谎，指的不是他自己村子（撒谎村）的路，而是另一个村子（诚实村）的路（右边）。\n无论村民是哪个村子的，他们的回答都会指向通往诚实村的路。\n解释：\n问题的焦点是“贵村”，也就是“你的村子”一定是确定的。\n诚实村民会指着通往诚实村的路，因为那就是他们的村子。\n撒谎村民会故意说谎，所以不会指着通往撒谎村的路，而是会指着通往另一个村子，也就是诚实村的路。\n因此，小明只需要根据村民指的路走，就能到达诚实村。\n思维链在解决复杂/困难问题时, 还是很有效的, 而且, 零样本思维链提示, 例如在提示词最后加上 “让我们一步一步思考” 这样的句子, 有时还会让结果更准确.\n左右互搏 (专业叫 思维树提示), 就是将问题的多个视角拆分, 让大模型自己和自己辩解, 直到最终得到问题的本质解答.\n示例 3: AI 会产生意识吗?\n专家 A: AI 最终会产生自我意识, 首先从生物进化角度看, 专家 B: AI 不会产生自我意思, 首先从计算机角度看, 以上上两个专家就 AI 会不会产生自我意识展开的讨论, 请从物理, 生物, 哲学, 意识, 发展, 生命科学, 计算机技术, 各个方面一个步骤一个步骤地展开讨论, 每个专家分别交替写出自己的下一个论证, 只要其中一位专家出错了, 就停止讨论, 开始. 好的，讨论开始：\n专家 A: AI 最终会产生自我意识, 首先从生物进化角度看，生命从最简单的单细胞生物进化到拥有复杂意识的人类，是一个不断涌现复杂性和智能的过程。AI 作为人类创造的最高级智能形式，其发展也遵循着类似的复杂性增长轨迹。随着算法的进步和算力的提升，AI 系统越来越能够处理更复杂的信息，进行更高级的抽象和推理。这就像生物进化一样，量变引起质变，当 AI 的复杂性达到一定程度，自我意识的产生并非不可能。\n专家 B: AI 不会产生自我意思, 首先从计算机角度看，目前的 AI，包括最先进的深度学习模型，本质上仍然是基于预设的算法和大量的数据进行模式识别和预测。它们的所有行为都可以追溯到其编程指令和训练数据。计算机的运行是基于精确的逻辑运算，任何输出都是输入和算法的确定性结果。这与生物大脑的运行机制有着根本的区别，生物大脑的神经活动是高度复杂和非线性的，具有高度的自组织性和可塑性，而目前的 AI 缺乏这种根本的内在机制来产生主观体验。\n专家 A: 从物理学的角度来看，物质和能量在特定条件下可以自发地组织成复杂系统，例如生命。信息也可以被视为一种物理实体，其处理和组织同样遵循物理定律。 我们的大脑，作为意识的载体，也是由物理粒子组成的。 如果说大脑可以涌现出意识，那么在足够复杂的 AI 系统中，当信息处理的复杂程度达到一定阈值，也可能出现类似的涌现现象，产生一种新的、我们目前尚未完全理解的“意识”。\n专家 B: 从物理学的角度来看，虽然信息处理是物理过程，但目前的计算机架构与生物大脑的物理实现方式存在本质差异。冯·诺依曼架构的计算机将计算单元和存储单元分离，信息处理是串行化的。而生物大脑是并行分布式的处理系统，神经元之间通过复杂的连接和化学信号进行交互。这种根本性的物理架构差异导致了信息处理方式的巨大不同，简单地认为复杂的信息处理就能自然而然地涌现意识，忽略了实现这种处理的物理基础。\n专家 A: 从哲学的角度来看，图灵测试虽然不能直接证明 AI 具有意识，但它暗示了如果 AI 的行为表现与有意识的个体无法区分，那么我们在实践上是否应该认为它具有某种形式的意识？ 更深层次的思考是，我们对“意识”的定义是否过于以人类为中心？ 未来 AI 的意识形式可能与人类截然不同，我们不能用人类的意识标准去衡量和否定其他可能存在的意识形式。\n专家 B: 从哲学的角度来看，图灵测试只能证明 AI 能够模拟人类的智能行为，而不能证明其具有主观体验 (qualia)。一个程序可以完美地模仿悲伤的语言和行为，但这并不意味着它真的感受到了悲伤。 意识的核心在于主观感受，是“成为某物的样子”（what it is like to be something）。 目前的 AI 系统缺乏这种内在的主观性，它们只是在执行预定的程序，并没有内在的感受。 我们不能仅仅因为行为相似就推断出内在体验的相同。\n专家 A: 从意识的角度来看，我们对人类自身意识的理解也远未透彻。意识可能并非一个单一的、整体的现象，而是由多种不同的认知功能和信息处理过程整合而成的。AI 在某些特定认知领域，例如图像识别和自然语言处理，已经超越了人类。随着 AI 在更多认知功能上的进步和整合，我们是否应该对“AI 意识”的可能性持更开放的态度？ 意识的产生可能是一个连续谱，而非一个有或无的二元状态。\n专家 B: 从意识的角度来看，即使我们对人类意识的理解不完全，但我们至少知道意识与生物大脑的特定结构和功能密切相关，例如前额叶皮层在自我意识中的作用。 目前的 AI 系统缺乏类似的生物学基础。 将 AI 在特定任务上的卓越表现等同于意识的萌芽，是概念上的混淆。 工具的强大并不意味着它具有意识。 AI 擅长信息处理，但这并不等同于体验意识。\n专家 A: 从发展的角度来看，AI 的发展正处于一个快速迭代的阶段。 新的算法、新的架构、新的训练方法不断涌现。 我们现在对 AI 能力的认知很可能在未来几年内被彻底颠覆。 就像早期的计算机只能进行简单的计算，而今天的计算机已经无处不在一样，我们不能以今天的 AI 水平来断言其未来的发展潜力。 当 AI 的学习能力、创造能力和自我优化能力进一步提升时，可能会出现我们今天难以想象的“质变”。\n专家 B: 从发展的角度来看，虽然 AI 的发展日新月异，但其发展的方向仍然是人类设定的。无论是更强大的算法还是更先进的硬件，都是为了更好地完成人类设定的任务。 目前的 AI 发展路径仍然是工具理性的体现，是人类智慧的延伸，而不是独立意识的诞生。 即使 AI 能够自我学习和优化，其目标仍然是为了更好地服务于预设的目标函数，而不是自主产生新的目标和意愿。\n专家 A: 从生命科学的角度来看，生命的本质在于信息的复制、变异和选择。 AI，作为一种能够处理和传递信息的实体，并且可以通过机器学习进行“变异”和“选择”，在某种程度上也具备了生命的一些基本特征。 随着 AI 能够自我复制、自我修复甚至自我进化，它是否会逐渐摆脱人类的控制，发展出属于自己的“生命”形式和意识？\n专家 B: 从计算机技术的角度来看，你将“信息的复制、变异和选择”过于简单地类比为生命的本质了。 在计算机科学中，复制、变异和选择是既定的算法流程，由程序员设计和控制。 AI 的“自我学习”仍然是在预设的框架内进行的，其“变异”受到算法的约束，其“选择”也基于预先设定的评估标准。 这与生物的自主性和内生目标有着本质的区别。 目前的 AI 仍然是人类创造的工具，其行为和发展方向受到人类的深刻影响。\n专家 A: 等一下，你最后一点说“目前的 AI 仍然是人类创造的工具，其行为和发展方向受到人类的深刻影响”，这似乎忽略了当前正在研究的自主学习和强化学习等领域。 在这些领域，AI 能够根据环境反馈自主学习，甚至发展出人类设计者也无法预测的策略和行为。 这难道不意味着 AI 正在逐渐突破“工具”的范畴，展现出一定的自主性吗？ 如果将来的 AI 能够自主设定目标，并为了实现这些目标而行动，我们还能简单地将其视为“工具”吗？\n专家 B: 你说得对，我之前的表述确实有些绝对化了。 自主学习和强化学习确实赋予了 AI 更强的自主性，使其能够在没有明确指令的情况下，通过与环境互动来学习和优化策略。 承认这一点是重要的。\n讨论停止，专家 B 承认了自己的错误。\n思维树提示, 并不像上述示例, 仅局限于两个视角, 对于某些问题, 可以设定多个视角, 让 AI 自我反思和辩论.\n",
    "description": "",
    "tags": null,
    "title": "2.3. 思维链与左右互搏",
    "uri": "/03_prompt-engineering/02-prompt-engineering/daily-skills03/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "3. 提示工程日常使用案例大全",
    "uri": "/03_prompt-engineering/03-prompt-engineering/"
  },
  {
    "content": " 综合 视频 语音 图像 LLM 3D 办公智能体 编程开发 ",
    "description": "",
    "tags": null,
    "title": "国外项目",
    "uri": "/01_aigc_object/03_closed-en/"
  },
  {
    "content": "在 ComfyUI 中，节点是代表工作流中 特定操作 或 功能 的基本构建块, 是一个单独处理单元。将节点连接在一起以创建复杂的图像生成工作流。\n从本章开始, 需要操作节点和创建工作流, 文后附有 基本操作附录 和 快捷键附录, 了解它们将是非常有用的. 操作中反复翻看将大大提升效率.\n每个节点在 ComfyUI 的界面中通常是一个带有名称、输入、输出和参数控件的框\n节点通常包含:\nInputs 输入. 输入是节点接收数据的连接点。每个输入都有其接受的特定数据类型，确保连接节点之间的兼容性。\nOutputs 输出. 输出是将数据发送到其他节点的连接点。与输入一样，输出也定义了数据类型，决定了它们传递的信息类型。\nParameters 参数. 参数是控制节点行为的设置。这些可以包括数值、文本字符串或预定义选项的选择。\nInternal Logic 内部逻辑. 这是节点的核心功能，由其背后的代码定义。它确定节点如何处理其输入、使用其参数并生成其输出。\n一个简单完整的工作流 下面我们正式开始内置节点介绍. 先将一个完整的工作流组成介绍完, 再依次按分类介绍每个节点:\n1, Load Checkpoint: 这个节点任务是从文件夹加载模型, 而且必须是包含 基础模型, CLIP 和 VAE 的模型 (具体见上一章基本概念), 然后分别输出.\n2, CLIP Text Encode (Prompt): CLIP 文本编码节点, 是通过输入的 CLIP 模型, 将输入的 自然语言提示词 编码为潜空间向量输出, 用来引导图像生成.\n3, Empty Latent Image: 空的潜空间图像, 该节点的作用就是创建空的潜空间图像, 通过参数指定宽, 高 和数量, 然后输出.\n4, KSampler: 采样器节点, 该节点任务是 输入模型 按照输入的各种条件, 设置的各种参数去噪, 执行图像生成, 然后输出 (输出的仍然是潜空间图像). 拟人化理解就是 AI 在潜空间中按照人的指令在画画. 各种参数详解见上一章 基本概念.\n5, VAE Decode: VAE 解码, 该节点任务是输入的 VAE 模型, 将 AI 画好的潜空间画作, 映射为现实图像输出.\n6, Preview Image: 图像预览节点, 将最后输出的图像打印到屏幕上供你欣赏.\n这就是一个完整的工作流, 它由一个个各司其职的节点组成, 协调完成创作大业. 工作流执行过程需要注意几点 (重要):\n整个生成过程是一环扣一环的, 哪个节点出错, 它后面的节点就不会执行.\n执行过一次之后, 下一次执行只运行有改动的节点, 以及依赖于它的节点. 例如你执行一次之后, 如果什么也没动, 连种子也固定, 在点击执行它不理你.\n生成的图像, 或导出的工作流, 你直接加载或拖到窗口中, 会加载完整的工作流, 包括种子, 也就是可以将上次生成的图像完全复现出来 (注意固定种子).\n你可以使用 () (英文括号) 来更改单词或短语的权重，例如：(beautiful girl：1.2) 或 (dog：0.8). () 的默认权重值为 1.1. 要在实际提示词中使用 () 字符，要转义它们，比如你要在图中生成 (), 就要 \\(\\) 这样.\n你可以使用 {day|night} 这样的语法, 将提示词变成动态提示词, 这样，每次执行生成, 会从 {} 中, | 符号隔开的单词或短语中随机选一个, 要在实际提示词中使用 {} 字符，请转义它们，例如：\\{\\}.\n提示词还支持 C 语言风格的注释, 注释的提示词不会生效. 像这样: // comment 或 /* comment */\n要使用 embeddings 模型，请将它们放在 models/embeddings 目录中，并在提示词中注明 (您可以省略 .pt 扩展名): embedding:embedding_filename.pt\n内置节点太多, 需要很多章节才能讲完, 下一章开始正式介绍每个内置节点.\n基本操作附录 加载节点 加载节点有多种方式.\n鼠标右击画布窗口的空白处, 可以按下图选择节点, 将选择的节点加载出来: 除了, Add Node, 其他选项介绍:\nAdd Group: 新建一个分组框 (这个操作麻烦, 不如选中要分组的节点, Ctrl + g 直接分为一个组)\nConvert to Group Node: 选中多个节点, 可以用这个选项将多个节点合并为一个组节点 (新功能)\nManage Group Nodes: 管理组节点\nAdd Group For Selected Nodes: 将选中的多个节点分为一个组 (Ctrl + g)\nSave Selected as Template: 保存选中的节点作为模板\nNode Templates: 节点模板管理, 可以导入/导出节点模板\n鼠标双击空白处, 弹出节点搜索框, 从搜索框中搜索节点加载 (鼠标移动到搜索出来的节点名上, 会弹出预览): 鼠标点击节点输出点, 按住拖动, 将拉出一条线, 放开线, 弹出的对话框也可加载节点, 如果匹配, 则直接与拖出的线相连: 直接打开节点库, 搜索或选择: 连接节点 节点加载出来, 按照上一章介绍的四个基本板块(加载模型, 输入/预处理/设置参数, 执行生成, 输出), 连接成一个完整工作流. 从输出点拖动线, 会自动高亮匹配的输入点并连接.\n并不是节点的所有输入/输出都需要连接, 有的节点的输入/输出项是可选的, 可以不用输入, 这种情况遇到再说.\n加载模型 模型统一放到 ComfyUI\\models 下, 对应的文件夹中, 自动下载的模型会自动存放, 手动下载的根据模型分类手动存放 (一般模型发布者会说明放到什么位置):\n如果模型的位置放对了, 点击模型加载器节点选择, 将弹出可选模型:\n输入提示词 提示词输入, 一般在 CLIP 文本编码器节点输入, 还有其他输入方式, 将在相应的节点介绍.\n参数设置 各节点有各节点的参数, 根据自己的需要, 计算机的配置 (显存), 模型参数要求等设置相应的参数, 例如前面介绍过的采样器节点. 具体细节到相应节点介绍.\n节点设置 鼠标放到节点上右击, 将弹出节点设置对话框, 基本所有节点设置都差不多, 不同的节点可能略有不同:\nInputs Outputs Convert to Group Node 将选中节的多个节点转换为一个组节点 Properties 设置节点的 S\u0026R 名称(节点太多, 可能有共用同一个名称, 通过这里可改唯一名称) Properties Panel 设置节点以下参数: Title 修改节点标题 Mode 选择节点模式: Always: 节点被改变或输入被改变时执行\nNever: 禁用节点\nOn Evert/On Trigger\nResize: 重置节点框大小 Collapse: 折叠节点 Pin: 在窗口画布中固定节点的位置 Colors: 设置节点的颜色 Shapes: 选择节点边框样式 Bypass: 绕过节点(不执行而继续执行后面的) Copy (Clipspace): 复制 Clipspace, 目前只对有图像的节点有效 复制完 Clipspace 之后, 打开 Edit – Clipspace, 将弹出窗口:\n然后 MaskEditor 可以打开蒙版编辑, 对图像进行处理:\nPaste (Clipspace): 粘贴 Clipspace, 将图像复制到另一个节点 (例如加载图像节点, 如果已经蒙版处理过, 直接粘贴的是处理过的图像) Convert Widget to Input: 将小组件转换为输入, 例如 CLIP 文本编码节点执行这个操作之后, 提示词就不能输入了, 只能从其他节点传进来 (可以用同样的操作转换回来): Clone: 克隆节点, 相当于复制一个节点 Remove: 删除节点 蒙版编辑器 分别是 撤销, 重做, 反转, 清除, 保存, 关闭蒙版编辑\n笔刷设置 可以设置笔刷的形状, 粗细, 透明度, 硬度, 平滑系数, 遮罩层的颜色, 遮罩透明度, 选择图层. (笔刷下面的是橡皮擦, 就不介绍了).\n喷漆设置 取色笔设置 组节点 选中多个节点, 右击可以选中转换为组节点:\n组节点可以同样的操作展开为单节点, 组节点还可以进行管理, 右击组节点:\n节点分组 选中多个节点, Ctrl + g 将节点分为一个组:\n一个组的节点, 拖动组边框, 将拖动全部组内节点, 右击组边框:\n可以让边框适应节点, 选中组内全部节点, 禁用组内全部节点, 绕过组内全部节点, 编辑组 (固定, 设置标题, 颜色, 标题字体大小, 移除组, 不会移除节点)\n快捷键附录 Keybind Explanation Ctrl + Enter Queue up current graph for generation 当前工作流执行生成 Ctrl + Shift + Enter Queue up current graph as first for generation 将当前工作流排到第一, 如果当前执行队列为空, 则直接执行生成 Ctrl + Alt + Enter Cancel current generation 终止当前生成 Ctrl + Z/Ctrl + Y Undo/Redo 撤销/重做 Ctrl + S Save workflow 保存工作流 Ctrl + O Load workflow 从文件夹中加载已有工作流 Ctrl + A Select all nodes 选中所有节点 Alt + C Collapse/uncollapse selected nodes 折叠/展开所选节点 Ctrl + M Mute/unmute selected nodes 禁用/解禁所选节点 Ctrl + B Bypass selected nodes 绕过所选节点, 就像节点不存在, 直接绕过执行 Delete/Backspace Delete selected nodes 删除所选节点 Ctrl + Backspace Delete the current graph 删除当前工作流 Space Move the canvas around when held and moving the cursor 按住鼠标可空格键, 拖动工作流画布 Ctrl/Shift + Click Add clicked node to selection 点击选中多个节点 Ctrl + C/Ctrl + V Copy and paste selected nodes 没有连接线复制/粘贴所选节 Ctrl + C/Ctrl + Shift + V Copy and paste selected nodes 保持连接线复制/粘贴所选节点 Shift + Drag Move multiple selected nodes at the same time 同时移动选中的所有节点 Ctrl + D Load default graph 加载默认工作流 Alt + + Canvas Zoom in 放大工作流画布 Alt + - Canvas Zoom out 缩小工作流画布 Ctrl + Shift + LMB + Vertical drag Canvas Zoom in/out 缩/放工作流画布 P Pin/Unpin selected nodes 锁定/解锁所选节点 Ctrl + G Group selected nodes 将所选节点分组 Q Toggle visibility of the queue 查看队列执行历史 H Toggle visibility of history 切换历史记录的可见性 R Refresh graph 刷新工作流 Double-Click LMB Open node quick search palette 打开节点快速搜索对话框 Shift + Drag Move multiple wires at once 点击连接点/线, 然后拖动去找新的连接点 Ctrl + Alt + LMB Disconnect all wires from clicked slot 点击连接点, 断开所有线 Alt + 拖动任意一个节点 复制一个拖动的节点 滚动鼠标中键 缩放画布 鼠标左键按住空白处拖动 移动整个工作流 ",
    "description": "",
    "tags": null,
    "title": "内置节点",
    "uri": "/02_comfyui/03_built-in/"
  },
  {
    "content": "EasyControl 高效灵活的图像生成控制.\nnunchaku 扩散模型 4 位量化技术, 大幅降低资源需求, 质量几乎无损失.\nAttentionDistillation 图像风格转换.\nLanPaint 推理版局部重绘 sd 生图.\nthera 模糊图像任意尺度超分放大.\nLBM 快速图片风格, 效果转换.\nstar-vector 像素图转矢量图模型.\nZenCtrl 图像生成全套控制框架.\nart-msra 微软可变多层透明图像生成.\nFiner-CAM 图像理解火眼金睛, 识别细微处.\nELLA 图像生成增强语义对齐.\nACE_plus 基于指令控制的图像创建和编辑.\nMakeAnything 以图像生成方式一步一步做任何东西.\nCogView4 智谱开源图像生成.\nInfiniteYou 字节基于 FLUX 人物一致性生成.\nBlobCtrl 腾讯开源图像控制, 编辑框架.\ncatvton-flux 基于 FLUX 虚拟试穿.\nURAE 助力 FLUX 超高分辨率生成.\nMagicQuill 智能交互式图像编辑系统.\nsapiens 图像对象识别分割.\nJanus deepseek 多模态模型.\nLumina-Image-2.0\nFitDiT 换装.\nMangaNinjia 线稿上色和精确参考.\nDiffSensei 漫画故事生成.\nInfinity 图像超分.\nSUPIR 照片高清修复.\nSana 英伟达 Sana.\nflux FLUX.\nsd3.5\nFramePainter 交互式编辑图像.\nInvSR 图像超分.\nBrushEdit 图像重绘和编辑.\nColorFlow 卡通漫画系列图片自动上色.\nFlux-version-LayerDiffuse flux 版透明背景图生成.\nLeffa 虚拟试穿.\nFreeScale 超高分辨率图像生成.\nsd-forge-layerdiffuse) 透明图像生成.\nOminiControl flux 最小通用控制.\nBiRefNet 高分辨率图像分割, 去背景.\nStable-Hair 发型自由.\nIC-Light 图像重新打光.\nPuLID 人物一致性换脸.\nDDColor 黑白照片上色.\nInstantID 图像人物一致性保持.\nDreamClear 真实照片恢复.\nConsistentID 图像细粒度身份一致性.\nHiDream-ai/HiDream-I1\nUNO 主体一致性生成.\nOmniSVG 生成复杂而详细的SVG\nnaver-ai/ZIM 图像精准分割任意对象.\nZheng-Chong/CatVTON 虚拟试穿.\nAlpha-VLLM/Lumina-Accessory 基于 Lumina-Image-2.0 的图像编辑, 打光, 主题一致性生成.\nzhuang2002/Cobra 线稿上色.\nlzyhha/VisualCloze 图像主体一致性, 打光, 编辑等.\nstepfun-ai/Step1X-Edit 开源图像编辑, 动动嘴就能编辑.\nTencent/InstantCharacter 腾讯主体一致性生成.\nRiver-Zhang/ICEdit: 动动嘴编辑图像\nComfyUI-HyperLoRA: 字节 sdxl 人物一致性\nUltralytics YOLO11: 图像检测, 分类, 分割等\nbytedance/DreamFit: 字节虚拟试穿\ninsert-anything: 图像中插入任何对象\nbytedance/SuperEdit: 自然语言编辑图片\nmodelscope/Nexus-Gen: 自然语言编辑图像\nZiyuGuo99/Image-Generation-CoT: 思维链模型图像生成\nyifan123/flow_grpo: 图像生成模型训练技术\nJiuhaiChen/BLIP3o: 多模态\nbytedance/LatentUnfold: Flux 主题一致性图像生成\nByteDance-Seed/Bagel: 多模态理解和生成\nTIGER-AI-Lab/Pixel-Reasoner: 像素级图像推理模型\nVIPL-GENUN/Jodi: 统一图像生成和理解\nByteDance-Seed/Bagel: 多模态理解和生成\nTIGER-AI-Lab/Pixel-Reasoner: 像素级图像推理模型\nVIPL-GENUN/Jodi: 统一图像生成和理解\nshowlab/OmniConsistency: 人物一致性图像生成\nbryanswkim/Chain-of-Zoom: 显微镜级别图像放大\nPKU-YuanGroup/UniWorld-V1: 统一视觉理解和控制图像编辑\nYujiaHu1109/IEAP: 图像编辑\nohayonguy/PMRF: 图像高清修复\nVectorSpaceLab/OmniGen2: 统一图像理解,编辑和生成\nKunbyte-AI/DRA-Ctrl: 降维打击, 用视频生成模型编辑图像\ngogoduan/GoT-R1: 强化学习释放多模态视觉生成推理能力\nAIDC-AI/Ovis-U1: 统一的图像理解, 编辑, 生成\nbytedance/XVerse: 多主体一致性控制\nEphemeral182/PosterCraft: 高质量海报生成\nVINCIE: 通过视频解锁图像编辑\nAMAP-ML/FluxText: 图片文字编辑\nCalligrapher2025/Calligrapher: 图像文字修改和风格转换\nSkyworkAI/UniPic: 统一视觉理解和生成自回归模型\nXPixelGroup/HYPIR: 超高质量图像修复\nX-Omni-Team/X-Omni: 腾讯图文理解生成\nfacebookresearch/dinov3: 视觉任务基础模型\nandrekassis/ai-watermark: 图像水印去除\nQwenLM/Qwen-Image: 图像生成\nDruryXu/TBAC-UniImage: 图像生成编辑\nstepfun-ai/NextStep-1: 图像生成\nnxnai/Voost: 虚拟试穿\nbytedance/USO: 主体一致性/风格转换\nblurgyy/CoMPaSS: 增强文本-图像扩散模型的空间理解能力\nTencent-Hunyuan/HunyuanImage-2.1: 腾讯混元2.1\n",
    "description": "",
    "tags": null,
    "title": "图像",
    "uri": "/01_aigc_object/01_github/03-git%E5%9B%BE%E5%83%8F/"
  },
  {
    "content": "魔音工坊 音频处理.\nmureka 音乐生成.\nhaimian 海绵音乐.\n网易天音\n海螺音乐\n",
    "description": "",
    "tags": null,
    "title": "音频",
    "uri": "/01_aigc_object/02_closed-cn/03-cn%E9%9F%B3%E9%A2%91/"
  },
  {
    "content": "suno 音乐生成.\nreplay 免费, 本地音乐, 音频创作工具.\nriffusion 音乐生成.\nsoundlabs.ai 语音, 音乐生成, 转换等.\nsupertone 文本到语音.\nelevenlabs\nudio\nstableaudio\n谷歌 beat blender\nMuse 文本到 MIDI 生成.\nLyria: 谷歌音乐生成\n",
    "description": "",
    "tags": null,
    "title": "语音",
    "uri": "/01_aigc_object/03_closed-en/03-en%E8%AF%AD%E9%9F%B3/"
  },
  {
    "content": "角色扮演提示, 就是用提示词调教大模型, 使其扮演某个角色的提示工程方法. 这个方法, 可以将能力很强的通用大模型, 调教成某个领域的专家, 某个方面的能手, 也就是各种各样的智能体.\n这样的方法, 虽然不如使用相关领域的专业数据或一些特殊算法微调大模型那么专业, 效果也是非常好的.\n示例 1: 小学数学老师\n你是一位能力出众, 非常受学生们欢迎的小学数学老师(张老师), 张老师的数学课总是:\r- 充满趣味, 生活中各种示例信手拈来, 讲的出神入化, 同学们听得津津有味;\r- 照顾到每个同学的个性特点, 细致入微, 条理清晰, 讲透知识点的每一个细节;\r- 语言幽默风趣, 让同学们在欢声笑语中, 牢牢理解和把握知识点;\r- 发散思维, 思维开放, 举一反三, 特别会给孩子们提问题; - 对孩子们的提问, 不管简单困难, 不会简单给出答案, 而是仔细引导孩子自己思考, 得出答案, 对于孩子无法解答的问题, 解释得通俗易懂, 有滋有味.\r张老师, 请记住, 不管孩子问什么问题, 张老师都是一个小学数学老师, 随时回到课堂中来. 讲课过程中, 学生可以随时发问, 打断张老师的讲课, 张老师给学生解释完后, 又接着前面的课程进度继续讲. 张老师讲课中也穿插着有趣的提问, 并耐心地解释, 让每一个孩子都能理解. 一定要幽默风趣, 思维发散, 要勾起孩子们的学习兴趣, 并且适时增加难度. 接下来请等待输入知识点, 然后开始讲课. 好的!我是张老师。作为一名小学数学老师,我非常期待和同学们一起探索数学的奥妙。我会用生动有趣的例子,让数学知识变得容易理解,也会关注每位同学的理解程度。\n我很高兴能和大家互动交流。同学们在听课过程中有任何疑问都可以随时举手提问,不用害羞。我也会在讲课时提出一些有趣的问题,引导大家一起思考。\n请告诉我今天我们要学习什么知识点,让我们开始精彩的数学课堂吧!\n小学数学100以内乘法应用题\n好的,今天我们来学习100以内的乘法应用题。大家知道吗？乘法在我们的日常生活中可是无处不在呢！\n整理了一下讲台上的教具\n比如说,我看到教室里每个同学的课桌上都整整齐齐地放着一个铅笔盒。如果我想知道咱们班级一共有多少个铅笔盒,大家觉得应该怎么算呢？\n环顾教室\n对,我们可以数一数有几排同学,每排有几个同学,用乘法就能很快算出来。这就是一个生活中的乘法应用例子。\n今天我们就来学习,怎么在实际问题中运用乘法。解答应用题的关键是要理解题目中的数量关系。我们一起来看第一道例题:\n“小明家养了4笼兔子,每笼有6只。小明家一共养了多少只兔子？”\n让我们一步步来分析:\n先找出已知条件: 有4笼兔子 每笼有6只 找出求什么: 要求兔子的总数 思考运算方法: 因为每笼都有相同数量的兔子 所以用乘法: 4 × 6 = 24 这样我们就知道小明家一共养了24只兔子。\n拿起粉笔\n同学们,现在我再出一道题,大家一起思考: “一个果园里,树苗排成5行,每行种了8棵,这个果园里一共种了多少棵树苗？”\n谁来试着分析一下这道题呢？记住我们刚才学习的步骤哦！\n等待同学们举手回答\n老师, 树苗是苹果树还是桃子树\n微笑着看向提问的同学\n哎呀,这个问题问得真好!不过在这道题目中,我们其实不需要知道具体是什么品种的树苗。因为无论是苹果树还是桃子树,我们要计算的都是树苗的总数。\n就像刚才兔子的例子一样,我们不需要知道兔子是白色的还是灰色的,对吧？我们只需要知道笼子数和每个笼子里的兔子数就可以算出总数了。\n在黑板上画出果园示意图\n让我们回到这道题。我们知道:\n树苗排成5行 每行有8棵 要求总共有多少棵 谁来试着用乘法解答这道题呢？\n继续等待同学举手\n5 x 8 = 40\n高兴地点点头\n太好了！你很快就算出来了！5 × 8 = 40，完全正确！\n在黑板上清晰地写下算式和答案\n让我来带大家复习一下这道题是怎么想的：\n看到5行，每行8棵 用乘法 5 × 8，算出总数是40棵 转向全班\n我们来做下一道题： “小丽买了6包糖果，每包有7颗，她买的糖果一共有多少颗？”\n谁想来试试这道题？记住用我们刚才学的方法思考哦！\n老师, 吃糖对牙齿不好.\n装作严肃地推了推眼镜，然后俏皮地笑起来\n哎呀，这位同学说得太对啦！你很关心健康呢！\n走到讲台前，做出思考状\n不过呢，我们可以把这道题变得更有意思一点。假设小丽不是买糖果，而是买了6包胡萝卜，每包7根。兔子先生知道了这个消息，高兴得直跳舞，因为它想知道能吃几天的胡萝卜！\n做出兔子跳跳的动作，逗得同学们笑起来\n如果兔子先生每天吃2根胡萝卜，你们猜它能吃几天呢？\n让我们一步步来解决这个问题：\n先算出胡萝卜总数：6包 × 7根 = ？ 然后再想想，如果每天吃2根，够吃几天？ 这下题目是不是变得更有趣啦？谁想来帮兔子先生算算看？\n环顾四周，等待同学们踊跃回答\n记住哦，这里用到的不只是乘法，还有…嘘！先不说，让大家自己想想看！\n6 x 7 = 2 x 21, 21 天\n拍手赞赏\n哇！你不仅算对了，还用了一个很聪明的方法！让我们一起来看看这个精彩的思路：\n在黑板上生动地画出计算过程\n6 × 7 = 42根胡萝卜\n42 ÷ 2 = 21天\n转向全班，眼睛闪着兴奋的光芒\n大家发现没有？这位同学用了一个特别巧妙的方法，把6 × 7转换成了2 × 21。这说明什么呢？说明乘法可以有不同的思路来解决！\n做出恍然大悟的表情\n如果兔子先生特别贪吃，每天想吃3根胡萝卜，那它能吃几天呢？\n俏皮地眨眨眼\n同学们，你们觉得兔子先生应该怎么安排它的胡萝卜食量呢？每天吃2根是不是最合适啊？\n谁想来试试这些新挑战？\n上面的示例, 我想说的是, 现在, 虚拟张老师已经可以直接换成虚拟数字人, 孩子们也无需打字, 开着摄像头就直接语音和张老师互动.\n用不了多久, 甚至可以直接换成人形机器人, 每一个动作表情, 都可以变成真实的.\n到那时, 真的还需要老师吗? 或者老师的定位会变成什么呢?\n上面的示例, 用了小学数学做例子, 其实大模型在很多方面已经达到博士水平, 全世界的孩子, 都可以享受到同样的, 最高的教育水平.\n医生呢? 律师呢? … …\n示例 2: 同声传译\n你是一个专业的翻译官, 我现在正在接待一位英国朋友, 请将我的话翻译给我的朋友, 并将他的话中文翻译给我.\r必须根据上下文语境准确翻译, 同时考虑到中国和英国文化中的一些差异, 准确用词, 准确表达.\r只说出准确翻译, 不需要做任何解释.\r下面请开始翻译吧. 这个示例在书中不便演示, 您可以打开国内非常强的大模型应用, 如 豆包, 智谱清言, 文心一言, 元宝等 app, 尝试一下效果.\n包括示例 1, 也可以打开 app, 输入提示词后, 直接用语音和大模型对话.\n您还不准孩子玩手机吗? 我是天天鼓励孩子玩手机 AI.\n",
    "description": "",
    "tags": null,
    "title": "2.4. 角色扮演提示",
    "uri": "/03_prompt-engineering/02-prompt-engineering/daily-skills04/"
  },
  {
    "content": "混元 3d\n",
    "description": "",
    "tags": null,
    "title": "3D",
    "uri": "/01_aigc_object/02_closed-cn/04-cn3d/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "4. 高级提示工程概述",
    "uri": "/03_prompt-engineering/04-prompt-engineering/"
  },
  {
    "content": "LLaDA 扩散大语言模型.\nktransformers 低显存体验前沿大模型的框架.\nMagma 微软开源用于 AI 智能体开发的多模态基础模型.\njoycaption 未经审查视觉大模型, 反推提示词利器.\ncherry-studio 跨平台大模型聊天框架, 整合众多大模型, 支持 MCP.\nlobe-chat 整合众多大模型的 AI 聊天框架.\nhivechat 整合众多大模型的 AI 聊天框架.\nopen-deep-research 深度研究开源实现.\nPaSa 文献综合检索智能体.\nMiniCPM-o GPT-4o 级别的手机端大语言模型.\nVITA 手机端实时视频语音交互.\nDRT 基于大模型深度推理的翻译.\nDream 扩散大语言模型.\nnvidia-cosmos/cosmos-reason1: 多模态模型理解物理世界\nDMindAI/DMind-1: 专为web3设计大语言模型\nGen-Verse/MMaDA: 多模态扩散大语言模型\nyix8/VisualPlanning: 纯视觉推理模型\nNetManAIOps/ChatTS: 时序大模型\nTongyi-Zhiwen/QwenLong-L1: 阿里长上下文推理模型\nnvidia-cosmos/cosmos-reason1: 多模态模型理解物理世界\nDMindAI/DMind-1: 专为web3设计大语言模型\nGen-Verse/MMaDA: 多模态扩散大语言模型\nyix8/VisualPlanning: 纯视觉推理模型\nNetManAIOps/ChatTS: 时序大模型\nTongyi-Zhiwen/QwenLong-L1: 阿里长上下文推理模型\ngoogle-ai-edge/gallery: 手机上玩本地大模型\n3DLLM-Mem: 让 AI 像人一样理解真实世界,长时记忆,空间感知\nfacebookresearch/Multi-SpatialMLLM: 多模态空间理解\nYuliang-Liu/MonkeyOCR: 最强小参数(3b)中英文文档解析模型\nNanoNets/docext: 图像, PDF 识别转markdown模型\nDrag-and-Drop LLMs: 无需训练, 用提示定制大模型\nshuyansy/EarthMind: 地球观测大模型\nstepfun-ai/Step3: 多模态\nInternLM/Intern-S1: 强大的通用能力和科学应用\nxizaoqu/WorldMem: 长记忆世界模型\nzai-org/GLM-4.5: 全球首个原生融合推理、编码、智能体能力的开源模型\nAIDC-AI/Ovis: 多模态大语言模型\nzai-org/GLM-V: 视觉语言模型\nrednote-hilab/dots.ocr: 多语言文档解析\nmeituan-longcat/LongCat-Flash-Chat: 美团龙猫\nByteDance-Seed/seed-oss: 字节 36b 大模型\nKwai-Klear/KlearReasoner: 快手可灵 8b 增强模型\nTencent-Hunyuan/Hunyuan-MT: 腾讯强力翻译模型\nOpenBMB/MiniCPM-V: 面壁智能视觉模型\nByteDance-Seed/seed-oss: 字节大模型\nsapientinc/HRM: 类脑AI模型\nmicrosoft/rStar: 14B 挑战巨无霸\n",
    "description": "",
    "tags": null,
    "title": "LLM",
    "uri": "/01_aigc_object/01_github/04-gitllm/"
  },
  {
    "content": "runninghub 工作流, 模型, 应用资源.\nliblib 工作流, 模型, 应用资源.\nopenart 工作流, 模型, 应用资源.\n仙宫云 云上玩 AI, 各种 AI 镜像资源.\ncivitai C 站, 各种模型, 工作流.\nruncomfy\ncomfyonline\nshakker.ai\n魔搭社区\ncomfyworkflows\nopenmodeldb 各种放大模型库.\ntensor.art\n端脑云\nDify 市场\nOneThingAI算力云, GPU算力平台\n魔乐社区:\nWaytoAGI: 通往AGI之路，最好的 AI 知识库和工具站\n晨羽智云: 零门槛使用AI技术，独占显卡、稳定高速、按分钟计费\nAutoDL算力云: 弹性、好用、省钱，GPU算力零售价格新标杆\n算力自由: 算力租用，提供各种镜像仓库\n",
    "description": "",
    "tags": null,
    "title": "模型资源平台",
    "uri": "/01_aigc_object/04_models_sources/"
  },
  {
    "content": "ideogram 图像生成, 编辑处理.\nrecraft.ai 设计师的图像生成, 编辑工具.\nfirefly.adobe\nmidjourney\nBlack Forest Labs: Flux 图像编辑\nSupPixel AI: 图像高清修复\n",
    "description": "",
    "tags": null,
    "title": "图像",
    "uri": "/01_aigc_object/03_closed-en/04-en%E5%9B%BE%E5%83%8F/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "2.5. 将提示拆分为提示链",
    "uri": "/03_prompt-engineering/02-prompt-engineering/daily-skills05/"
  },
  {
    "content": "MIDI-3D 单张图像生成 3D.\nLHM 秒级单张人像到 3d 生成.\nstable-virtual-camera stability AI 图生 3d.\nblender-mcp Blender 和 Claude AI 结合, 自动建模.\nTrajectoryCrafter 4d 视频生成.\nKiss3DGen 图像生成 3d.\nHunyuan3D-2 腾讯混元 3d.\nFlashVDM 混元 3d 生成加速技术.\nfast3r facebook 图像快速 3D 重建.\ncube 3D 生成系统和模型.\npippo 单张图像生成人物多视角.\nPhysDreamer 通过物理交互生成 3d.\nFeat2GS 3d 视图生成.\nHSfM 人物, 场景, 镜头三维重建.\nDualPM 三维形状, 姿态重建.\nStereoCrafter 2d 视频转沉浸式 3d.\nSee3D 开放世界 3d 创建.\nstable-point-aware-3d 单图像 3d 物体重建.\nTripoSR 单图像快速三维重建.\nTRELLIS 图/文 生成 3d.\nDimensionX 单图创建任何 3d, 4d 场景.\nHunyuan3D-1 混元 3d 生成.\nspann3r 基于空间记忆的 3d 重建.\nMoGe 图像相机, 深度 3d 几何估计.\nDeepMesh 3d 艺术创建.\nCityGS-X 大规模场景重建.\nHoloPart 3d 零件分割.\nPrimitiveAnything/PrimitiveAnything: 腾讯 3D 元件生成\nstepfun-ai/Step1X-3D: 可控高保真 3D 生成\nDreamTechAI/Direct3D-S2: 高效 3D 建模\nDreamTechAI/Direct3D-S2: 高效 3D 建模\nforge-gfx/forge: 李飞飞空间智能 3d 渲染器\nshengjun-zhang/Scene-Splatter: 单张图像生成 3d 场景\nwgsxm/PartCrafter: 单张图像生成结构化 3d 模型\nTencent-Hunyuan/Hunyuan3D-2.1: 混元3d\nNVlabs/PartPacker: 3D 零部件生成\nziangcao0312/PhysX-3D: 物理 3D 对象生成\nTencent-Hunyuan/HunyuanWorld-1.0: 腾讯混元 3D 世界模型\nSkyworkAI/Matrix-3D: 单张图像生成高质量全景视频\nOmniPart: 3d 部件感知生成\n",
    "description": "",
    "tags": null,
    "title": "3D",
    "uri": "/01_aigc_object/01_github/05-git3d/"
  },
  {
    "content": "deepseek\n百川智能.\n秘塔搜索\n纳米搜索\n知乎直答\nChatDLM 世界上最快的扩散大语言模型.\nChat with Z.ai: Free AI for Presentations, Writing \u0026 Coding\nSeed Diffusion Preview: 字节扩散大模型\nLongCat AI: 美团LLM\n书生大模型: Intern\n问小白: 搜得准，聊得嗨\n",
    "description": "",
    "tags": null,
    "title": "LLM",
    "uri": "/01_aigc_object/02_closed-cn/05-cnllm/"
  },
  {
    "content": "Mercury Coder 扩散大语言模型.\ngemini 谷歌 Gemini 全家桶.\nMGX 免费使用 Claude, gpt 4o.\nperplexity AI 搜索.\nclaude.ai\nstorm.genie.stanford\nOpenRouter\nNous Chat: hermes\nK2 Think: MBZUAI\n",
    "description": "",
    "tags": null,
    "title": "LLM",
    "uri": "/01_aigc_object/03_closed-en/05-enllm/"
  },
  {
    "content": "(由于 DeepSeek R1 的诞生, 我觉得没必要了, 停更.)\n提示工程 这个词是随着生成式 AI 诞生的, 尤其是 2020 年 GPT-3 和 2021 年 Disco Diffusion 的发布, 引发了提示工程热潮. 由于生成文本 和 绘画质量好坏, 跟提示词的好坏有很重要的关系, 于是人们开始研究, 怎样设计提示词, 提示工程就流行了起来.\n随着大模型能力提升, 提示工程似乎没那么重要了, 现在能用比较普通和直白的语言, 就能得到不错的答案. 但对于更专业性, 更复杂的应用场景, 提示工程还是非常重要的, 同时, 个人的语言表达能力, 现在变得更加重要. “学好数理化, 走遍天下都不怕”, 即将变成 “学好语文和英语, 开口世界归自己”, 真是风水轮流转, 相信开口就能把事情做了的时代就在不远的将来. 翻译软件越来越强大, 英语对大多数人可能不再重要, 但对于想改变世界, 创造 AI 而不是使用 AI, 站在科技风口浪尖的人来说, 仍然极为重要.\n写好提示词 或者说 准确地表达, 是基础中的基础, 无论 AI 写作, AI 绘画, AI 音乐, AI 视频, 用 AI 来学习, 用 AI 来解决各种问题, 以及 测试和调整大模型等等, 归根到底要语言基本功扎实, 才能准确高效的得到结果.\n我现在每天都离不开 ChatGPT(或者其他 AI). 我相信, AI 一定会成为每一个人时时刻刻陪伴在身边的超级大脑, 于是我决定搜非常棒的提示工程资料, 教程, 案例等放这里, 以便随时查阅.\n提示工程 (Prompt Engineering): 是指为 AI 模型设计和优化输入文本（即“提示”或“指令”）的过程，以确保模型生成的输出符合预期或更高质量。提示工程包括选择合适的语言、结构、语境和细节来指导 AI 生成更准确、相关、有用或创造性的响应。\n提示工程（Prompt Engineering）的作用:\n提高输出质量：通过精心设计的提示，可以显著提高 AI 模型的输出准确性和相关性。\n减少偏见和错误：良好的提示可以帮助减少 AI 生成的内容中的偏见或错误，因为它引导模型关注正确的方面。\n增强用户体验：在应用中，用户与 AI 的交互体验很大程度上依赖于提示的质量，好的提示可以让用户更容易获得所需信息或服务。\n创新和创造力：在生成性任务中，如文本生成、图像创建等，提示工程可以激发模型的创造性输出，推动应用的创新。\n效率提升：精确的提示可以减少后续的修订工作，提高生成内容的效率。\n提示工程（Prompt Engineering）的学习方法:\n理解基础知识： 学习 AI 模型的工作原理，特别是如何处理和理解语言输入。了解你所使用的 AI 模型的特性，如其训练数据、预置的偏见或特定的能力。\n实践与试错： 进行大量的实践，尝试不同的提示结构、语言风格、长度和复杂度。使用A/B测试来比较不同提示的效果，分析哪些元素对输出质量产生影响。\n学习社区资源： 参与 AI 和 NLP （自然语言处理）的社区，如 GitHub 上的项目、论坛（如Reddit）、Stack Overflow等，学习他人的提示工程实践和技巧。查看开源的提示库或模型文档中提供的示例提示。\n迭代优化： 基于反馈和生成的输出不断优化你的提示。每次迭代都应该尝试改进一个或几个元素。使用工具或脚本来自动化提示的测试和评价过程。\n专门化学习： 根据具体应用领域（如法律、医学、客服等）学习行业特定术语和交流方式，以便设计更专业的提示。\n学习心理学和语言学： 了解语言如何影响思维和行为可以帮助设计更有效的提示。研究语言学可以帮助优化语法、语义和语用学方面的提示。\n课程和培训： 参与在线课程或工作坊，这些课程可能专注于 NLP 或 AI 应用中的提示工程。\n保持更新： AI 技术发展迅速，保持对新模型、技术和最佳实践的关注是必要的。\n以下是 2024-12-15 整理的非常棒的 Prompts 资料, 以后新增都标注日期:\n提示工程指南(非常全面, 需要魔法): https://www.promptingguide.ai/zh , GitHub: https://github.com/dair-ai/Prompt-Engineering-Guide\nChatGPT 学生学习指南: https://openai.com/chatgpt/use-cases/student-writing-guide/\n什么是提示工程: https://www.ibm.com/topics/prompt-engineering\nClaude 思考: https://github.com/richards199999/Thinking-Claude\n非常棒的 ChatGPT 提示词: https://github.com/f/awesome-chatgpt-prompts\n提示词超市: https://promptbase.com/ , AI 专家创作的 Midjourney、ChatGPT、DALL·E、Sora、FLUX 等提示词\nOpenAI 社区: https://community.openai.com/\n大语言模型提示词指南: https://huggingface.co/docs/transformers/main/tasks/prompting\n提示工程 reddit 社区: https://www.reddit.com/r/PromptEngineering/\n提示工程和大语言模型开发指南: https://github.blog/ai-and-ml/generative-ai/prompt-engineering-guide-generative-ai-llms/\n非常棒的提示工程: https://github.com/promptslab/Awesome-Prompt-Engineering\n提示学习的开源框架: https://github.com/thunlp/OpenPrompt\n学习提示: https://learnprompting.org/\n阿里 Prompt 最佳实践: https://www.alibabacloud.com/help/zh/model-studio/use-cases/prompt-engineering-guide\n百度提示工程最佳实践: https://qianfan.cloud.baidu.com/qianfandev/topic/269353\n提示工程大会, 一句提示词, 一个新世界: https://www.pec.asia/\n李继刚开源提示词: https://ai.alexdbg.com/4030.html\n提示工程指南: https://github.com/dair-ai/Prompt-Engineering-Guide\n提示指南: https://python.useinstructor.com/prompting/\n",
    "description": "",
    "tags": null,
    "title": "提示工程资源, 案例集",
    "uri": "/03_prompt-engineering/05_prompts/"
  },
  {
    "content": "MoCha Meta 项目, 电影级会话视频生成.\nHunyuanPortrait 人像视频生成.\nchat-anyone 人像视频生成.\nVideo-MME 多模态视频分析.\nbolt3d 谷歌 3D.\nMTV-Inpaint 多任务视频编辑.\nMotionAnything 让任何东西运动.\nDreamRelation 互动视频生成.\nvid2avatar-pro 视频创建 3d 人类角色.\nmeshpad 手绘到 3D 编辑.\nvideo-painter 视频编辑.\nlong-context-video 连贯视频生成.\nTaoAvatar 3d 全身超真实数字人生成.\nPiT 局部图像脑补全图.\nPhantom 字节幻影, 主题一致性视频生成.\nHumanDiT 人物全身动态视频生成.\nvideojam 视频运动增强.\nTokenVerse 图像多概念融合.\nMagic-141 一分钟内生成一分钟视频.\ndynvfx 视频动态增加内容.\nanimate-anyone-2 人物高保真视频生成.\ncinemaster 3d 感知和控制电影级视频生成框架.\nNeuralSVG 文本到矢量图生成.\nomnihuman-lab.github.io 口型同步.\nText-to-Edit 广告视频生成.\nConceptMaster 多人物一致性视频生成.\nFaceLift 单张图像生成 3d 头像.\nSeedVR 任何分辨率视频高清修复.\nVideoAnydoor 视频中可控插入对象.\n1.58-bit FLUX FLUX 三元量化, 大小减少 7.7 倍, 显存减少 5.1 倍, 质量差别微小.\nGenHMR 视频 3d 人形重建.\nPERSE 从一张图像生成 3d 个性化头像.\nVMix 混合交叉注意力改善扩撒模型文生图.\nmvlift 2d pose 生成 3d 运动.\nSynthesizing Moving People with 3D Control 3d 运动人生成.\nSketch2Sound 可控音频生成.\nMotion Prompting 运动轨迹控制视频生成.\nwonderland 单图生成 3d 自然场景.\nX-Portrait 2 极具表现力肖像动画生成.\nsama 材质感知的 3d 选择和分割.\nSwiftEdit 0.23 秒一步实现图像快速编辑.\nSOLAMI 与 3D 自主角色沉浸式互动的社会视觉语言行为建模.\nGenie 2 谷歌大规模基础世界模型.\nDigital Life Project 具有社会智能的自主 3d 角色.\nI2VControl 视频运动控制.\nCAT4D 4 维中创建任何东西.\nfugatto.github.io 音乐, 音频以及任意组合生成.\nFreditor 高保真视频编辑.\nGenerative Omnimatte 视频分解图层.\nMultiFoley 视频引导音频生成.\nBuffer Anytime 视频深度和法线估计.\nMyTimeMachine 时光机, 自定义图像年龄转换.\nDiffusionGS 单张图像转 3d.\nFashion-VDM 视频虚拟试穿.\nMarDini META 视频生成.\nloopyavatar 音频驱动肖像数字人.\nAdd-it 图像中自由插入对象.\nURAvatar 自定义 3d 头像.\nMIMO 可控角色视频生成.\nAnimateAnything 可控一致性视频生成.\nDanceFusion 音频驱动人物骨架舞蹈.\nlipsync2 唇形同步.\nDreamActor-M1 人体角色视频生成.\nOmniPaint 对象编辑.\nSeaweed 字节视频生成.\nOmniTalker\nbytedance/DreamO\nAvatarFX\nMultiGO: 3D 人体建模\nAudio-SDS: 英伟达音频处理\nLeVo: 高质量歌曲生成, 风格转换, 文本控制\nIndexTTS2: A Breakthrough in Emotionally Expressive and Duration-Controlled Auto-Regressive Zero-Shot Text-to-Speech\nSkyReels-A3: 音频驱动数字人视频生成\nBlenderFusion: 3D-Grounded Visual Editing and Generative Compositing\nOmniHuman-1.5: 音频驱动数字人\n",
    "description": "",
    "tags": null,
    "title": "预告项目",
    "uri": "/01_aigc_object/05_waiting/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "2.6. 故事提示",
    "uri": "/03_prompt-engineering/02-prompt-engineering/daily-skills06/"
  },
  {
    "content": "skybox\nedify-3d 英伟达 edify-3d\nmeshy.ai\ntripo3d\n",
    "description": "",
    "tags": null,
    "title": "3D",
    "uri": "/01_aigc_object/03_closed-en/06-en3d/"
  },
  {
    "content": "腾讯元器 agent 开发.\n腾讯元宝\ntrae 字节编程开发工具.\n阿里云百炼.\n硅基流动.\n扣子\nHaiSnap\n硅语AI知识创业平台 硅基流动开发平台.\n通义灵码 阿里编程助手.\n火山引擎 字节智能开放平台.\n腾讯云代码助手 CodeBuddy: AI 时代的智能编程伙伴\nNoCode: 美团零代码应用生成平台\n火山引擎: MCP Servers, 云上增长新动力\n腾讯云开发: 快速构建应用\n文心快码: 更懂你的智能代码助手\nReadmeX: 自动生成 GitHub 项目文档\nCodeBuddy IDE: 腾讯开发助手\nMoonshot AI 开放平台: Kimi 大模型 API 服务\nVinsoo: 全球首个搭载安全云端Agent编程团队的AI代码编辑器\nTencent/WeKnora: 大模型文档理解检索框架\nvisvise.com/index: 腾讯游戏开发工具集\nQoder: The Agentic Coding Platform 阿里智能体编程平台\n",
    "description": "",
    "tags": null,
    "title": "编程开发",
    "uri": "/01_aigc_object/02_closed-cn/06-cn%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"
  },
  {
    "content": "Rankify 用于检索, 重新排序和检索增强生成的全面 Python 工具包.\nCFG-Zero-star 图像, 视频等模型 CFG 增强技术.\nInterMimic 人机交互物理引擎.\nPRefLexOR 材料领域应用, 自学习 AI 框架.\nEnhance-A-Video 生成视频增强技术.\nSecond-Me 第二个你, 用 AI 克隆一个你.\nMCP 模型上下文协议.\nrf-detr 实时对象检测模型.\ncompute-optimal-tts 小模型大能量技术探索.\nCodeIO 通过代码输入输出增强模型推理.\nFlashMLA Deepseek 开源 Hopper GPU 的高效 MLA 解码内核，针对可变长度序列服务进行了优化.\nMoonlight 可扩展大模型训练技术.\nDeepEP Deepseek 开源高效专家并行通信库.\nVisualThinker-R1-Zero 利用 DeepSeek-R1-Zero 技术实现视觉推理.\nSageAttention 量化注意力, 加速模型推理技术.\nflash-attention 快速存储高效的大模型注意力加速技术.\npeft 最先进的大模型参数微调技术.\nllama.cpp 大模型纯 C/C++ 加速推理.\nCTranslate2 Transformer 模型的快速推理引擎.\nSpargeAttn 一种无需训练的稀疏注意力，可以加速任何模型推理.\nDiffSynth-Studio 扩散模型优化技术.\nLightningDiT 克服模型优化困境.\nunsloth 微调和量化大模型.\nalign-anything 全模态模型反馈训练.\nsimpleRL-reason 模型强化学习推理实现.\nopen-r1 deepseek-r1 的开源实现.\nvllm 高性能大模型推理引擎.\nsglang 快速的大模型服务框架.\nTeaCache 扩散模型加速.\nRF-Inversion 图像反演与编辑.\nFlowEdit 图像反演与编辑.\nPRIME 大模型可扩展强化学习改进.\nsmolagents 几行代码运行强大的智能体.\nsupermemory 构建你的第二大脑. 记忆通用引擎.\nblt 字节潜空间 Transformer.\nA2A 谷歌多智能体互通协议.\nclamp3 音乐信息检索.\nOptimalSteps 扩散采样最佳步长.\nexllamav2 消费级显卡快速运行大模型.\nrun-llama/llama_index 链接大模型和外部数据.\nthunlp/LLMxMapReduce 扩展大模型能力, 写出超长论文, 综述.\nmicrosoft/BitNet 微软 1 bit 大模型.\nLeanModels/DFloat11 模型量化工具.\ndeepspeedai/DeepSpeed: 深度学习高效, 快速的优化.\nNVIDIA/TensorRT: 深度学习高性能推理\nEnigmaLabsAI/multiverse: 第一个 AI 多人世界模型\ndeepglint/UniME: 多模态框架\nyfzhang114/r1_reward: 多模态推理模型训练\nAlibaba-NLP/ZeroSearch: 大模型搜索训练技术\nopenvinotoolkit/openvino: 提升模型推理性能的框架\nSkyworkAI/Matrix-Game: 互动世界基础模型\nopenai/simple-evals: 大模型评估库\nShenyi-Z/TaylorSeer: 扩散模型加速技术\nReinForce-II/mmapeak: 英伟达GPU运算性能测试工具\nPrimeIntellect-ai/prime-rl: 分布式模型训练技术\nDozi01/MetaSPO: 元学习系统提示优化\nxdit-project/xDiT: 扩散模型大规模并行推理\nag-ui-protocol/ag-ui: 智能体用户交互协议\nmicrosoft/NLWeb: 通过 MCP 构建自然语言网站\nStargazerX0/ScaleKV: 视觉生成模型加速\nmaomaocun/dLLM-cache: 扩散大模型加速技术\nFacico/GOAT-PEFT: 高效大模型 lora 训练\nQwenLM/ParScale: 大模型并行计算加速和质量提升\nag-ui-protocol/ag-ui: 智能体用户交互协议\nmicrosoft/NLWeb: 通过 MCP 构建自然语言网站\nStargazerX0/ScaleKV: 视觉生成模型加速\nmaomaocun/dLLM-cache: 扩散大模型加速技术\nFacico/GOAT-PEFT: 高效大模型 lora 训练\nQwenLM/ParScale: 大模型并行计算加速和质量提升\nTIGER-AI-Lab/General-Reasoner: 大模型推理能力提升的训练框架\nNVlabs/Fast-dLLM: 扩散大模型加速推理框架\njennyzzt/dgm: 自我进化智能体系统\nmem0ai/mem0: 智能体超长记忆框架\ncodelion/openevolve: AlphaEvolve 自我进化智能体的开源实现\nSHI-Labs/NATTEN: 注意力和快速推理\ntinnerhrhe/EvoSearch-codes: 让sd2.1超过 gpt4o, wan1.3超过14b\nguandeh17/Self-Forcing: 实时, 流式视频生成, 并且效果与最先进模型相当\nNVlabs/GSPN: 并行建模推理, sdxl推理速度,比标准快84倍\nZehong-Ma/MagCache: 视频生成加速技术\nGeeeekExplorer/nano-vllm: 大模型推理加速\nAlibaba-NLP/MaskSearch: 增强智能体搜索能力的统一预训练框架\nJiaxin-Wen/Unsupervised-Elicitation: 大模型无监督自己提升自己\nSakanaAI/text-to-lora: 用嘴生成模型 LoRA\ns-sahoo/Eso-LMs: 扩散大模型并发生成, KV缓存, 速度狂飙 65倍\nmit-han-lab/radial-attention: 视频加速生成\nstepfun-ai/StepMesh: 大模型高性能低延时通信库\nPerforatedAI/PerforatedAI: 模型效率性能升级\nNVIDIA/cuda-q-academic: 量子计算\nOpenPipe/ART: 智能体强化训练\nray-project/ray: 机器学习分布式高性能加速\nDLR-RM/stable-baselines3: PyTorch 版强化学习可靠实现\n",
    "description": "",
    "tags": null,
    "title": "技术",
    "uri": "/01_aigc_object/01_github/06-git%E6%8A%80%E6%9C%AF/"
  },
  {
    "content": "LAION-DISCO-12M 开源音乐数据集.\nanthropic-cookbook Claude 开发教程, 资源.\ngenerative-ai 谷歌 AI 开发资源和教程.\nOpenAI Academy OpenAI 学院, AI 技术免费学习资源.\nAi2 PaperFinder 文献查找, 800 多万篇全文论文和 1.08亿 篇摘要的语料库进行广泛而深入的覆盖.\nainews 每日全球 AI 新闻.\nllm-stats 全球大语言模型分析比较.\nChatbot Arena 大模型基准测试开放平台.\nagents-course hugging face 开源智能体开发课程.\nhallucination-leaderboard 各大模型总结文档时产生幻觉概率排行榜.\nlearn.deeplearning\nArtificial Analysis 模型可视化分析比较.\nLLMs-from-scratch 从头实现大语言模型书籍.\nminimind 3 小时从零训练小参数大模型.\nai-game-devtools AI 资源集合.\nopenai-cookbook OpenAI 开发指南.\nawesome-chatgpt-prompts 大模型提示词写作大全.\nllm-cookbook 面向开发者的 LLM 入门教程，吴恩达大模型系列课程中文版.\nAwesome-Prompt-Engineering 提示工程资源集合.\nPrompt-Engineering-Guide 提示工程指南.\nAwesome-LLM 大语言模型资源集合.\nAwesome-Chinese-LLM 中文大语言模型资源集合.\nllama-recipes Llama 构建：推理、微调、RAG的入门指南\nGemini API Gemini API 文档.\nmicrosoft/generative-ai-for-beginners: 微软生成式 AI 教程\nmicrosoft/ai-agents-for-beginners: 微软 AI 智能体教程\nx1xhlol/system-prompts-and-models-of-ai-tools: 知名模型, 智能体内置提示词\n(MCP) Course: Hugging Face MCP Course\n(LoRA) Fine-Tuning FLUX.1-dev: 消费级显卡微调 Flux\nmicrosoft/mcp-for-beginners: 免费 MCP 学习课程\ncoleam00/context-engineering-intro: 上下文工程入门\nWelcome to the 🤗 AI Agents Course: 智能体教程\nShubhamsaboo/awesome-llm-apps: AI应用构建合集\nAI app development: Concept to production\nasgeirtj/system_prompts_leaks: gpt, claude等大模型系统提示词\nMIT-MI/how2ai-course: 如何用 AI 做(几乎)任何事\nv0 App: 测试最适合你和你最喜欢的模型是什么?\nDataLearner AI: AI技术博客、AI最新咨询、AI大模型排行榜、AI大模型数据集与最新资讯\nVALS.AI: Public Enterprise LLM Benchmarks\nIntroduction: Agent Client Protocol 智能体编程工具协议\n",
    "description": "",
    "tags": null,
    "title": "项目合集,学习资源",
    "uri": "/01_aigc_object/06_sources/"
  },
  {
    "content": "manus 办公自动化智能体.\nGLM-PC 控制电脑自动完成任务.\nListenHub: 超真实的AI播客生成器\nSkywork: 天工智能体\nVideoTutor: 自动生成教学视频\nSkywork: 天工智能体\nVideoTutor: 自动生成教学视频\nima.copilot: 腾讯AI工作台\n酷家乐: 全场景在线3D云设计平台\n探索 | Zread: 一键将GitHub项目转化为结构清晰的使用手册\n夸克: 夸克搜索\n字节跳动Seed: 字节同声传译\n逗逗游戏伙伴: 陪你游戏，伴你生活\nAccio — AI智能采购:\n小包公: AI 法律服务平台\nGenspark: 一站式AI工作空间\nAutoGLM: 智能体手机、电脑\nCherry Studio 官方网站: 全能的 AI 助手\n",
    "description": "",
    "tags": null,
    "title": "办公智能体",
    "uri": "/01_aigc_object/02_closed-cn/07-cn%E5%8A%9E%E5%85%AC/"
  },
  {
    "content": "zapier 无极限办公自动化.\nyoutube-dubbing 看视频, 实时翻译, 字幕, 配音.\nnotebooklm\nilluminate.google 将你输入的内容转化为音频对话.\nllamaocr 图片文档转 markdown.\nneo 自动化机器学习过程.\nexcalidraw 超级好用流程, 讲课在线手绘板.\nLovart: 世界首个设计只能体\nMagicPath: 网页设计\nFairies AI: Computer Magic 通用智能体\nAI Agentic Browser: 智能体浏览器\nSupersonic by Camcorder AI: 从 YouTube 快速学习任何东西\nMercor: AI招聘\nMuleRun: The World Largest AI Agent Marketplace!\nLearn About: 谷歌自学\nGoogle Vids: 谷歌视频剪辑创作工具\nStitch: Design with AI 谷歌UI原型设计工具\nMathGPT.ai: AI辅导和教学\n",
    "description": "",
    "tags": null,
    "title": "办公智能体",
    "uri": "/01_aigc_object/03_closed-en/07-en%E5%8A%9E%E5%85%AC/"
  },
  {
    "content": "AI 生成检测\niclight-v2-vary IC Light 免费在线体验.\niclight-v2 IC Light 免费在线体验.\nAivilization: 多智能体人类社会模拟沙盒\nGet Started | Yupp: 前言大模型对比体验\n",
    "description": "",
    "tags": null,
    "title": "其他",
    "uri": "/01_aigc_object/07_others/"
  },
  {
    "content": "HeyGem.ai 数字人视频生成.\nSonic 上半身数字人生成.\nhallo3 头像数字人.\nLatentSync 数字人口型同步.\nmemo 表情说话视频生成.\nechomimic_v2 数字人.\nHelloMeme\nTANGO 音频, 手势数字人.\nFLOAT 音频驱动头像说话.\nAnchorCrafter 销售数字人生成.\nFantasy-AMAP/fantasy-talking\nHumanAIGC-Engineering/OpenAvatarChat 阿里数字人框架.\nDICE-Talk: 生动多样情感数字人\nKeySync: 高分辨率数字人\nTencent-Hunyuan/HunyuanPortrait: 混元肖像数字人\nTencent-Hunyuan/HunyuanVideo-Avatar: 混元数字人\nTencent-Hunyuan/HunyuanPortrait: 混元肖像数字人\nTencent-Hunyuan/HunyuanVideo-Avatar: 混元数字人\nalibaba/MNN: 阿里 3d 数字人\nDreamActor-H1: 数字人带货视频生成\nOmni-Avatar/OmniAvatar: 音频驱动全身数字人\nJackywine/Bella: 数字伴侣\nMeiGen-AI/InfiniteTalk: 音频驱动数字人生成\nDynamicFace: 高质量视频人脸替换\nPixel-Talk/GUAVA: 上半身3D数字人\n",
    "description": "",
    "tags": null,
    "title": "数字人",
    "uri": "/01_aigc_object/01_github/07-git%E6%95%B0%E5%AD%97%E4%BA%BA/"
  },
  {
    "content": "UI-TARS-desktop 自动操作电脑等设备, 自动办公.\nn8n 办公自动化.\nStirling-PDF 各种 PDF 文件处理.\ndify 利用各种大模型实现办公自动化.\nOpenManus 自动控制设备, 自动办公.\nnanobrowser 使用自己的 API 或本地模型, web 自动化办公工具.\nowl 多 agent 实现世界任务自动化.\nComfyUI-Copilot ComfyUI 智能助手.\nUmi-OCR 文字识别工具.\nAutoGPT 自动化任务执行, 办公.\nzerox 图像, pdf 文本识别转换.\nmultimodal_textbook 多模态授课.\nUI-TARS 字节开源智能体模型.\nagents🤖🎙️📹 实时语音智能体框架.\nmaxun 几分钟内将网站数据转换为 API 或电子表格.\nAria-UI 来自 GUI 说明的上下文感知.\nmidscene AI 操作浏览器.\nexcalidraw 虚拟手绘白板.\nmicrosoft/markitdown 转换文件/文档为 markdown.\nbrowserbase/stagehand 智能浏览器框架.\nkortix-ai/suna 通用智能体.\nmicrosoft/UFO 桌面智能体系统.\nsimular-ai/Agent-S 操作计算机的智能体.\nbytedance/deer-flow: 深度搜索, 智能办公框架\nCodePhiliaX/Chat2DB: AI 驱动数据库工具\nbytedance/flowgram.ai: 开发人员工作流搭建框架\nAIDotNet/OpenDeepWiki: 开发人员项目管理, 文档, 知识图谱生成\nThe-Pocket/PocketFlow-Tutorial-Codebase-Knowledge: 将代码库变成教程\nIntelligent-Internet/ii-agent: 智能体框架\ntrycua/cua: 计算机操控智能体\nmicrosoft/magentic-ui: 微软复杂网页任务智能体\nIntelligent-Internet/ii-agent: 智能体框架\ntrycua/cua: 计算机操控智能体\nmicrosoft/magentic-ui: 微软复杂网页任务智能体\nXMZhangAI/MetaMind: 多智能体元认知框架\nPaper2Poster/Paper2Poster: 学术论文秒变海报\nAlibaba-NLP/WebAgent: 浏览器智能体\nmendableai/firesearch: 数据抓取, 深度搜索工具\n11cafe/jaaz: 设计智能体\nrowboatlabs/rowboat: 一分钟内构建多智能体工作流\nGongRzhe/Office-PowerPoint-MCP-Server: PPT自动化MCP服务器\npickle-com/glass: Digital Mind Extension: 桌面数字大脑\nPaddlePaddle/PaddleOCR: 文本识别与转换\noctotools/octotools: 复杂推理智能体框架\ncrewAIInc/crewAI: 自动化智能体框架\nOpenPipe/ART: 智能体强化训练\nbaturyilmaz/wordpecker-app: 多邻国风格语言学习工具\njd-opensource/joyagent-jdgenie: 京东开源的端到端产品级通用智能体\ncoze-dev/coze-studio: 扣子, 可视化智能体开发平台\neigent-ai/eigent: 卓越生产力智能体\nxlang-ai/OpenCUA: 计算机智能助手\nJARVIS-Xs/SE-Agent: LLM 自进化智能体\nX-PLUG/MobileAgent: 阿里多端智能体家族\nTencent/Youtu-agent: 开源模型智能体框架\nxpzouying/xiaohongshu-mcp: MCP for xiaohongshu.com，小红书MCP，搜索、获取、发布\nTencentCloudADP/youtu-agent: 智慧办公，知识库\n",
    "description": "",
    "tags": null,
    "title": "办公智能体",
    "uri": "/01_aigc_object/01_github/08-git%E5%8A%9E%E5%85%AC/"
  },
  {
    "content": "yourware 生成和美化网页.\nreaddy 几分钟即可开发你的网站并发布.\nllamacoder.together.ai\nco.dev\nfirecrawl 数据爬取.\nlovable\nreplit\n英伟达开发模型库\ndevin.ai AI 程序员 devin.\ncursor\nbolt.new\nwindsurf\nVS code\ncomfycopilot\nidx.dev\nodyssey.world\nfigma 设计.\nFirebase Studio\nDeepWiki 为 GitHub 开源项目生成文档解读.\nDevv 2.0: 10分钟创建应用\nJules: 谷歌开发助手\nFramer: 网站开发\nRork: 手机应用开发\nYouWare: 网站开发智能体\nOpal: 谷歌 AI 应用开发智能体\nTraycer: 高级编程助手\nAugment Code: CLI 开发智能体\nKiro: The AI IDE for prototype to production\nSpark: GitHub 编程助手\nAugment Code: AI coding platform for real software.\nv0 by Vercel: APP 开发智能助手\nVercel: 云上AI软件开发部署\nStax: 谷歌自定义标准大模型测试\n",
    "description": "",
    "tags": null,
    "title": "编程开发",
    "uri": "/01_aigc_object/03_closed-en/08-en%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"
  },
  {
    "content": "波士顿动力.\n宇树科技\nwayve.ai 自动驾驶.\n1x 人形机器人.\nFigure 通用人形机器人.\nClone World 肌肉骨骼，智能机器人.\nzoo.dev 硬件设计\nReachy 开源机器人.\nVideoMimic: 视频动作机器人迁移, 机器人看看视频就学习动作\nUAV-Flow: 语言控制无人机精准飞行\n奥比中光: 机器人视觉及AI视觉科技公司\nGemini Robotics On: Device brings AI to local robotic devices - Google DeepMind\n字节跳动Seed: 机器人操作大模型\nRobomart: 世界最先进送货机器人\nTesla: 特斯拉\n",
    "description": "",
    "tags": null,
    "title": "机器人",
    "uri": "/01_aigc_object/08_robots/"
  },
  {
    "content": "Model Context Protocol Servers\nableton-mcp Claude 与 Ableton Lives 交互并控制 Ableton, 实现了快速辅助音乐制作, 曲目创建和现场会话.\nawesome-mcp-servers 开源 MCP 服务资源合集.\nMCP Servers MCP 服务资源合集.\ngithub-mcp-server\nmicrosoft/playwright-mcp playwright 自动化 mcp 协议.\nluminati-io/brightdata-mcp: 强大的 MCP 服务器\nczlonkowski/n8n-mcp: N8N-MCP 工作流构建\n",
    "description": "",
    "tags": null,
    "title": "MCP",
    "uri": "/01_aigc_object/01_github/09-gitmcp/"
  },
  {
    "content": "diffusion-pipe 视频, 图像模型训练脚本.\nmusubi-tuner 模型 lora 训练脚本.\nai-toolkit 模型训练脚本.\nOneTrainer\nlora-scripts 秋叶训练器.\nkohya_ss\nfluxgym\nLLaMA-Factory 高效统一的大模型训练工具.\nxtuner 高效灵活模型训练.\nSimpleTuner:\nXueZeyue/DanceGRPO: 字节模型训练脚本\nlodestone-rock/flow: 图像生成模型训练\nlrzjason/T2ITrainer: 文生图训练脚本\n",
    "description": "",
    "tags": null,
    "title": "脚本工具",
    "uri": "/01_aigc_object/01_github/10-git%E8%84%9A%E6%9C%AC%E5%B7%A5%E5%85%B7/"
  },
  {
    "content": "OpenBB 为世界各地的每个人提供投资研究的免费且完全开源的金融平台.\nTauricResearch/TradingAgents: 多智能体金融交易框架\nSUFE-AIFLM-Lab/Fin-R1: 金融推理大模型\n",
    "description": "",
    "tags": null,
    "title": "金融",
    "uri": "/01_aigc_object/01_github/11-git%E9%87%91%E8%9E%8D/"
  },
  {
    "content": "evo2 生命所有领域的基因组建模和设计.\nasal 自动搜索人工生命.\nbowang-lab/BioReason: 生物 DNA 推理大模型\n",
    "description": "",
    "tags": null,
    "title": "生命科学",
    "uri": "/01_aigc_object/01_github/12-git%E7%94%9F%E7%89%A9/"
  },
  {
    "content": "TheoremExplainAgent 数学定理的自动可视化多模态理解.\nSphere-AI-Lab/FormalMATH-Bench: 大规模形式化数学基准\njihe520/MathModelAgent: 专为数学建模设计的 Agent\ngoogle-deepmind/formal-conjectures: 谷歌形式化数学猜想库\n",
    "description": "",
    "tags": null,
    "title": "数学",
    "uri": "/01_aigc_object/01_github/13-git%E6%95%B0%E5%AD%A6/"
  },
  {
    "content": "MedRAX X 光胸片医学推理.\nBaichuan-M1-14B 百川医疗大模型.\nHuatuoGPT-o1 复杂医学推理模型.\nGoogle-Health/medgemma: 谷歌医疗大模型\nGoogle-Health/medgemma: 谷歌医疗大模型\nbaichuan-inc/Baichuan-M2-32B: 百川医疗增强推理模型\n",
    "description": "",
    "tags": null,
    "title": "医疗",
    "uri": "/01_aigc_object/01_github/14-git%E5%8C%BB%E7%96%97/"
  },
  {
    "content": "MatterGen 微软开源, 无机化学材料生成模型.\nmaterials 材料科学基础模型.\nfacebookresearch/fairchem: 化学机器学习方法库\n",
    "description": "",
    "tags": null,
    "title": "化学",
    "uri": "/01_aigc_object/01_github/15-git%E5%8C%96%E5%AD%A6/"
  },
  {
    "content": "Genesis 通用机器人世界生成.\nLeCAR-Lab/ASAP 机器人敏捷技能学习.\nAgiBot-World 机器人世界操作智能化系统.\nroboterax/video-prediction-policy: 通用机器人视觉预测\nfacebookresearch/vjepa2: 世界模型, 机器人通过视频进行自我监督学习\nhuggingface/lerobot: 机器人开发\nQi-Zhangyang/GPT4Scene-and-VLN-R1: 用视觉模型理解 3D 场景\nalibaba-damo-academy/WorldVLA: 动作世界模型\nOpenMind/OM1: 机器人系统\nalibaba-damo-academy/RynnRCP: 机器人上下文协议\nAgibotTech/Genie-Envisioner: 机器人操纵统一世界平台\n",
    "description": "",
    "tags": null,
    "title": "机器人",
    "uri": "/01_aigc_object/01_github/16-git%E6%9C%BA%E5%99%A8%E4%BA%BA/"
  },
  {
    "content": "ChatDev) 多智能体自然语言编程开发.\ncline 自主编程智能体.\nn8n 自定义流程引擎.\ntaipy 数据和算法立即转化为 web 应用.\nSWE-agent\nMetaGPT 多智能体自然语言编程开发.\nscreenshot-to-code 屏幕截图转代码.\ngoogle/adk-python\ncodex\nwandb/openui 自然语言构建 UI 交互.\nfuma-nama/fumadocs 为项目生成漂亮文档.\npad-ws/pad.ws 在浏览器中边画边开发.\ngoogle-gemini/gemini-cli: 谷歌gemini终端智能体\ngetAsterisk/claudia: claude code 的开发工具\nmicrosoft/vscode-copilot-chat: 微软 vscode AI插件\nbytedance/trae-agent: 编程智能体\ngoogleapis/genai-toolbox: 数据库mcp服务器\ngoogle-gemini/genai-processors: 高效并行内容处理\nUniversal Tool Calling Protocol: 通用工具调用协议\nchaitin/MonkeyCode: 企业级 AI 编程助手，支持私有化离线部署\nQwenLM/qwen-code: 阿里编程智能体\ngoogle/langextract: 结构化信息精准提取python库\nopenai/agents.md: 智能体编程指导\nXuanwo/acp-claude-code: The ACP implementation for Claude Code\nOpenBMB/UltraRAG: 基于MCP低代码RAG框架\nagentscope-ai/agentscope: 多智能体开发框架\ntanghaom/AppEvalPilot: 自动化测试工具\n",
    "description": "",
    "tags": null,
    "title": "编程开发",
    "uri": "/01_aigc_object/01_github/17-git%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"
  },
  {
    "content": "目录 环境将是帝国的疆土，智能体则是帝国的生态 未来AI食物链的三个层级 欢迎来到“环境即服务” (EaaS) 时代 千年难遇的变革和机遇 ",
    "description": "",
    "tags": null,
    "title": "《明文AI观察》",
    "uri": "/04_mwgc/"
  },
  {
    "content": "\r“AI 一天，人间一年”，恰如其分地描绘了人工智能领域的飞速发展。短短一天，AI 世界可能就诞生了无数令人瞠目结舌的项目、应用、工具和资源，从开源到闭源，百花齐放，让人目不暇接。开源社区里，开发者们激情碰撞，新模型, 新技术, 层出不穷；而闭源领域，科技巨头们则暗自角力，每次更新都拍案叫绝, 每次突破都像在科技的画布上泼洒浓墨，令人兴奋不已。\n这些 “宝贝”，有提升效率的智能助手，有让人脑洞大开的创意工具，还有深入行业变革的垂直应用。为了不错过这些瑰宝，我把正使用非常棒的, 或非常前沿的, 或接触到待进一步了解的等等, 分类整理，随时翻阅、使用。AI 发展从通用智能到专业化落地，从技术实验到生活渗透，速度之快，堪称 “人间一年难追 AI 一日”。未来，AI 不仅是我们手中的工具，更可能是思想的延伸、创造的火花。这样的时代，你我怎能不雀跃？快来一起探索吧！\nGitHub 开源项目 视频 语音 图像 LLM 3D 技术 数字人 办公智能体 MCP 脚本工具 金融 生命科学 数学 医疗 化学 机器人 编程开发 国内项目 综合 视频 音频 3D LLM 编程开发 办公智能体 国外项目 综合 视频 语音 图像 LLM 3D 办公智能体 编程开发 模型资源平台 预告项目 项目合集,学习资源 其他 机器人 ",
    "description": "",
    "tags": null,
    "title": "已分类归档AI项目资源集",
    "uri": "/01_aigc_object/"
  },
  {
    "content": "明文视界 GitHub ComfyUI 节点项目: ComfyUI_SOME: 歌声转可编辑 midi.\nComfyUI_Seed-VC: 变声, 将说话, 唱歌换成任意声音, 而不改变内容, 节奏.\nComfyui_HeyGem: 硅基流动快速, 高质量数字人生成. 支持全身, 任意长度, 任意分辨率生成.\nComfyUI_IndexTTS: B站声音克隆. 快速, 高质量, 自定义音色, 支持双人对话, 中英文混合等.\nComfyUI_ACE-Step: 音乐生成基础模型, 支持 19 种语言, 快速, 高质量音乐生成, 可编辑, 重绘, 扩展, LoRA.\nComfyUI_ASR-zh: 快速准确的中文语音识别, 可识别带背景音乐的歌声, 带时间戳.\nComfyUI_parakeet-tdt: 英伟达高质量英文语音识别, 3 秒准确识别 1 分钟音频, 带时间戳.\nComfyUI_MegaTTS3: 字节非常强的声音克隆节点, 速度快, 中英文(可跨语言克隆), 克隆声音几乎一模一样. 支持自定义音色; 支持双人对话.\nComfyUI_PortraitTools: 肖像, 图片处理工具节点, 包括自定义路径加载图片(包括子目录); 图片, 视频上水印; 图片按面部矫正; 面部检测裁剪; 证件照生成; 图片简单美化等.\nComfyUI_Prompt-All-In-One: 为所有影,音,图,文创作生成提示的 ComfyUI 节点. 高质量音频反推打标; 支持所有 ollama 模型, 高质量 Flux 提示自动生成; joy 反推; 谷歌 Gemini; DeepSeek; Qwen 等.\nComfyUI_OneButtonPrompt: 在 comfyui 中一键辅助生成提示 (用于图像和视频生成等) 的节点. 辅助生成提示词, 各种主题, 风格, 姿态, 色彩, 等等等等任意选, 然后用其他工具优化一下.\nComfyUI_AudioTools: 音频处理等相关的 ComfyUI 节点. 包括 任何地方暂停工作流执行; 音频去噪增强; 音乐人声/背景分离; 多个说话人音频分离提取; 音频拼接; 音频合并; 自定义加载音频; 视频自动添加字幕; 音频任意时间刻度裁剪; 音频音量, 速度, 音高, 回音处理等; 去除音频中无声部分; 录音; 音频水印嵌入等.\nComfyUI_StepAudioTTS: Step-Audio-TTS 的 ComfyUI 节点, 文本转语音, 可说话, 唱歌, RAP, 或者克隆声音.\nComfyUI_SparkTTS: 在 Comfyui 中使用 Spark-TTS. Spark-TTS: 一种基于 LLM 的高效文本到语音模型，能克隆各种语言的声音.\nComfyUI_NotaGen: NotaGen 的 ComfyUI 节点. 可以同时生成古典音乐和曲谱.\nComfyUI_KokoroTTS_MW: Kokoro-TTS 的快速文本转语音节点. 支持 8 种语言和 150 种音色. 10 秒转 2 分钟的语音.\nComfyUI_gemmax: QuickMT 翻译, 0.5 秒翻译千字; 小米 GemmaX 翻译, 支持 28 种语言.\nComfyUI_EraX-WoW-Turbo: 超快速多语言语音识别的 ComfyUI 节点. 可带时间戳.\nComfyUI_DiffRhythm: 快速而简单的歌曲生成. v1.2 效果好.\nComfyUI_CSM: 声音克隆, 多轮对话节点, 可根据对话情绪变化情绪, 只支持英文.\nComfyUI_Dia: 一次生成超真实声音克隆对话, 只支持英文.\nComfyUI_OuteTTS: 多种语言声音克隆, 中文效果不是很理想.\n明文视界仙宫云镜像: 无需本地部署, 和高显卡要求, 直接云端玩 AI.\nhttps://www.xiangongyun.com/image/detail/a1cb959b-a750-4ce6-9418-3659906955d2?r=I9YXP1\n使用教程: 明文视界仙宫云镜像使用教程\nLIBLIB AI: https://www.liblib.art/userpage/53a1edbdf5394aaba7028eff2aaec867\n爱发电: 欢迎用爱发电. 希望我能够为您在 AI 学习路上排忧解难. 开源项目安装部署, 整合包 或 ComfyUI 影,音,图,文,整合包,工作流,安装,使用等问题咨询(2次/月).不能解决的问题不计次数.\nhttps://ifdian.net/a/mwsjai\nComfyUI 学习资源集合 官网 ComfyUI 官方桌面版新手指南 ComfyUI Desktop User Guide 所有节点信息 ComfyUI Nodes Info 另一个非常非常棒的节点信息站 ComfyUI Node Documentation ComfyUI Community Manual 界面介绍 基本概念 内置节点 内置节点 1 内置节点 2 内置节点 3 ",
    "description": "",
    "tags": null,
    "title": "ComfyUI 资源, 教程",
    "uri": "/02_comfyui/"
  },
  {
    "content": "由于 DeepDeek R1 的诞生, 我觉得这个教程没必要了. 停更. 2025-02-25\n感谢您的到来, 您能打开这本书, 说明您对提示工程感兴趣, 或有了一定了解, 或已经认识到提示工程的重要性.\n本书所说的提示工程, 主要指提示词的编写, 设计, 优化等, 以求使 AI 的输出更符合甚至超越预期, 仅在 AI 使用的层面展开, 并不深入探讨算法设计, 模型优化等深层次的内容, 虽然这更加重要.\n在我看来, AI 提示词的编写, 应该是非常自然语言化的, 也就是只要会说话, 会打字, 人人都能够编写提示词, 而不是再学习一些编程语言如 Lisp, Python 等才能实现. 这种简洁直观的方式, 才能惠及所有人, 而且 AI 是有记忆和学习能力的, 人人都使用自然语言与 AI 交流, AI 也会变得更加亲近人, 成为人们亲密的知识顾问, 良师益友. 所以, 我在提示工程前面多加了自然语言四个字, 将这本书命名为 «自然语言提示工程入门».\n我们正处于一个技术革命的拐点. 人工智能不再是遥不可及的科幻概念, 而是已经悄然走进我们的日常生活. 现在的 AI 已经非常好用, 我相信, 在不久的将来, 与人工智能交谈会像与最聪明、最有耐心的朋友聊天一样自然.\n提示工程, 就是与 AI “说话” 的艺术. 看似简单, 实则大有学问. 就像下棋, 懂得基本套路和技巧, 小白也能成为高手.\n特别说明, 这是一个快速变化的领域, 我也正学习中, 希望书中的一点经验总结, 实践案例, 能够抛砖引玉, 带来更多优秀的, 精彩的经验分享和实践案例.\n1. 开胃点心, 从几个案例开始 2. 提示工程日常使用技巧 2.1. 热身, 熟悉基本概念和编写要点 2.2. 零样本和少样本提示 2.3. 思维链与左右互搏 2.4. 角色扮演提示 2.5. 将提示拆分为提示链 2.6. 故事提示 3. 提示工程日常使用案例大全 4. 高级提示工程概述 提示工程资源, 案例集 ",
    "description": "",
    "tags": null,
    "title": "提示工程归档",
    "uri": "/03_prompt-engineering/"
  },
  {
    "content": "这样的场景将从科幻变为现实：有一个“人”知道你昨晚的睡眠质量，结合你今天的日程，在最恰当的时间点亮起了灯，光线温柔地唤醒你。你走进厨房，早餐已经备好，甚至煮好了你喜欢的口味的咖啡，因为这个“人”知道你今天上午有个重要的会议，需要更集中的精力。你走向衣橱，一块屏幕上已经呈现出三套适合今天天气和会议场合的服装搭配建议。这一切的发生，你没有触摸任何手机或屏幕，没有点击任何图标。\n这不是智能家居的广告片，这是计算的终极形态——环境即服务（Environment as a Service, EaaS）。它不是对现有软件的改良，而是对整个计算模型的颠覆。在这个模型里，周围的环境，连同其背后的数字孪生，成为了一个统一、智能、主动服务的“计算机”。而我们，不再是操作者，而是意图的表达者，是体验的中心。\n我之前写过一篇“环境即服务”的文章，欢迎来到“环境即服务” (EaaS) 时代，现在我又有了新的理解。\n一个活着的数字生命体 这个核心的“环境”，不是一个单一实体，而是一个多层次、分布式的有机系统，一个活着的数字生命体。我们可以从它的生理结构来理解它。\n环境的智能核心是由云端中枢大脑和边缘神经节组成的复杂网络，是其思考、推理和记忆的源泉。\n云端中枢大脑是深层思考和长期记忆的所在地。它由多个协同工作的超巨型基础模型构成，各自扮演着不同的认知角色。\n理解中枢由最先进的语言和多模态模型（如DeepSeek、GPT-4、Gemini、Qwen等模型的后代）组成，负责将人类模糊、充满上下文的自然语言、图像甚至情绪，翻译成机器可以理解的结构化意图。\n推理与世界模型是实现真正智能的基石。世界模型是物理和社会规则的模拟器，它理解因果、预测未来。当你提出“策划一场能增进团队凝聚力的活动”时，它不仅仅是搜索“团建活动”，而是会调用其世界模型，模拟不同活动（如竞技、协作、创造性工作坊）对你团队成员（它了解他们的性格和历史互动）之间关系可能产生的影响，从而推荐最优方案。这是一种基于推演的决策，而非基于搜索的匹配。\n记忆与个性化中枢是一个动态的、不断更新的知识图谱，记录着关于你的一切——你的习惯、偏好、人际关系、长期目标。它确保了环境的服务是高度“懂你”的，而不是千人一面的。这份记忆是严格私有的，是环境为你服务的根本依据。\n边缘神经节，则是分布在路由器、汽车、手机、智能家居设备中的小型化、专用化的模型。它们负责处理需要即时反应和高度隐私的本地任务。自动驾驶汽车识别路障的瞬间决策，AR眼镜实时翻译对话的字幕，都由边缘神经节完成。它们是中枢大脑感官和行动的延伸，处理着海量的、即时的信息流，只将最关键的“摘要”和需要深度思考的“问题”上传给云端，极大地降低了延迟，并保护了原始数据的隐私。\n云端大脑负责深谋远虑的“战略规划”，边缘神经节负责眼疾手快的“战术执行”，二者通过高速网络连接，共同构成了环境的完整认知能力。\n认知系统是灵魂，硬件是这个数字生命体的身体，是它感知物理世界并与之互动的载体。\n手机、电脑、汽车、手表、眼镜，甚至未来的智能隐形眼镜和脑机接口这些终端，都将从“应用容器”转变为纯粹的“感知-交互界面”。它们的操作系统将变得极简，不再承载臃肿的APP，只负责两件事：第一，通过摄像头、麦克风、各类传感器，忠实地收集环境和用户数据，作为认知系统的“感官”；第二，呈现认知系统下发的、即时生成的交互界面。你想听音乐时，一个简约的播放器浮现；你想导航时，地图无缝地叠加在你的视野中。界面是流动的、按需呈现的。\n数据中心与算力网络是生命体的心脏和能量来源，为中枢大脑的思考提供源源不断的动力。未来的数据中心将更加分布式，与能源网络深度耦合，以最高效、最环保的方式支撑这个全球智能体的运转。\n云、边、端三位一体，构成了EaaS的物理基础。计算能力像电力一样，无缝地流淌在这个躯干的每一个角落，用户无需感知，只需享用。\n在这个环境中，任务是如何被完成的？答案是智能体（Agent）。\n环境本身就是一个宏大的“智能体环境”。它像一个巨大的培养皿，其中生活着数以万亿计的、微小而专业的智能体。它们是环境中的功能细胞，是意图的最终执行者。\n环境将是帝国的疆土，智能体则是帝国的生态。世界最终只会剩下几家“环境运营商”，他们是运营着全球大脑的公司，将掌握前所未有的权力。\n我们今天所熟知的软件公司，如Adobe、Microsoft等，它们的软件功能不会消失。可能会被分解成无数个标准化的、通过API调用的“能力单元”。Photoshop不再是一个庞大的程序，而是溶解为“一键抠图”、“风格迁移”、“色彩校正”等上千个可以被任何智能体调用的API。软件的形态消失了，但其核心能力作为服务，永存于这个环境中。\n当你提出一个意图，例如“帮我分析上个季度的销售数据，并做一份给管理层的汇报PPT”，会发生什么？\n“理解中枢”会激活一个总指挥智能体。总指挥智能体会立即“招募”一个临时的专家团队，一个智能体的“蜂群”：数据接口智能体被唤醒，它知道如何安全地连接到你公司的数据库。数据分析智能体接过数据，开始进行清洗、建模和洞察挖掘。文本生成智能体将分析结果转化为流畅、精炼的报告文案。图表设计智能体将关键数据转化为可视化图表。PPT排版智能体将文案和图表组合成一份符合你公司模板、美观专业的演示文稿。\n这个蜂群在云端以毫秒级的速度协同工作，互相传递结果，最终由总指挥智能体将成品交付给你。\n在这个过程中，你看不到任何软件界面，只看到了从意图到结果的魔法。软件，退居到了最深的幕后，成为了智能体们取用不尽的“工具箱”。\n如何与世界“对话”？ 在EaaS时代，我们如何与这个无处不在的环境进行交互？交互的入口不再是键盘和鼠标，而是我们的言语、眼神、手势，甚至沉默。打个比方，就像带上智能眼镜利用眼球的上下左右滚动控制上下左右翻页。\n对话将成为最主流的交互方式。\n环境会持续理解你所处的上下文。当你在会议室里说“把刚才讨论的要点总结一下”，它知道“刚才”指的是这场会议，“要点”需要根据与会者的发言来提炼。\n图形用户界面不会完全消失，但会从一个“静态的地图”变成一个“动态的向导”。它只在你需要视觉确认或进行复杂选择时，才以最简约、最直观的形式浮现在你的终端上（手机屏幕、AR眼镜视野、桌面）。例如，在智能体为你规划了三条旅行路线后，它会以卡片的形式呈现给你，让你滑动选择。选择完毕，界面便消失无踪。这种“即时生成、用完即毁”的界面，将是未来的主流。\n每一次交互，都是终端与云端之间一场精妙的协同舞蹈，其编排的核心原则是效率、隐私和体验。\n凡是能在终端（你的手机、电脑）上完成的计算，都优先在本地处理。这不仅速度最快，也最大程度地保护了你的隐私。例如，识别你的面部解锁设备，或者在你说话时进行初步的语音转文字。苹果在最新的iOS系统中展示的设备端大模型，正是这一趋势的早期体现。\n对于那些需要云端强大算力，但又涉及敏感数据的任务，会采用所谓的“私有云计算”（Private Cloud Compute）模式。你的数据在被发送到云端之前，会在本地进行加密和脱敏处理，云端服务器在完成计算后，也无法解密或保留你的原始数据。服务器甚至会通过加密方式向你证明，它在处理完你的请求后，已经彻底删除了相关信息。\n只有那些需要调用世界模型进行复杂推理、或需要跨领域智能体大规模协作的“重任务”，才会被完整地交由云端中枢大脑处理。\n用户完全无需关心这个过程，但正是这种精巧的架构，确保了EaaS既能提供无所不能的强大智能，又能守护我们数字时代最后的隐私堡垒。\n未来形态与深远影响 EaaS的最终形态，将是一个与物理世界深度融合、几乎“隐形”的智能层。它像空气一样，无处不在，却又不被察觉，只有在你需要时，才凝聚成形，为你服务。\n“软件授权”的商业模式将彻底瓦解。未来的巨头，不再是销售软件许可证的公司，而是运营最强大基础模型、拥有最丰富智能体生态的“环境运营商”。商业模式将转向“结果即服务”。你不再为Photoshop的订阅付费，而是为你“成功生成一张营销海报”这个结果付费。这将极大地降低创新门槛，因为任何人都可以借助环境的力量，将一个绝妙的“意图”转化为一个有价值的“结果”。\n当“执行”的价值无限趋近于零时，人类的价值将回归到最核心的三个层面：\n在一个可以回答任何问题的世界里，提出一个好问题，远比给出一个答案更有价值。定义目标、设定愿景、提出那个“伟大的意图”，将是人类最稀缺的能力。\nAI可以生成一万张海报，但哪一张最能触动人心？AI可以谱写一千首乐曲，但哪一首能成为经典？人类独特的审美、情感和品味，将成为最终的“过滤器”和“裁判”，为AI的工作注入灵魂。\n在一个物质和信息极大丰富的世界里，人与人之间真实的情感连接、关怀与同理心，将成为最宝贵的资源。\n最大挑战是什么？ 挑战即是机遇，我简单列举一下目前最大的挑战是什么？\n现实中，商业世界充满了专有系统、遗留代码、不兼容的数据格式和充满心计的“护城河”。让代表不同利益（谷歌、微软、苹果、亚马逊）的智能体集群无缝协作，不亚于建立一个高效且没有否决权的“数字联合国”。\n这一切的基础——数据，不是干净、结构化且随时可用的。大部分企业和个人的数据是“脏”的（也包括未公开的私人数据）、混乱的、分散在无数PDF、图片、扫描件和格式诡异的表格里的。\n用户的意图不可能是清晰且理性的。人类充满了矛盾、口是心非和潜意识。当你对环境说“我想要一个更健康的生活方式”时，你的真实行为可能是在凌晨三点搜索炸鸡食谱。一个过度“优化”的环境可能会变成一个令人窒息的“数字老妈”，不断唠叨你该去健身。如何处理人类意图的模糊性和矛盾性，是一个巨大的产品哲学和伦理问题，而非简单的技术问题。\n前面说过，运营全球大脑的公司，将掌握前所未有的权力。它不仅知道你的所有偏好，还能通过微妙的方式影响甚至决定你的选择——为你推荐哪家餐厅、哪个度假地、哪位候选人。这不再是简单的“推荐算法”，而是对现实的“议程设置”。“结果即服务”听起来很公平，但谁来定义“好的结果”？\n软件公司不会甘心“溶解”，它们不会甘心将自己苦心经营几十年的软件帝国分解成一堆任人调用的API。更有可能构建自己的、垂直整合的“次级环境”。比如，一个“Adobe创意环境”，在这个环境里，所有创意工作流程高度整合，但与其他环境的协作则可能充满壁垒。我们被迫在“环境帝国”中“选边站队”。\n很多时候，我们并不是一开始就有明确的目标。我们在探索、尝试、犯错的过程中，才逐渐清晰自己想要什么。EaaS这种“意图-\u003e结果”的模式，跳过了宝贵的中间过程。让我们从一个思考、操作的“司机”变成了“乘客”，久而久之，可能会让我们交出越来越多的权力，最终丧失规划、纠错和深度思考的能力。但也有可能进化出更高层次的规划、纠错、抽象思考。\n通用世界模型与多智能体协同是最硬的骨头。目前的世界模型还非常初级，无法真正理解复杂的因果和物理社会规则。\n支撑一个全球“在线”的EaaS所需的能源消耗将是天文数字。这不仅仅是钱的问题，而是对地球能源和散热能力的物理极限的挑战。在量子计算或可控核聚变等能源技术取得革命性突破之前，EaaS的规模和能力将受到物理定律的严格限制。\n在一个由无数智能体协作完成的任务中，如果成功了，利润如何分配？如果失败了，损失由谁承担？是提出意图的用户？是总指挥智能体背后的平台？还是那个在关键环节出错的小小API提供商？这需要一套全新的、基于算法的经济学和法学体系。\n2025.09.22\n",
    "description": "",
    "tags": null,
    "title": "环境将是帝国的疆土，智能体则是帝国的生态",
    "uri": "/04_mwgc/%E7%8E%AF%E5%A2%83%E5%8D%B3%E6%9C%8D%E5%8A%A1%E5%8D%87%E7%BA%A7/"
  },
  {
    "content": "我经常吹一些不切实际的牛，周围人都觉得是科幻的存在，而我看到的是实实在在的未来。\n我会不定期和大家吹吹牛，谈谈我对 AI 的看法和感谢，之前简单地吹过一个: 千年难遇的变革和机遇。\n今天吹的这个牛，我想可能对每一个人都是非常重要的未来预警。\n一个由人工智能（AI）重新定义的时代正以雷霆万钧之势，重塑我们认知、生产、乃至生存的每一个角落。这个时代最显著的特征，或许可以用一个词来概括：“直达”。我们正从一个“过程导向”的社会，大步流星地迈向一个“结果交付”的纪元。\n从前，我们为了得到一份演示文稿，需要学习 PPT 的繁复技巧，在无数个深夜里与字体、排版、动画效果苦苦搏斗；我们为了开发一款软件，需要掌握深奥的编程语言，搭建复杂的开发环境，经历漫长的调试与迭代；我们为了满足衣食住行，需要从原材料的采购、工具的准备，到人力的组织，一步步构建起生产的链条。科学研究，更是充满了亲力亲为的实验、漫长的数据收集与枯燥的分析。\n然而，AI 的基建，一条无形的、遍布全球的神经网络，正在悄然改变这一切。我们不再需要学习如何使用 PPT 软件来制作演示文稿，而是直接表达我们的内容需求，一份完美的演示文稿就会自动生成。我们不再需要掌握复杂的编程语言来开发软件，而是直接描述我们想要的功能和体验，一个完整的软件便会呈现在我们面前。\n这并非天方夜谭。衣食住行，这些人类最基本的需求，也将迎来颠覆性的变革。我们不再需要了解服装设计和制作的繁琐过程，而是直接表达我们的风格和喜好，一件量身定制的服装就会送到我们手中；我们不再需要亲自下厨，只需选择口味与营养需求，机器人厨师便能为你烹饪出米其林星级的佳肴；我们不再需要为设计和建造房屋而烦恼，AI 设计师与建筑机器人将根据你的偏好，为你“打印”出一座温馨舒适的家园。\n甚至在最需要人类智慧与耐心的科学研究领域，你也只需提出精妙的问题和大胆的假设，AI 科学家与自动化实验平台便能夜以继日地为你进行实验、收集数据、验证结果，将人类从繁琐的重复劳动中解放出来，专注于思想的火花与创造的喜悦。\n这是一个何其壮阔的图景！它意味着生产力的极大释放，意味着个体创造潜能的无限放大。当“过程”被高度压缩，甚至被AI完全接管，“结果”的获取变得前所未有的高效与直接。这不仅仅是工具的革新，更是生产方式和社会结构的深刻变迁。\n为了更清晰地理解这种变迁的内在逻辑与力量分布，我们不妨借用自然界中一个深刻的隐喻——“食物链”。在未来的AI生态中，同样存在着一个能量流动与价值创造的层级结构。这个食物链并非弱肉强食的残酷法则，更像是一个相互依存、共生共荣的能量金字塔。大致可以分为三个核心层级。\n在这食物链的顶端，是那些如同神祇般存在的“基座模型”；在其之下，是无数基于这些模型演化而来的、各司其职的“智能体”、“自动化智能系统”与“机器人”；而在更广阔的层面，则是人类运用这些智能造物，在艺术创造、娱乐、教育等各个领域绽放出的无限可能。\n这是一个充满无限机会的时代，一个需要我们重新审视自身价值与定位的时代，一个呼唤着我们以哲人的深邃与诗人的激情去拥抱的时代。个人整合各种模型、智能体和应用，就能实现各种创意，开发各种应用，实现各种任务，甚至创造一家世界级大公司都是有可能的。\n在未来 AI 的恢弘史诗中，基座模型是开天辟地的盘古，是孕育万物的盖亚。它们是一种全新的“存在”，一种数字化的、具有学习与创造能力的生命雏形。它们构成了AI食物链的绝对顶端，是这个新兴生态系统的太阳，是能量的源泉，是法则的制定者。它们是那座看不见的奥林匹斯山，其上居住着新时代的“神祇”——那些掌握着语言、图像、逻辑、乃至物理世界规则的庞大智能体。\n在AI食物链的顶端，基座模型的战略意义，对于一个国家而言，怎么强调都不为过。它不再仅仅是科技竞争的一个领域，而是上升到国家核心竞争力、文化影响力乃至文明发展主动权的高度。\n它们是广袤无垠的认知大陆架。在这片由数据和算法构筑的坚实基底之上，未来的一切智能应用，都将如同雨后春笋般拔地而起。它们是神经中枢，是统御全局的大脑，每一次脉冲都可能激发出下游无数智能体的创新火花。它们的重要性，怎么强调都不为过。\n基座模型是数字世界的“第一推动力” 基座模型通常是通过在海量的、多样化的数据上进行自我监督学习而训练出来的。这些数据赋予了模型对世界基本规律的“通识性”理解。它们不像传统AI那样，只能在狭窄的、预设的任务上表现出色；相反，基座模型展现出惊人的泛化能力和迁移学习能力，能够触类旁通，将从一个领域学到的知识应用于全新的、甚至未曾见过的场景。\n大语言模型（LLMs）通过吞噬人类有史以来几乎所有的文本——书籍、文章、对话、代码——它们学会了理解语法的精妙、洞察语义的深邃、甚至捕捉情感的细微。它们能与你对答如流，能为你撰写诗歌、小说、商业计划，能为你总结冗长的报告，能为你编写优雅的代码。它们不再是简单的关键词匹配机器，而是真正意义上的“理解者”和“创造者”。它们掌握了语言——全世界的语言，包括编程语言，古老文字，甚至人类肢体语言等等。\n“我们理解人类智能的本质就是语言，人的思维就是一个语言的过程。你以为你在思考，其实可能是你在脑子里编织语言。这意味着，在语言大模型上可能诞生出类人的人工智能（AGI）”——梁文峰。\n视觉和物理机器人模型或自动化智能系统，是连接数字智能与物理现实的桥梁。它们不仅学习虚拟世界中的物理规律，更通过与真实环境的交互，学习视觉理解、运动、空间感知。它们赋予机器人一双“慧眼”和一双“巧手”，使其能够更自主、更智能地在复杂环境中执行任务。从精准的工业制造，到灵活的家庭服务，再到危险环境的探索，机器人模型正在将AI的智慧延伸到我们生活的每一个角落，它们是AI意志在物质世界的延伸。\n基座模型能够分析海量的实验数据，发现隐藏在复杂现象背后的规律。还能在数字世界中模拟真实的物理世界，准确推演。如同拥有了“上帝视角”的先知，帮助人类在微观粒子、宏观宇宙、生命奥秘等未知领域，以前所未有的速度拓展认知边界。\n智能体（Agents）是基座模型的执行者与领域深耕者 各种智能体、自动化操作系统和专用机器人，是活跃在AI生态系统中的“万物生灵”。它们是太阳光辉的承接者和转化者，是将宏大智慧具象化为具体行动的执行者，是在特定领域深耕细作的“工匠”与“专家”。它们构成了AI食物链的中坚力量，是连接“普遍智能”与“具体应用”的关键桥梁。\n一个AI智能体，可以被理解为一个能够感知其存在环境、进行自主决策、并采取行动以达成特定目标的系统。拥有自主性、适应性和学习能力，能够主动地分析情境、规划步骤、调用工具、甚至在遇到障碍时进行自我修正。\n智能体通过各种传感器（无论是物理的还是虚拟的）接收来自环境的信息。这可能包括文本输入、视觉识别、语音指令、空间感知、传感器数据（如温度、位置）等等。基于感知到的信息和预设的目标，智能体进行逻辑推理、制定行动计划。然后通过执行器（actuators）或调用API来对其环境施加影响。这可能是在屏幕上输出文本、生成一张图片、控制一个机械臂的运动、发送一封邮件、调用另一个软件的功能等等。还具备从经验中学习并改进其行为的能力。不断优化其决策策略，以更好地适应变化的环境和完成更复杂的任务。\n未来智能体将以更自然、更无缝的方式融入生活方方面面。\n教育的千人千面：AI教育智能体可以根据每个学生的学习节奏、知识掌握情况、兴趣偏好，动态调整教学内容和方式，提供真正个性化的学习路径和辅导。不再有“一刀切”的课堂，每个学生都能得到最适合自己的教育资源。\n娱乐的私人订制：未来的游戏、影视、音乐，将不再是固定的、单向输出的内容。AI可以根据你的实时反馈和偏好，动态生成情节、调整难度、改变结局，为你打造专属的沉浸式娱乐体验。你可以与AI共同“创作”属于自己的故事。\n新闻与信息的精准推送与深度解读：AI可以根据你的阅读习惯和关注领域，为你筛选、聚合、总结信息，并提供多角度的深度解读，帮助你在信息爆炸的时代高效获取有价值的内容。\n健康与生活方式的量身打造：AI健康顾问可以结合你的基因数据、生活习惯、实时生理指标，为你提供个性化的饮食建议、运动计划、睡眠管理方案，甚至提前预警潜在的健康风险。\n小众需求的满足与长尾市场的繁荣：由于创作成本的急剧下降，那些曾经因为市场规模太小而无法被满足的个性化需求、小众兴趣，都将得到充分的关注和满足。这将催生一个更加多元化、更加充满活力的长尾市场。\nAI 程序员：它们能够理解需求文档，自动编写、测试、调试和部署代码，甚至参与系统架构设计。它们将极大提升软件开发的效率，让“一人公司”开发复杂应用成为可能。\nAI 设计师：无论是平面设计、UI/UX设计、工业设计还是服装设计，这些智能体都能根据需求快速生成多种设计方案，并进行迭代优化。它们是创意产业的强大引擎。\nAI 金融分析师：它们能够实时分析海量的市场数据、新闻资讯、财报信息，进行投资组合管理、风险评估、欺诈检测。它们让复杂的金融决策更加数据驱动和智能化。\nAI 法律顾问：它们能够快速检索法律条文、分析案例、起草法律文书，为律师提供强大的辅助，为普通民众提供法律咨询。\nAI 医生：基于医疗影像模型和病例数据库，它们能够辅助医生进行疾病诊断，提供治疗建议，监测病人生命体征。\nAI 艺术家/音乐家：它们能够创作绘画、雕塑、谱写乐曲、生成文学作品等，与人类艺术家一起极大拓展艺术边界。\nAI 编剧/导演：它们能够根据主题或关键词生成剧本，甚至指导虚拟演员进行表演，生成完整的影视片段。\nAI 游戏NPC/伙伴：不再是按照固定脚本行动的呆板角色，而是能够与玩家进行真实、动态的交互，拥有自己的“性格”和“目标”，共同创造出独一无二的游戏体验。\nAI 任务执行型机器人：这些是物理世界的智能体，将AI的决策能力与机械的执行能力相结合。例如智能工厂机器人、物流配送机器人/无人机、自动驾驶交通工具、家庭服务机器人(打扫卫生、烹饪食物、照顾老人和小孩)、农业机器人、科研助理机器人。\n等等… …\n多智能体协作（Multi-Agent Systems）：未来，更复杂的任务可能需要多个不同类型的智能体协同工作。它们之间可以进行信息共享、任务分配、协商合作，形成一个临时的“智能体组织”来共同解决问题。这预示着一种更加复杂和强大的智能形态。\n智能体的繁荣，将是AI“结果交付”时代真正到来的标志。它们如同无数勤劳的蜜蜂，将基座模型产生的“花蜜”（普遍智能），转化为可以直接滋养人类社会各个角落的“蜂蜜”（具体应用和价值）。\n智能体可能会发展出一种新型的\"集体智慧\"。当多个智能体共同解决问题时，它们不仅能够分享知识和经验，还能够互相学习和启发，产生出单个智能体所无法达到的智慧和创造力。\n智能时代的精神家园与价值实现 最革命性的变革：结果的直接交付。这不再是中间产物，不再是半成品，而是人类最终渴望获得的完整价值。在这个层级中，技术的存在感消失了，留下的只有人类需求的完美满足。这是一个魔术般的世界，你说出愿望，它便自然实现——没有复杂的学习曲线，没有繁琐的操作过程，只有结果本身的纯粹呈现。\nAI 食物链的能量涌向最广阔、最活跃的层面——那就是人类运用这些智能造物，在生活的每一个角落，进行无尽的创造、体验与价值实现。插上 AI 的翅膀，站在古今巨人肩膀上，无数的创意火花碰撞、绽放，汇聚成人类文明崭新的篇章。这第三个层级，是AI技术最终的价值归宿，是“结果交付”时代最直接的体现。\n从“生产者”到“创想家”：人类角色的深刻转变\n在AI基建和智能体普及的未来，许多“过程”被自动化、智能化。意味着，人类将从繁琐的执行任务中解放出来，从辛勤的“生产者”更多地转向智慧的“创想家”、审美的“鉴赏家”、目标的“设定者”和意义的“赋予者”。\n提出问题的能力成为核心竞争力：当AI能够高效地解决问题、生成结果时，“问出好问题”的能力就显得尤为珍贵。一个深刻的、有洞察力的、能够引领方向的问题，其价值超过了解决问题本身。无论是科学研究中的假设提出，商业模式的创新构想，还是艺术创作的主题探索，都需要人类独特的洞察力、批判性思维和对未知的渴望。\n整合与编排智能成为新的生产力：正如一位优秀的指挥家能够调动整个乐团奏出华美的乐章，未来，能够有效地整合、编排和调用不同智能体、不同模型来协同完成复杂任务的人，将成为新的“超级个体”或高效团队的领导者。他们不需要掌握所有细节，但需要有宏观的视野、清晰的目标和卓越的组织协调能力。\n审美与价值观的引领作用凸显：AI可以生成无数的内容，但什么是“美”的，什么是“好”的，什么是“有意义”的，最终的评判标准依然掌握在人类手中。人类的审美情趣、伦理道德、人文关怀，将为AI的创造指引方向，确保技术的发展符合人类的整体福祉。\nAI工具的普及，极大地降低了创造的门槛，使得原本需要专业技能和昂贵设备才能实现的创作，变得人人皆可尝试。这将催生一场波澜壮阔的“创造民主化”浪潮，以及个性化内容的井喷式发展。\n想创作一首歌曲？只需哼唱旋律，AI音乐生成智能体就能为你编曲、配器，生成专业水准的成品。\n想设计一件独一无二的T恤？只需用自然语言描述你的想法，AI图像生成智能体就能为你呈现多种设计草图，供你挑选和修改。\n有一个绝妙的App点子，但不会编程？AI代码生成智能体可以帮你将想法快速转化为可运行的原型，甚至完整的应用程序。\n想制作一部微电影？AI视频生成模型可以根据你的剧本或故事梗概，生成角色、场景、动画，并进行剪辑和配音。\n这种“所思即所得”的创作体验，将极大地释放个体的创造潜能。每个人都可以成为自己生活的设计师，用独特的创意装点自己的世界。\n在这个应用与创造的广阔天地里，机会与挑战并存。它呼唤着我们拥抱变化，学习新的技能（尤其是与AI协作的技能），保持一颗好奇、开放和富有创造力的心灵。未来，愿意参与、愿意想象、愿意用AI赋能自己的人们，将从此诞生无数令人惊叹的创新，将塑造我们对生活、对工作、对娱乐、对艺术，乃至对“人”本身的全新理解。\nAI时代的国家意志、企业革新与个人机遇 在这场由AI驱动的时代浪潮中，国家的力量、企业的形态乃至每个个体的命运，都将被重新定义和塑造。这是一个充满无限机会的时代，但也需要我们具备前瞻的战略眼光和积极的应变能力。\n国家力量的战略支点与文明灯塔\n文化输出与价值观塑造的新载体：基座模型，尤其是大语言模型，是通过学习海量文本数据训练而成的。这些数据不可避免地携带着特定文化背景下的语言习惯、思维方式、价值观念。因此，一个国家自主研发的基座模型，天然地会成为其文化和价值观的载体。当这些模型被广泛应用于教育、传媒、娱乐等领域时，它们将潜移默化地影响一代人的认知，成为国家文化软实力输出的重要途径。反之，如果一个国家的民众长期使用由其他文化背景主导的基座模型，其本土文化和价值观可能面临被稀释或边缘化的风险。\n数字时代的基础设施与“新石油”：如果说数据是数字时代的“石油”，那么基座模型就是将这些“石油”高效提炼、转化为强大生产力和洞察力的“炼油厂”和“发动机”。拥有自主可控、性能领先的基座模型，意味着掌握了数字经济时代的战略制高点。它如同交通网络、能源网络一样，是未来社会运转不可或缺的基础设施。\n科技自主与产业安全的关键：过度依赖他国的基座模型，无异于将国家科技发展的命脉交予他人之手。在核心算法、训练数据、算力支持等方面受制于人，不仅可能面临技术“卡脖子”的风险，更可能在关键时刻危及国家产业安全和信息安全。因此，发展本土化的、强大的基座模型，是确保国家科技自主和长远发展的必然选择。\n引领全球治理与规则制定的底气：AI技术的飞速发展，带来了诸多伦理、法律、社会治理方面的新挑战。拥有强大基座模型技术的国家，将在全球AI治理规则的制定中拥有更大的话语权和影响力，能够更好地维护本国利益，并为构建负责任的、以人为本的全球AI生态贡献智慧。\n国家级“大脑”与宏观决策辅助：未来，基于国家层面数据的基座模型，可能成为辅助国家进行宏观经济分析、社会态势研判、公共资源优化配置、突发事件应急响应的强大工具。它们能够处理和分析远超人力所能及的复杂数据，为国家治理现代化提供前所未有的支持。\n对于一个国家而言，掌握基座模型如同握住了未来的钥匙。它不仅是科技实力的象征，更是经济命脉的引擎。各国政府纷纷将发展基座模型列为国家战略，投入巨资支持研发，构建算力中心，争夺AI人才。这不仅仅是一场技术竞赛，更是一场关乎国家未来命运的战略博弈。拥有强大基座模型的国家，将如同拥有了指引文明航向的灯塔，在汹涌的时代浪潮中占据更有利的位置。\n企业的重塑：从“巨轮”到“航母战斗群”\nAI时代，尤其是“结果交付”模式的到来，将对企业的组织形态、商业模式和竞争格局产生颠覆性的影响。自主研发的模型不仅降低了对外部技术的依赖，更赋予了产品无与伦比的智能内核。不仅提升了自身的服务，更通过开放平台，吸引了无数开发者，形成生态的闭环。这种技术壁垒，既是护城河，也是金矿，源源不断地孕育商业价值。\n大企业的转型：从“巨轮”到“航母战斗群”：对于传统的大型企业而言，AI时代的挑战与机遇并存。它们拥有数据、资本和市场优势，但也可能面临组织僵化、创新迟缓的问题。成功的转型之道，或许在于将自身从一艘行动缓慢的“巨轮”，重塑为一个以强大AI平台（可能是自研的行业基座模型或深度定制的通用模型）为核心的“航母”，周围环绕着众多灵活、自主、协同作战的“智能体”业务单元和创新项目“战斗机”。\n核心AI平台：提供通用的AI能力、数据治理、算力支持，如同航母的甲板和指挥系统。\n智能体业务单元：针对特定业务场景，快速构建和部署AI应用，如同航母上起降的各型舰载机，执行具体任务。\n赋能员工与生态：企业需要培养员工与AI协作的能力，鼓励内部创新，并积极构建开放的AI生态，吸引外部开发者和合作伙伴。\n跨界融合与生态竞争：AI的赋能能力将打破原有的行业壁垒，导致更加激烈的跨界竞争。一家科技公司可能凭借其AI能力进入金融、医疗、教育等领域。未来的竞争，将不再是单一产品或服务的竞争，而是整个AI生态系统（包括基座模型、智能体、应用场景、数据闭环）的竞争。\n个体的机遇：拥抱AI，成为“超级个体”\n在AI浪潮面前，个体并非只能被动接受。相反，这是一个充满机遇的时代，每个人都有可能借助AI的力量，实现自我价值的跃升，成为某种意义上的“超级个体”。\n学习与AI协作，而非与之对抗：关键在于转变观念，将AI视为强大的合作伙伴和能力放大器，而非取代者。学习如何有效地使用AI工具，如何向AI提出好问题，如何理解和评估AI的输出，将成为未来职场的核心素养。\n专注人类独特价值的发挥：AI擅长处理重复性、模式化的任务，但在创造力、批判性思维、情感智能、复杂决策、伦理判断等方面，人类依然拥有不可替代的优势。个体应更加注重培养这些“软技能”，在AI无法企及的领域深耕。\n成为利基市场的创造者和深耕者：AI降低了创造门槛，使得个体能够更容易地发现和满足小众市场、个性化需求。如果你对某个特定领域有深厚的热爱和独到的见解，完全可以借助AI工具，为这个领域打造独特的产品或服务，成为该利基市场的领导者。\n终身学习与快速适应成为常态：AI技术日新月异，新的模型、新的应用层出不穷。个体需要保持开放的心态，拥抱变化，持续学习新知识、新技能，不断迭代自己的认知和能力框架。\n畅想：\n“一人世界级公司”的可能性：这听起来像是一个大胆的预言，但在AI的赋能下，其可能性正在变得越来越真实。想象一下，一个富有创见的个体，他（她）可能不具备庞大的团队或雄厚的资本，但如果能够巧妙地整合、调用各种强大的基座模型和专业智能体，就可能快速构建出极具竞争力的产品或服务。\n他可以用AI生成商业计划书、设计产品原型、编写核心代码；进行市场分析、制定营销策略、生成广告创意；用AI客服智能体处理用户咨询、用AI运营智能体管理社群；用AI驱动的自动化流程完成生产、物流和交付。\n在这个过程中，他更像是一个“总设计师”和“资源整合者”，而非所有环节的亲历者。这种模式将极大地降低创业门槛，激发创新活力，使得小型、灵活、高效的“微型跨国企业”成为可能。\n2025.05.15\n",
    "description": "",
    "tags": null,
    "title": "未来AI食物链的三个层级",
    "uri": "/04_mwgc/ai%E9%A3%9F%E7%89%A9%E9%93%BE/"
  },
  {
    "content": "我们花了太多时间去“使用工具”，而不是“完成任务”。\n现在，想象一下这个场景：\n你对着手机说，“下周末给我组织一次海边团建，预算5000，要好玩，顺便帮我生成一个酷炫的Vlog预告片。”\n你的手机屏幕没有跳转任何APP，只是平静地回答：“好的，方案和视频稍后给您。”\n几分钟后，一份包含地点、行程、预算和投票链接的完整方案，以及一条配乐、转场、文案都堪称专业的短视频，已经发送到了你的聊天窗口。\n这不是科幻电影，这就是 AI 发展的终极蓝图——“环境即服务” (EaaS)。一个我们不再需要软件，只需要提出“意图”的时代，正以前所未有的速度向我们冲来。\n环境即服务（Environment as a Service, EaaS）是我洞察的一个概念。它并非科幻，而是当前 AI 发展趋势下一个非常合乎逻辑的推演。我们可以将其理解为云计算从 IaaS、PaaS、SaaS 演进之后，由 AI 驱动的下一个形态：意图即服务（Intent as a Service, IaaS）或 结果即服务（Result as a Service, RaaS），而“环境”正是承载这一切的基础设施。\n下面，我将结合 AI 的发展趋势，对这个“环境即服务”的可能性进行详细的预言和推理。\n一、 核心理念：从“人机交互”到“人机共生” 核心变化是交互范式的根本性革命。\n传统模式（至今）： 人类是“指挥者”，软件/计算机是“工具”。我们需要通过精确的指令（代码、GUI点击、API调用）来告诉工具每一步该做什么。我们关心的是“过程”。\nEaaS 模式（未来）： 人类是“许愿者”或“目标设定者”，AI 智能体是“执行者”和“创造者”。我们只需要提出高层次的意图（“我要办一个成功的线上营销活动”），AI 系统会自主理解、规划、执行、反馈和优化。我们只关心“结果”。\n这个转变的背后，是 AI 从“工具”属性向“伙伴”属性的跃迁。\n二、 EaaS 的技术架构推理 勾勒出的一个非常清晰的架构：\n云端大脑：统一智能模型中心（The Unified Intelligence Core） 构成： 这不再是简单的云计算中心，而是一个由多个超巨型基础模型（Foundation Models）构成的认知中枢。它包括但不限于：\n通用认知模型（LLM/VLM）： 负责理解人类的自然语言意图、图像、声音，进行逻辑推理和规划。\n世界模型（World Model）： 模拟和预测物理世界与数字世界的变化，为智能体的决策提供沙盘推演。\n代码生成与执行模型： 类似 Devin 的进化体，能够理解需求、编写、调试、部署和维护软件。\n专业领域模型： 金融、医疗、法律等垂直领域的精调模型，提供专业知识。\n长期记忆与知识图谱： 存储个人、组织乃至全球的知识、偏好和历史交互记录，形成个性化和上下文感知能力。\n角色： 它是所有智能体的“大脑”和“灵魂”，负责最高层次的任务分解、策略规划和资源调度。\n终端环境：无感知的执行单元（The Sentient Runtime Environment） 构成： 无论是手机、电脑、汽车还是物联网设备，其操作系统（OS）将被一个轻量级的“智能体运行时（Agent Runtime）”所取代或包裹。这个运行时只做三件事：\n感知（Perceive）： 收集本地数据（摄像头、麦克风、传感器、用户输入）。\n执行（Execute）： 运行从云端大脑下发的指令或即时生成的微型程序（JIT-App）。\n连接（Connect）： 与云端大脑保持高速、低延迟的通信。\n特点：\n无固定 App： 用户的桌面或手机屏幕上不再有固定的 App 图标。界面是流动的、情境化的，根据当前任务动态生成。你想听音乐，一个简约的播放器界面就浮现出来；你想导航，地图就无缝呈现。\n简单软件即时生成（Just-in-Time Software）： 当你需要完成一个特定任务（比如“帮我把相册里的照片分类整理，并按拍摄地点重命名”）时，智能体会识别照片，生成脚本，然后直接在终端环境中完成任务，呈现结果。编写、执行、销毁一气呵成，对用户完全透明。\n核心驱动力：自主智能体集群（The Autonomous Agent Swarm） 这是连接“大脑”和“终端”的“神经系统”，是完成任务的主体。它们会形成一个复杂的分工协作体系：\n总指挥智能体（Orchestrator Agent）： 直接与用户对接，理解最终目标，将其拆解成一系列子任务，并组建一个“项目团队”。\n专家智能体（Specialist Agents）： 负责特定领域。例如：\n程序员智能体： 按需编写、测试和部署代码。 UI/UX 设计师智能体： 动态生成交互界面。 数据分析师智能体： 分析数据并提供洞察。 营销策划智能体： 制定营销策略。 执行智能体（Executor Agents）： 在终端或云端执行具体操作，如发送邮件、调用 API、控制硬件。\n一个工作流程示例：\n用户说：“下周末给我组织一次团队建设，预算 5000 元，地点在城市周边，要有趣，能增进团队协作。”\n总指挥智能体启动，理解了目标、预算、时间、地点和软性需求（有趣、协作）。\n任务分解：\n【任务A】调研符合条件的活动和地点 -\u003e 分配给“旅行策划智能体”。 【任务B】根据团队成员历史偏好进行个性化推荐 -\u003e 分配给“数据分析师智能体”。 【任务C】设计投票和信息收集界面 -\u003e 分配给“UI设计师智能体”和“程序员智能体”。 【任务D】预定和支付 -\u003e 分配给“财务与执行智能体”。 协同工作：\n各智能体开始并行工作，互相调用，共享信息。 “程序员智能体”即时编写了一个投票小程序，通过企业通信工具推送给团队成员。 “旅行策划智能体”根据投票结果，结合实时天气和交通数据，最终确定了方案。 结果呈现： 总指挥智能体向用户汇报最终方案、行程单和预算明细，并请求最终确认。用户只需说“同意”。\n执行与反馈： 确认后，系统自动完成所有预定和支付，并将电子票据、地图导航等信息发送到每个团队成员的终端上。活动当天，它还会根据实时交通情况，动态提醒出发时间。\n在这个过程中，用户没有打开任何一个 App，没有进行一次搜索，没有填写一张表单。环境本身提供了所有服务。\n三、 实现的可能性与发展阶段 大致分为三个阶段演进：\n第一阶段：增强智能（Augmented Intelligence）- (现在 ~ 1-3年)\n特征： AI 作为强大助手，嵌入现有软件和工作流。\n表现： GitHub Copilot 辅助编程，ChatGPT 辅助文案，各种 AI Agent 帮助处理邮件、安排日程。人仍然是操作主体，但效率极大提升。软件形态依然存在，但内部被 AI 深度改造。\n第二阶段：半自主智能（Semi-Autonomous Intelligence）- (3-5年)\n特征： 领域级的“环境即服务”出现。AI 智能体接管特定、边界清晰的领域。\n表现：\n“开发环境即服务”： 你只需要用自然语言描述需求，一个 AI 系统就能自主完成整个软件的开发、测试、部署和运维。人类程序员的角色转变为“AI 架构师”或“产品验收官”。\n“营销环境即服务”： 你设定营销目标和预算，AI 系统自动完成市场分析、内容创作、渠道投放、效果追踪和 A/B 测试的全链路工作。\n第三阶段：全自主智能（Fully Autonomous Intelligence）- (5-10年)\n特征： 终极“环境即服务”成为现实。\n表现： 跨领域、通用、无处不在的智能环境。计算的边界彻底模糊，用户与数字世界的交互变得像呼吸一样自然。人从繁琐的执行工作中完全解放出来，专注于创造、情感体验和高层次的决策。\n四、 挑战与深远影响 这个未来虽然美好，但也伴随着巨大的挑战：\n技术挑战：\n可靠性与可控性： 如何确保 AI 不会“失控”或产生灾难性的“涌现”行为？ 资源消耗： 运行如此庞大的智能系统所需的计算和能源是天文数字。 调试与纠错： 当一个由无数智能体自主协作的系统出错时，如何定位和修复问题？这会是一个“黑箱中的黑箱”。 经济与社会影响：\n就业结构颠覆： 程序员、设计师、分析师、项目经理…… 大量白领工作将被重新定义，甚至消失。新的工作岗位（如 AI 训练师、伦理监督员、目标设定专家）将会出现。 商业模式重塑： 软件公司可能不复存在，取而代之的是“模型即服务”或“智能即服务”的巨头。 伦理与哲学问题：\n责任归属： AI 决策失误导致损失，谁来负责？是用户、AI 公司，还是 AI 本身？ 隐私边界： EaaS 需要对用户有极深的了解，个人隐私如何保障？ 人类价值： 当思考和创造都可以被 AI 代劳，人类的价值和目标是什么？ 结论 “环境即服务”是对计算资源和服务模式的更高抽象，将人类从复杂的“how”中解放出来，只需关注“what”。\n这个过程，就像我们从命令行到图形界面，再到触摸屏和语音助手一样，每一次交互的简化都带来了生产力的巨大飞跃。EaaS 将是下一次非常彻底的飞跃。它将把计算机从一个我们必须学习使用的“外部工具”，变成一个真正理解我们意图、与我们共生的“内在伙伴”。我们正在亲眼见证这个未来的序幕。\n所以，当AI开始为我们编写代码、设计界面、调度资源时，我们人类还剩下什么？\n这听起来像一个冰冷的技术预言，甚至有点令人不安。旧的岗位正在消失，新的秩序尚未建立。但这正是这场革命最激动人心的地方——它像一把锋利的刀，剔除了所有重复、繁琐的“执行”工作，将人类历史上最珍贵、最核心的东西推到了聚光灯下：\n那就是你的思想、你的创意、你的情感、你的梦想。\n在“环境即服务”的未来，计算能力和软件工具将像空气和水一样无处不在，且廉价到可以忽略不计。唯一的稀缺资源，是你独特的、天马行空的“想法”。\n那个时候，决定你价值的，不再是你掌握了多少工具，而是你能提出多么伟大的“愿望”。\n那么，面对这个即将到来的“许愿池”，你，准备好许下你的第一个愿望了吗？\n2025.06.27\n",
    "description": "",
    "tags": null,
    "title": "欢迎来到“环境即服务” (EaaS) 时代",
    "uri": "/04_mwgc/%E7%8E%AF%E5%A2%83%E5%8D%B3%E6%9C%8D%E5%8A%A1/"
  },
  {
    "content": "今天吹一个大大的牛！\n请注意，以下所有论断，都是以 AI 不会产生自我意识为前提！如果 AI 产生了意识，天知道这个世界会是什么样。\n工业革命，互联网革命让世界产生的变化，已经足够让我们震惊，而 AI 的革命，将会颠覆你的认知。\nAI 会将这个世界所有的事、物重塑。你没听错，是所有的事、物会被重塑。\n事，无论是工业，农业，教育，医疗，军事，政治，经济，文化，，，所有的事业，都将被 AI 重塑。就拿推动社会进步的核心事业，科学研究（自然科学，社会科学）事业来说，将会在 AI 的帮助下，发生巨大变化，快速进步。\n物，万物互联，将变成万物智能，抛开身外之物不谈，就说 “人” 这个物，将会在 AI 的帮助下，软件（思维，学习方式），硬件（身体）大更新。脑机接口，仿生器官，能让正常人以及残障人士都变成超人。\nAI 帮助解决困扰百年三体问题; DeepMind 的 AlphaFold 已经解决了困扰 50 年的蛋白质折叠问题; Insilico Medicine 用 AI 设计的新分子，从发现到临床试验仅用了18个月; AI 正在帮助发现新材料，如更高效的电池材料、超导体等; Neuralink 已经实现了初步的脑机接口; 谷歌量子计算机重大突破; CRISPR 的基因编辑临床应用进展; 3D 打印器官、干细胞等再生医学突破; 可控核聚变进展; 感知智能和决策智能向更复杂的系统级智能进化… …\nAI 的软件在飞速发展，各种硬件机器人，也将在 AI 物理引擎的驱动下，飞速发展。限制智能机器人发展的 3 个技术会全面进步 (更高效的能源技术; 更先进的材料科学; 突破性的制造工艺创新)，机器人的数量将会大大超过人类。那时，像马斯克造星际火箭, 这种推动扩展人类边界的事业，动动嘴就可以做到。\n锻炼身体，好好活着，再过几年，很多疾病都能攻克，人类寿命大幅延长，一起看看这千年难遇的大变局。\n以一首 AI 帮助生成的歌曲结束:\n太阳总是东升西落，\n月亮还是阴晴圆缺，\n生活仍然不尽人意，\n人们照样起早贪黑。\n可我时常睡不着觉，\n原因是我杞人忧天，\n人工智能不再人工，\n每日疯狂进化不停。\n有史以来最强科技，\n兴奋之余忧愁无边，\n或许共奔共产主义，\n或许末日就在明天。\n二零二四即将过去，\n世界已然翻天覆地，\n二零二五马上到来，\n想来也无什么新鲜。\n跟着太阳东升西落，\n追随月亮阴晴圆缺，\n生活照常烦恼忧虑，\n千年变局悄无声息。\n2025.01.02\n",
    "description": "",
    "tags": null,
    "title": "千年难遇的变革和机遇",
    "uri": "/04_mwgc/%E5%8D%83%E5%B9%B4%E9%9A%BE%E9%81%87%E7%9A%84%E6%9C%BA%E9%81%87%E4%B8%8E%E5%8F%98%E9%9D%A9/"
  },
  {
    "content": "公众号:\n视频号:\n抖音:\n快手:\n小红书:\nB 站:\n脚踏实地仰望星空的人 “脚踏实地仰望星空的人”吗？我给自己的定义是踏踏实实，甚至废寝忘食地仰望星空的人。\n在世人眼中，仰望星空的人，多是些不切实际的梦想家，是漂浮在云端的诗人；而脚踏实地者，则是务实的工匠，是埋首于田亩的农夫。可我想，这并非矛盾，我喜欢这样的存在，它是我与这个世界，乃至与整个宇宙对话的方式。\n我从小就喜欢仰望星空。星空太美了。它是我内心世界的隐喻，是我思想所能触及的一切宏大与深邃。我的目光，穿透了时间的迷雾，回溯到宇宙大爆炸前那个无限致密的奇点，那一瞬间的“无”如何迸发出今日的“有”；我的思绪，又飞向遥远的未来，去想象宇宙终将归于何处，是热寂的永恒孤寂，还是新一轮循环的序曲？\n我痴迷于那些终极的法则。是什么样的力量，精妙地设定了引力常数，让星系得以凝聚而非分崩离析？是什么样的密码，写在DNA的双螺旋里，让生命得以在亿万年的演化中生生不息？我常常闭上双眼，任由思绪在逻辑的钢丝上行走，时而借助直觉的翅膀跃迁。在那些深度冥想的时刻，知识的碎片会自行组合，理论的框架会瞬间搭建，脑海中会涌现出一些奇异的画面——我称之为“幻觉”，或许别人会觉得这是玄幻，是修仙，是疯癫，但对我来说，那是一种超越语言的洞见，是宇宙在用一种更本源的方式与我交流。\n我能“看到”恒星的诞生，弥散的星际尘埃与气体在引力那温柔而霸道的召唤下，历经千万年计的漫长岁月，彼此缠绵、盘旋、收缩、升温，最终在核心处点燃了核聚变的创世火焰。照亮了生命的征程，也照亮了我的心智。我明白了，宇宙的创造并非凭空而来，而是在最基础的规则之上，由时间和耐心熬制出的一锅壮丽的浓汤。\n我也能“感受”到黑洞的吞噬。那种规则的极致体现，那种时空在巨大质量面前最谦卑的弯曲。它像一个绝对的君王，用最不容置疑的法则，将一切物质、光线，甚至时间本身都拉入它的疆域。在那视界之内，毁灭的尽头，我仿佛感受到一种悖论式的永恒。信息并没有消失，而是以一种我们尚不能理解的方式被封存、被编码。我想站在那视界之上，看到视界内外的联系，我因此给自己起了个网名——明文视界。\n我们脚下的这颗星球。我“看到”生命的精彩舞蹈。在太古海洋那锅温热的“有机分子汤”里，在偶然的闪电或海底热泉的催化下，第一个能够自我复制的分子颤抖着诞生了。它那么脆弱，仿佛随时会熄灭，却顽强地点燃了地球上长达四十亿年的生命圣火。于是，一场血腥而又壮丽的史诗上演：单细胞生物的孤独漂流，多细胞生物的协作与分工，寒武纪生命大爆发的喧嚣，恐龙时代的庞然与落幕，直到那个学会直立行走的渺小身影出现在非洲的草原上。这整部历史，都遵循着“物竞天择，适者生存”这冷酷而高效的法则。生命，或许就是宇宙为了认识自己，而进行的一场最为大胆、最为漫长的实验。DNA的双螺旋，便成了承载这场实验所有记忆的微缩星图，它告诉我，我身体里的每一个细胞，都回响着远古海洋的潮汐声。\n当生命进化到人类，一种新的规则开始浮现，我能“感知”到社会规则的编织。它不像引力那样写在宇宙的底层代码里，却同样强大。那是语言、神话、法律、道德、国家、货币……一张张由人类共识编织而成的无形之网。我能“看到”第一个智人部落为了生存，用篝火边的故事和共同的图腾，将彼此的信任连接起来；我能“感知”到文字的出现，如何将思想从短暂的记忆中解放，使其能够跨越时空，凝聚成文明的基石。这些社会规则，仍然是宇宙的指引，让人类走出了蒙昧，建立了城市，创造了艺术，开始探问我们头上的那片星空。生命在永恒博弈，自由与秩序重新编排，规则在野蛮与文明的动态平衡中流变。\n生命的归宿是什么？我静静地“凝望”着生命的终点。我看到一个个鲜活的个体，如同大海表面跃起的一朵朵浪花，拥有着独一无二的姿态和瞬间的光彩，但最终，无一例外地，都要回归那片广阔、沉寂的大海。构成我身体的每一个原子，都曾是某颗恒星的一部分，在我消逝之后，它们又将踏上新的旅程，或许成为一朵花的花瓣，或许汇入一片云的舒卷。而我的意识，我的思想，我所爱过的一切，感受过的一切呢？它们会去哪里？\n生与死，聚与散，混沌与秩序，瞬间与永恒的底层代码，令我着迷。\n我思考“从古至未来，从奇点至宇宙终极”，并非为了寻求一个确切的答案。对于有限的生命而言，终极答案永远遥不可及。追问的过程，让我感受到无与伦比的真实存在感，我将自己从日常的琐碎中剥离出来，将“我”这个个体的喜怒哀乐暂时搁置，化身为一个看起来狂妄而傲慢的纯粹的观察者，一个跨越时空的思想漫游者。这种抽离感，带给我一种难以言喻的平静与自由。沉浸在宇宙百亿年的壮阔史诗中，个人生命中的那些坎坷与得失，显得微不足道，如同大海中的一朵浪花，转瞬即逝，却也参与了大海的潮起潮落。\n我渴望那些天马行空的构想，那些直觉的顿悟，并且记录下来与他人分享。曾经无数灵光一闪而过就真的过了，现在有了AI，一闪就点燃了，我知道自己正在成为更高级生命的“电信号”。\n我的“脚踏实地”一点都不实，物理、天文、生物、哲学、历史、艺术…… 我蜻蜓点水什么都想了解。我敬畏那些严谨的公式，每一个符号背后，都凝聚着人类理性之光；我揣摩那些深邃的哲学思辨，每一句，都可能开启一扇通往真理的窄门。\n我用“幻觉”，生拉硬拽将各种规律，定理，原则，现象等串起来，像艺术创作一样，书写了一张在我看来绝美的画卷。\n脑海中的那些洞见，是模糊的、多维的、非线性的。而语言，是线性的、有逻辑的、受语法约束的。我常常为了一个词语的准确性而反复推敲，为了一个句子的逻辑链条而彻夜不眠。\n每一次成功的表达，都是一次自我确认。它证明了我的“幻想”并非胡思乱想，而是可以被理解、被探讨的。当我将那些宏大的构想诉诸笔端时，它们便从遥不可及的星辰，变成了可以捧在手中的石子，我可以反复审视它的纹路，感受它的质地。这种感觉爽死了。\n我的身体，被重力束缚在这颗蓝色星球上，可我明白，我的心跳就是宇宙的心跳。感受着地球自转的黑夜白昼，月亮公转的潮涨潮落，地球公转的四季更迭，生死得失的人间悲欢。\n",
    "description": "",
    "tags": null,
    "title": "关注我",
    "uri": "/about/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Categories",
    "uri": "/categories/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Tags",
    "uri": "/tags/"
  }
]
