[
  {
    "content": " AI å‘å±•æ—¥æ–°æœˆå¼‚, ä»¥ä¸‹é¡¹ç›®æ˜¯ç›®å‰ (2024-11-23) æœé›†æ•´ç†çš„éå¸¸æ£’çš„é¡¹ç›®/åº”ç”¨/å·¥å…·/èµ„æºâ€¦ åé¢æ–°æ·»åŠ , éƒ½ä¼šæ ‡æ³¨æ—¥æœŸ.\nå†…å®¹ä¸»è¦åˆ†ä¸º é¡¹ç›®çš„å®˜æ–¹ç½‘ç«™, é¡¹ç›®çš„ GitHub ä¸»é¡µ, é¡¹ç›®çš„ Hugging Face Space (å¯åœ¨çº¿è¯•ç”¨), AIGC ç›¸å…³ç½‘ç«™, ç›¸å…³æ–‡æ¡£èµ„æ–™. å®ƒä»¬ä¹‹é—´å¯èƒ½ä¼šæœ‰é‡å çš„é¡¹ç›®, ä½†éå¸¸å°‘, æˆ‘åšäº†å»é‡, ç¡®ä¿å”¯ä¸€æ€§.\né¡¹ç›®çš„å®˜æ–¹ç½‘ç«™ é¡¹ç›®çš„ GitHub ä¸»é¡µ Hugging Face Space AIGC ç›¸å…³ç½‘ç«™ ç›¸å…³æ–‡æ¡£èµ„æ–™ ",
    "description": "",
    "tags": null,
    "title": "ACGC é¡¹ç›®, åº”ç”¨, å·¥å…·, èµ„æºé›†",
    "uri": "/01_aigc_object/"
  },
  {
    "content": "ComfyUI æ•™ç¨‹èµ„æº ",
    "description": "",
    "tags": null,
    "title": "ComfyUI æ•™ç¨‹",
    "uri": "/02_comfyui/"
  },
  {
    "content": "æœç´¢é—®ç­” Kimi\nchatgpt\nç§˜å¡”\nperplexity\nMeta AI\nè…¾è®¯å…ƒå®\nè±†åŒ… - æŠ–éŸ³æ——ä¸‹ AI æ™ºèƒ½åŠ©æ‰‹\nGoogle AI Studio\nClaude\nçŸ¥ä¹ç›´ç­”\n360æœ\nPoe\nHuggingChat\nè§†é¢‘, è¯­éŸ³, ç»˜å›¾ç­‰ç»¼åˆ æ™ºè°±æ¸…è¨€\nå³æ¢¦AI - ä¸€ç«™å¼AIåˆ›ä½œå¹³å°\nå¯çµ AI - æ–°ä¸€ä»£ AI åˆ›æ„ç”Ÿäº§åŠ›å¹³å°\næµ·èº AI\nè·ƒé—®\nLuma Dream Machine | AI Video Generator\nKREA AI - AIGCé›†åˆ-é£æ ¼-å›¾æœ‰å…è´¹\nHome - Leonardo.Ai\nAI Test Kitchen\nLimeWire\nLe Chat - Mistral AI\nWHEE - é«˜å“è´¨çš„AIç´ æç”Ÿæˆå™¨\nè§†é¢‘ kaze.ai - AI-powered Free Online Removing Watermark and Logos Tool 2024-11-27\nViduï¼Œè®©æƒ³è±¡å‘ç”Ÿ\nHailuo AI Video Generator - Reimagine Video Creation\nRunway\nè®²æ•…äº‹çš„æ–¹å¼å‘ç”Ÿäº†è½¬å˜LTXå·¥ä½œå®¤ â€” Storytelling Transformed | LTX Studio\nNoisee AI éŸ³ä¹ç”ŸæˆMV\nPika\nGenmo. Create videos and images with AI.\nHome | PixVerse\nViggle AI\nä¸‡å¾·åŠ¨åŠ› â€” Wonder Dynamics\nHeyGen - AI Spokesperson Video Creator\nAiuni\nDomoAI: video to video, video to animation and more\nFlair\nWarpvideo AI: Change Video Style with AI\nHedra æ•°å­—äºº\nAI æ“æŠ± - å…è²»ç·šä¸Š AI æ“æŠ±å½±ç‰‡ç”Ÿæˆå™¨\nMOKI - æˆ‘ç”¨AIåšçŸ­ç‰‡\nMeshcapade | ç¼–è¾‘äººç‰©åŠ¨ä½œ\nBoomCut - çˆ†å‰ªè¾‘ - å°å½±ç§‘æŠ€æ——ä¸‹ AI å†…å®¹åˆ›æ„äº§å“ä¸æœåŠ¡å¹³å°\nç»˜ç”»è®¾è®¡ Create stunning visuals in seconds with AI.\nè¶…èƒ½ç”»å¸ƒé¦–é¡µ\nAdobe Firefly\nDesign - Playground\nSkybox AI 360Â°å…¨æ™¯\nMagic Studioï¼šåˆ©ç”¨ AI åˆ¶ä½œç²¾ç¾å›¾åƒ\nmidjourney\nRemove Background from Image for Free â€“ remove.bg\nCraiyon, formerly DALL-E mini\nCreate - Artbreeder\nNightCafe Creator\nProjects - Recraft\nBlendbox.ai å¤šå›¾ç»„åˆ\nIdeogram ç”»å¸ƒ\nLogo-creator.io â€“ Generate a logo\nåœ¨çº¿æŠ å›¾è½¯ä»¶_å›¾ç‰‡å»é™¤èƒŒæ™¯ | remove.bg â€“ remove.bg\nè§¦æ‰‹AI\n3D Meshy - Free 3D Models Generated from Images and Text\nImmersity AI | Convert Image and Video to 3D\nTripo AI - ç”¨æ–‡å­—æˆ–å›¾ç‰‡å…è´¹ç”Ÿæˆ3Dæ¨¡å‹\nè¯­éŸ³, éŸ³ä¹ Suno\næµ·ç»µéŸ³ä¹\nFree Text to Speech \u0026 AI Voice Generator | ElevenLabs\nUdio AI Music Generator - Make Original Tracks in Seconds\nStable Audio - Generate\nåœ¨çº¿å…è´¹æ–‡æœ¬è½¬è¯­éŸ³ - TTS-Online | å¤šç§å£°éŸ³ä¸äºŒæ¬¡å…ƒè¯­éŸ³\nSoundboard - TUNA - Download Unlimited Free Meme Sounds\nèŠ‚å¥ç”Ÿæˆå™¨-Beat Blender éŸ³ä¹\nç½‘æ˜“å¤©éŸ³ - ä¸€ç«™å¼AIéŸ³ä¹åˆ›ä½œå·¥å…· - å®˜ç½‘\næç¤ºè¯ promptoMANIA:ç»˜ç”»æç¤ºç”Ÿæˆå™¨\nLexica\nPromptHero - æç¤ºè¯å¤§å…¨\nä»£ç  MarsCode - AI IDE\nCursor\nbolt.new\nScriptEcho | AIç”Ÿæˆç”Ÿäº§çº§ä»£ç  |\nå…¶ä»– NotebookLM | Note Taking \u0026 Research Assistant Powered by AI\næ‰£å­ - AI æ™ºèƒ½ä½“å¼€å‘å¹³å°\nFigma\nIlluminate | Learn Your Way\nChat Nio\nLlamaOCR.com â€“ Document to markdown\nNeo AI engineer\nExcalidraw\nç­‰å¾…ä¸­çš„é¡¹ç›® Baking Gaussian Splatting into Diffusion Denoiser for Fast and Scalable Single-stage Image-to-3D Generation 2024-11-27\nFugatto, Worldâ€™s Most Flexible Sound Machine, Debuts | NVIDIA Blog 2024-11-27\nFashion-VDM: Video Diffusion Model for Virtual Try-On\nInverse Painting: Reconstructing The Painting Process\né¦–é¡µ |å‰§é›†ä¸»ç®¡ â€” Home | Showrunner\næ‚ èˆ¹\nVideo Oceanè§†é¢‘å¤§æ¨¡å‹ - äººäººçš†å¯¼æ¼”\nPersonaTalk: Bring Attention to Your Persona in Visual Dubbing\nMarDini: Masked Auto-Regressive Diffusion for Video Generation at Scale â€“ Meta AI Research\nç‚‰ç±³Lumi\nloopyavatar.github.io/?ref=aihub.cn\nGoogle Vidsï¼šåœ¨çº¿è§†é¢‘åˆ›å»ºå’Œç¼–è¾‘å™¨ | Google Vidsè°·æ­Œå·¥ä½œåŒº â€” Google Vids: Online Video Creator and Editor | Google Workspace\nSkyReels\nURAvatar: Universal Relightable Gaussian Codec Avatars\nMikuDance\nAdd-it\nDanceFusion: A Spatio-Temporal Skeleton Diffusion Transformer for Audio-Driven Dance Motion Reconstruction.\nAnimateAnything\nMIMO\nInstructAvatar\næ¨¡å‹, èµ„æº, å·¥ä½œæµ Discovery | OpenArt\nShakker - Generative AI design tool with diverse models\né¦–é¡µ Â· é­”æ­ç¤¾åŒº\nComfy Workflows\nOpenModelDB\nFREE online image generator and model hosting site! | Tensor.Art\nCivitai: The Home of Open-Source Generative AI\nCodeWithGPU | èƒ½å¤ç°æ‰æ˜¯å¥½ç®—æ³•\nLiblibAI-å“©å¸ƒå“©å¸ƒAI - ä¸­å›½é¢†å…ˆçš„AIåˆ›ä½œå¹³å°\nComfyUIå·¥ä½œæµ - åœ¨çº¿è¿è¡Œï¼Œé€Ÿåº¦å¿«ï¼Œä¸æŠ¥é”™\nFREE online image generator and model hosting site! | Tensor.Art\nCephalon Cloud ç«¯è„‘äº‘ - AIGC åº”ç”¨å¹³å°\n",
    "description": "",
    "tags": null,
    "title": "é¡¹ç›®çš„å®˜æ–¹ç½‘ç«™",
    "uri": "/01_aigc_object/01_object/"
  },
  {
    "content": "è§†é¢‘ k4yt3x/video2x: A machine learning-based lossless video super resolution framework. Est. Hack the Valley II, 2018. 2024-11-27\nfacefusion/facefusion: Industry leading face manipulation platform 2024-11-27\nyangchris11/samurai: Official repository of â€œSAMURAI: Adapting Segment Anything Model for Zero-Shot Visual Tracking with Motion-Aware Memoryâ€\nalibaba/Tora: The official repository for paper â€œTora: Trajectory-oriented Diffusion Transformer for Video Generationâ€\naigc-apps/CogVideoX-Fun: ğŸ“¹ A more flexible CogVideoX that can generate videos at any resolution and creates videos from images.\naigc-apps/EasyAnimate: ğŸ“º An End-to-End Solution for High-Resolution and Long Video Generation Based on Transformer Diffusion\nGitHub - HVision-NKU/StoryDiffusion: Create Magic Story!\nhpcaitech/Open-Sora: Open-Sora: Democratizing Efficient Video Production for All\nVision-CAIR/MiniGPT4-video\nhkchengrex/Cutie: [CVPR 2024 Highlight] Putting the Object Back Into Video Object Segmentation\nPicsart-AI-Research/StreamingT2V: StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text\naigc-apps/EasyAnimate: ğŸ“º An End-to-End Solution for High-Resolution and Long Video Generation Based on Transformer Diffusion\nTencent/MimicMotion: High-Quality Human Motion Video Generation with Confidence-aware Pose Guidance\njianchang512/pyvideotrans: Translate the video from one language to another and add dubbing. å°†è§†é¢‘ä»ä¸€ç§è¯­è¨€ç¿»è¯‘ä¸ºå¦ä¸€ç§è¯­è¨€ï¼Œå¹¶æ”¯æŒapiè°ƒç”¨\nHillobar/Rope: GUI-focused roop\nGitHub - sczhou/CodeFormer: [NeurIPS 2022] Towards Robust Blind Face Restoration with Codebook Lookup Transformer\nHuanshere/VideoLingo: Netflix-level subtitle cutting, translation, alignment, and even dubbing - one-click fully automated AI video subtitle team | Netflixçº§å­—å¹•åˆ‡å‰²ã€ç¿»è¯‘ã€å¯¹é½ã€ç”šè‡³åŠ ä¸Šé…éŸ³ï¼Œä¸€é”®å…¨è‡ªåŠ¨è§†é¢‘æ¬è¿AIå­—å¹•ç»„\njy0205/Pyramid-Flow: Code of Pyramidal Flow Matching for Efficient Video Generative Modeling\nVision-CAIR/LongVU\nDoubiiu/ToonCrafter: [SIGGRAPH Asia 2024, Journal Track] ToonCrafter: Generative Cartoon Interpolation\nVectorSpaceLab/Video-XL: ğŸ”¥ğŸ”¥First-ever hour scale video understanding models\nanliyuan/Ultralight-Digital-Human: ä¸€ä¸ªè¶…è½»é‡çº§ã€å¯ä»¥åœ¨ç§»åŠ¨ç«¯å®æ—¶è¿è¡Œçš„æ•°å­—äººæ¨¡å‹\nantgroup/echomimic_v2: EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation\nZejun-Yang/AniPortrait: AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animation\nfudan-generative-vision/hallo2: Hallo2: Long-Duration and High-Resolution Audio-driven Portrait Image Animation\nantgroup/echomimic: EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditioning\nLordLiang/DrawingSpinUp: (SIGGRAPH Asia 2024) This is the official PyTorch implementation of SIGGRAPH Asia 2024 paper: DrawingSpinUp: 3D Animation from Single Character Drawings\nHelloVision/HelloMeme: The official HelloMeme GitHub site\nKmcode1/SG-I2V: This is the official implementation of SG-I2V: Self-Guided Trajectory Control in Image-to-Video Generation.\nfacebookresearch/sapiens: High-resolution models for human tasks.\nAlonzoLeeeooo/StableV2V: The official implementation of the paper titled â€œStableV2V: Stablizing Shape Consistency in Video-to-Video Editingâ€.\ngenmoai/mochi: The best OSS video generation models\nTHUDM/CogVideo: text and image to video generation: CogVideoX (2024) and CogVideo (ICLR 2023)\nCyberAgentAILab/TANGO: Official implementation of the paper â€œTANGO: Co-Speech Gesture Video Reenactment with Hierarchical Audio-Motion Embedding and Diffusion Interpolationâ€\nIDEA-Research/MotionCLR: [Arxiv 2024] MotionCLR: Motion Generation and Training-free Editing via Understanding Attention Mechanisms\nJi4chenLi/t2v-turbo: Code repository for T2V-Turbo and T2V-Turbo-v2\nLightricks/LTX-Video: Official repository for LTX-Video\nComfyUI EvilBT/ComfyUI_SLK_joy_caption_two: ComfyUI Node 2024-11-27\nhuchenlei/ComfyUI-layerdiffuse: Layer Diffuse custom nodes 2024-11-27\nkijai/ComfyUI-IC-Light: Using IC-LIght models in ComfyUI 2024-11-27\nkijai/ComfyUI-CogVideoXWrapper\nLightricks/ComfyUI-LTXVideo: LTX-Video Support for ComfyUI\nsmthemex/ComfyUI_EchoMimic: You can using EchoMimic in ComfyUI\nAIFSH/ACE-ComfyUI\nlogtd/ComfyUI-MochiEdit: ComfyUI nodes to edit videos using Genmo Mochi\nkijai/ComfyUI-SUPIR: SUPIR upscaling wrapper for ComfyUI\nHelloVision/ComfyUI_HelloMeme: Official comfyui repository of Hellomeme\nalimama-creative/SDXL_EcomID_ComfyUI\nAIGODLIKE/AIGODLIKE-ComfyUI-Studio: Improve the interactive experience of using ComfyUI, such as making the loading of ComfyUI models more intuitive and making it easier to create model thumbnails\nssitu/ComfyUI_UltimateSDUpscale: ComfyUI nodes for the Ultimate Stable Diffusion Upscale script by Coyote-A.\nGourieff/comfyui-reactor-node: Fast and Simple Face Swap Extension Node for ComfyUI\nlldacing/ComfyUI_BiRefNet_ll\nAIGODLIKE/ComfyUI-BlenderAI-node: Used for AI model generation, next-generation Blender rendering engine, texture enhancement\u0026generation (based on ComfyUI)\nsmthemex/ComfyUI_Hallo2: ComfyUI_Hallo2: Long-Duration and High-Resolution Audio-driven Portrait Image Animation\nkijai/ComfyUI-Florence2: Inference Microsoft Florence2 VLM\nCY-CHENYUE/ComfyUI-Molmo: Generate detailed image descriptions and analysis using Molmo models in ComfyUI.\nyolain/ComfyUI-Easy-Use: In order to make it easier to use the ComfyUI, I have made some optimizations and integrations to some commonly used nodes.\nsipherxyz/comfyui-art-venture\nGiusTex/ComfyUI-DiffusersImageOutpaint: Diffusers Image Outpaint for ComfyUI\nXLabs-AI/x-flux-comfyui\nT8star1984/Comfyui-Aix-NodeMap: Comfyuiâ€™s latest node organization and annotation, continuously updated, and supported by the Aix team/comfyuiæœ€æ–°èŠ‚ç‚¹æ•´ç†åŠæ³¨é‡Šï¼ŒæŒç»­æ›´æ–°ï¼ŒAIXå›¢é˜Ÿ\nT8star1984/Comfyui-Aix-NodeMap: Comfyuiâ€™s latest node organization and annotation, continuously updated, and supported by the Aix team/comfyuiæœ€æ–°èŠ‚ç‚¹æ•´ç†åŠæ³¨é‡Šï¼ŒæŒç»­æ›´æ–°ï¼ŒAIXå›¢é˜Ÿ\nlogtd/ComfyUI-Fluxtapoz: Nodes for image juxtaposition for Flux in ComfyUI\nWASasquatch/was-node-suite-comfyui: An extensive node suite for ComfyUI with over 210 new nodes\ncubiq/ComfyUI_IPAdapter_plus\ncubiq/ComfyUI_InstantID\ncubiq/ComfyUI_InstantID\nZHO-ZHO-ZHO/ComfyUI-InstantID: Unofficial implementation of InstantID for ComfyUI\nkijai/ComfyUI-MochiWrapper\nkijai/ComfyUI-LivePortraitKJ: ComfyUI nodes for LivePortrait\nPowerHouseMan/ComfyUI-AdvancedLivePortrait\nTemryL/ComfyUI-IDM-VTON: ComfyUI adaptation of IDM-VTON for virtual try-on.\ncity96/ComfyUI-GGUF: GGUF Quantization support for native ComfyUI models\nFizzleDorf/ComfyUI_FizzNodes: Custom Nodes for Comfyui\nbalazik/ComfyUI-PuLID-Flux: PuLID-Flux ComfyUI implementation\nkijai/ComfyUI-PyramidFlowWrapper\nstavsap/comfyui-ollama\nltdrdata/ComfyUI-Manager: ComfyUI-Manager is an extension designed to enhance the usability of ComfyUI. It offers management functions to install, remove, disable, and enable various custom nodes of ComfyUI. Furthermore, this extension provides a hub feature and convenience functions to access a wide range of information within ComfyUI.\nerosDiffusion/ComfyUI-enricos-nodes: Compositor Node experiments\nStartHua/Comfyui_CXH_joy_caption: Recommended based on comfyui node pictures:Joy_caption + MiniCPMv2_6-prompt-generator + florence2\nZHO-ZHO-ZHO/ComfyUI-YoloWorld-EfficientSAM: Unofficial implementation of YOLO-World + EfficientSAM for ComfyUI\nlogtd/ComfyUI-Fluxtapoz: Nodes for image juxtaposition for Flux in ComfyUI\nGreenLandisaLie/AuraSR-ComfyUI: ComfyUI implementation of AuraSR\nJonseed/ComfyUI-Detail-Daemon: A port of muerrillaâ€™s sd-webui-Detail-Daemon as a node for ComfyUI, to adjust sigmas that control detail.\ntaabata/ComfyCanvas: Canvas to use with ComfyUI\njtydhr88/ComfyUI-Hunyuan3D-1-wrapper: ComfyUI Hunyuan3D-1-wrapper is a custom node that allows you to run Tencent/Hunyuan3D-1 in ComfyUI as a wrapper.\nsmthemex/ComfyUI_Sapiens: You can call Using Sapiens to get segï¼Œnormalï¼Œposeï¼Œdepthï¼Œmask\n1038lab/ComfyUI-RMBG: A ComfyUI node for removing image backgrounds using RMBG-2.0.\nTTPlanetPig/Comfyui_Object_Migration: This is a study aim to transfer the single concept by using DIT model self-attention capablity\nDoctorDiffusion/ComfyUI-BEN: Background Erase Network - Remove backgrounds from images within ComfyUI.\nmarduk191/ComfyUI-Fluxpromptenhancer: A Prompt Enhancer for flux.1 in ComfyUI\nLightricks/ComfyUI-LTXVideo: LTX-Video Support for ComfyUI\nWebUI open-webui/open-webui: User-friendly AI Interface (Supports Ollama, OpenAI API, â€¦)\ncontinue-revolution/sd-webui-segment-anything: Segment Anything for Stable Diffusion WebUI\nlllyasviel/stable-diffusion-webui-forge\naigc-apps/sd-webui-EasyPhoto: ğŸ“· EasyPhoto | Your Smart AI Photo Generator.\nLLM THUDM/GLM-4-Voice: GLM-4-Voice | ç«¯åˆ°ç«¯ä¸­è‹±è¯­éŸ³å¯¹è¯æ¨¡å‹\noobabooga/text-generation-webui: A Gradio web UI for Large Language Models.\njanhq/jan: Jan is an open source alternative to ChatGPT that runs 100% offline on your computer. Multiple engine support (llama.cpp, TensorRT-LLM)\nollama/ollama: Get up and running with Llama 3.2, Mistral, Gemma 2, and other large language models.\nbinary-husky/gpt_academic: ä¸ºGPT/GLMç­‰LLMå¤§è¯­è¨€æ¨¡å‹æä¾›å®ç”¨åŒ–äº¤äº’æ¥å£ï¼Œç‰¹åˆ«ä¼˜åŒ–è®ºæ–‡é˜…è¯»/æ¶¦è‰²/å†™ä½œä½“éªŒï¼Œæ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒè‡ªå®šä¹‰å¿«æ·æŒ‰é’®\u0026å‡½æ•°æ’ä»¶ï¼Œæ”¯æŒPythonå’ŒC++ç­‰é¡¹ç›®å‰–æ\u0026è‡ªè¯‘è§£åŠŸèƒ½ï¼ŒPDF/LaTexè®ºæ–‡ç¿»è¯‘\u0026æ€»ç»“åŠŸèƒ½ï¼Œæ”¯æŒå¹¶è¡Œé—®è¯¢å¤šç§LLMæ¨¡å‹ï¼Œæ”¯æŒchatglm3ç­‰æœ¬åœ°æ¨¡å‹ã€‚æ¥å…¥é€šä¹‰åƒé—®, deepseekcoder, è®¯é£æ˜Ÿç«, æ–‡å¿ƒä¸€è¨€, llama2, rwkv, claude2, mossç­‰ã€‚\nSillyTavern/SillyTavern: LLM Frontend for Power Users.\nmendableai/firecrawl: ğŸ”¥ Turn entire websites into LLM-ready markdown or structured data. Scrape, crawl and extract with a single API.\nInternLM/InternLM: Official release of InternLM2.5 base and chat models. 1M context support\nè®­ç»ƒè„šæœ¬ kohya-ss/sd-scripts\ncocktailpeanut/fluxgym: Dead simple FLUX LoRA training UI with LOW VRAM support\nkijai/ComfyUI-FluxTrainer\nReleases Â· bmaltais/kohya_ss\nAkegarasu/lora-scripts: LoRA \u0026 Dreambooth training scripts \u0026 GUI use kohya-ssâ€™s trainer, for diffusion model.\nNerogar/OneTrainer: OneTrainer is a one-stop solution for all your stable diffusion training needs.\nå›¾åƒè®¾è®¡ erwold/qwen2vl-flux 2024-11-27\nYuanshi9815/OminiControl: A minimal and universal controller for FLUX.1. 2024-11-27\nlllyasviel/sd-forge-layerdiffuse: [WIP] Layer Diffusion for WebUI (via Forge) 2024-11-27\nali-vilab/ACE: All-round Creator and Editor\nmit-han-lab/hart: HART: Efficient Visual Generation with Hybrid Autoregressive Transformer\nZhengPeng7/BiRefNet: [CAAI AIR'24] Bilateral Reference for High-Resolution Dichotomous Image Segmentation\nYangLing0818/IterComp: IterComp: Iterative Composition-Aware Feedback Learning from Model Gallery for Text-to-Image Generation\nxinsir6/ControlNetPlus: ControlNet++: All-in-one ControlNet for image generations and editing!\nKwai-Kolors/Kolors: Kolors Team\nXiaojiu-z/Stable-Hair: Stable-Hair: Real-World Hair Transfer via Diffusion Model\nyisol/IDM-VTON: [ECCV2024] IDM-VTON : Improving Diffusion Models for Authentic Virtual Try-on in the Wild\nbcmi/libcom: Image composition toolbox: everything you want to know about image composition or object insertion\nPixArt-alpha/PixArt-alpha: PixArt-Î±: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis\nblack-forest-labs/flux: Official inference repo for FLUX.1 models\nStability-AI/sd3.5\nlllyasviel/Omost: Your image is almost there!\ngligen/GLIGEN: Open-Set Grounded Text-to-Image Generation\nTencent/HunyuanDiT: Hunyuan-DiT : A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding\nlllyasviel/IC-Light: More relighting!\ntencent-ailab/IP-Adapter: The image prompt adapter is designed to enable a pretrained text-to-image diffusion model to generate images with image prompt.\npiddnad/DDColor: [ICCV 2023] Official implementation of â€œDDColor: Towards Photo-Realistic Image Colorization via Dual Decodersâ€\ncumulo-autumn/StreamDiffusion: StreamDiffusion: A Pipeline-Level Solution for Real-Time Interactive Generation\nToTheBeginning/PuLID: [NeurIPS 2024] Official code for PuLID: Pure and Lightning ID Customization via Contrastive Alignment\nKDE/krita: Krita is a free and open source cross-platform application that offers an end-to-end solution for creating digital art files from scratch built on the KDE and Qt frameworks.\nAcly/krita-ai-diffusion: Streamlined interface for generating images with AI in Krita. Inpaint and outpaint with optional text prompt, no tweaking required.\ninstantX-research/InstantID: InstantID: Zero-shot Identity-Preserving Generation in Seconds ğŸ”¥\njbilcke-hf/FacePoke: Select a portrait, click to move the head around (please use your own space / GPU!)\ncatcathh/UltraPixel: Implementation of UltraPixel: Advancing Ultra-High-Resolution Image Synthesis to New Peaks\nZeyi-Lin/HivisionIDPhotos: âš¡ï¸HivisionIDPhotos: a lightweight and efficient AI ID photos tools. ä¸€ä¸ªè½»é‡çº§çš„AIè¯ä»¶ç…§åˆ¶ä½œç®—æ³•ã€‚\nVectorSpaceLab/OmniGen: OmniGen: Unified Image Generation. https://arxiv.org/pdf/2409.11340\nshallowdream204/DreamClear: [NeurIPS 2024ğŸ”¥] DreamClear: High-Capacity Real-World Image Restoration with Privacy-Safe Dataset Curation\nNVlabs/consistory\ninstantX-research/Regional-Prompting-FLUX: Training-free Regional Prompting for Diffusion Transformers ğŸ”¥\nali-vilab/In-Context-LoRA: Official repository of In-Context LoRA for Diffusion Transformers\nmit-han-lab/nunchaku: SVDQuant: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion Models\nChenyangSi/FreeU: FreeU: Free Lunch in Diffusion U-Net (CVPR2024 Oral)\nmagic-quill/MagicQuill: Official Implementations for Paper - MagicQuill: An Intelligent Interactive Image Editing System\nNutlope/logocreator: A free + OSS logo generator powered by Flux on Together AI\nNVlabs/Sana: SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformer\nJackAILab/ConsistentID: Customized ID Consistent for human\nDepthAnything/Depth-Anything-V2: [NeurIPS 2024] Depth Anything V2. A More Capable Foundation Model for Monocular Depth Estimation\ntryonlabs/FLUX.1-dev-LoRA-Outfit-Generator: FLUX.1-dev LoRA Outfit Generator can create an outfit by detailing the color, pattern, fit, style, material, and type.\nè¯­éŸ³, éŸ³ä¹ netease-youdao/EmotiVoice: EmotiVoice ğŸ˜Š: a Multi-Voice and Prompt-Controlled TTS Engine\nhaidog-yaqub/EzAudio: High-quality Text-to-Audio Generation with Efficient Diffusion Transformer\n2noise/ChatTTS: A generative speech model for daily dialogue.\nBytedanceSpeech/seed-tts-eval\nRVC-Project/Retrieval-based-Voice-Conversion-WebUI: Easily train a good VC model with voice data \u003c= 10 mins!\nGitHub - yxlllc/DDSP-SVC: Real-time end-to-end singing voice conversion system based on DDSP (Differentiable Digital Signal Processing)\nvoicepaw/so-vits-svc-fork: so-vits-svc fork with realtime support, improved interface and more features.\nGitHub - RVC-Boss/GPT-SoVITS: 1 min voice data can also be used to train a good TTS model! (few shot voice cloning)\nSWivid/F5-TTS: Official code for â€œF5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matchingâ€\nmisya11p/amt-apc: AMT-APC: AMT-APC: Automatic Piano Cover by Fine-Tuning an Automatic Music Transcription Model\nWEIFENG2333/AsrTools: âœ¨ AsrTools: æ™ºèƒ½è¯­éŸ³è½¬æ–‡å­—å·¥å…· | é«˜æ•ˆæ‰¹å¤„ç† | ç”¨æˆ·å‹å¥½ç•Œé¢ | æ— éœ€ GPU |æ”¯æŒ SRT/TXT è¾“å‡º | è®©æ‚¨çš„éŸ³é¢‘ç¬é—´å˜æˆç²¾ç¡®æ–‡å­—ï¼\nopen-mmlab/Amphion: Amphion (/Ã¦mËˆfaÉªÉ™n/) is a toolkit for Audio, Music, and Speech Generation. Its purpose is to support reproducible research and help junior researchers and engineers get started in the field of audio, music, and speech generation research and development.\nfishaudio/fish-speech: Brand new TTS solution\n3D VAST-AI-Research/TripoSR 2024-11-27\nmicrosoft/MoGe: MoGe: Unlocking Accurate Monocular Geometry Estimation for Open-Domain Images with Optimal Training Supervision\nHengyiWang/spann3r: 3D Reconstruction with Spatial Memory\nTencent/Hunyuan3D-1\nwenqsun/DimensionX: DimensionX: Create Any 3D and 4D Scenes from a Single Image with Controllable Video Diffusion\næ–‡æœ¬å¤„ç† zyddnys/manga-image-translator: Translate manga/image ä¸€é”®ç¿»è¯‘å„ç±»å›¾ç‰‡å†…æ–‡å­— https://cotrans.touhou.ai/\nchidiwilliams/buzz: Buzz transcribes and translates audio offline on your personal computer. Powered by OpenAIâ€™s Whisper.\nAgentEra/Agently-Daily-News-Collector: An open-source LLM based automatically daily news collecting workflow showcase powered by Agently AI application development framework.\nLC044/WeChatMsg: æå–å¾®ä¿¡èŠå¤©è®°å½•ï¼Œå°†å…¶å¯¼å‡ºæˆHTMLã€Wordã€Excelæ–‡æ¡£æ°¸ä¹…ä¿å­˜ï¼Œå¯¹èŠå¤©è®°å½•è¿›è¡Œåˆ†æç”Ÿæˆå¹´åº¦èŠå¤©æŠ¥å‘Šï¼Œç”¨èŠå¤©æ•°æ®è®­ç»ƒä¸“å±äºä¸ªäººçš„AIèŠå¤©åŠ©æ‰‹\ngabrielchua/open-notebooklm: Convert any PDF into a podcast episode!\ngetomni-ai/zerox: Zero shot pdf OCR with gpt-4o-mini\nopendatalab/PDF-Extract-Kit: A Comprehensive Toolkit for High-Quality PDF Content Extraction\nNutlope/llama-ocr: Document to Markdown OCR library with Llama 3.2 vision\nopendatalab/MinerU: A high-quality tool for convert PDF to Markdown and JSON.ä¸€ç«™å¼å¼€æºé«˜è´¨é‡æ•°æ®æå–å·¥å…·ï¼Œå°†PDFè½¬æ¢æˆMarkdownå’ŒJSONæ ¼å¼ã€‚\nå…¶ä»– Ucas-HaoranWei/GOT-OCR2.0: Official code implementation of General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model\ndeepseek-ai/DeepSeek-VL: DeepSeek-VL: Towards Real-World Vision-Language Understanding\ndynobo/normcap: OCR powered screen-capture tool to capture information instead of images\nmodelscope/DiffSynth-Studio: Enjoy the magic of Diffusion models!\nabi/screenshot-to-code: Drop in a screenshot and convert it to clean code (HTML/Tailwind/React/Vue)\nstackblitz/bolt.new: Prompt, run, edit, and deploy full-stack web applications\nlean-dojo/LeanCopilot: LLMs as Copilots for Theorem Proving in Lean\ngeekan/MetaGPT: ğŸŒŸ The Multi-Agent Framework: First AI Software Company, Towards Natural Language Programming\nprinceton-nlp/SWE-agent: [NeurIPS 2024] SWE-agent takes a GitHub issue and tries to automatically fix it, using GPT-4, or your LM of choice. It can also be employed for offensive cybersecurity or competitive coding challenges.\nOpenCodeInterpreter/OpenCodeInterpreter: OpenCodeInterpreter is a suite of open-source code generation systems aimed at bridging the gap between large language models and sophisticated proprietary systems like the GPT-4 Code Interpreter. It significantly enhances code generation capabilities by integrating execution and iterative refinement functionalities.\nIkaros-521/AI-Vtuber: AI Vtuberæ˜¯ä¸€ä¸ªç”± ã€ChatterBot/ChatGPT/claude/langchain/chatglm/text-gen-webui/é—»è¾¾/åƒé—®/kimi/ollamaã€‘ é©±åŠ¨çš„è™šæ‹Ÿä¸»æ’­ã€Live2D/UE/xunirenã€‘ï¼Œå¯ä»¥åœ¨ ã€Bilibili/æŠ–éŸ³/å¿«æ‰‹/å¾®ä¿¡è§†é¢‘å·/æ‹¼å¤šå¤š/æ–—é±¼/YouTube/twitch/TikTokã€‘ ç›´æ’­ä¸­ä¸è§‚ä¼—å®æ—¶äº’åŠ¨ æˆ– ç›´æ¥åœ¨æœ¬åœ°è¿›è¡ŒèŠå¤©ã€‚å®ƒä½¿ç”¨TTSæŠ€æœ¯ã€edge-tts/VITS/elevenlabs/bark/bert-vits2/ç¿å£°ã€‘ç”Ÿæˆå›ç­”å¹¶å¯ä»¥é€‰æ‹©ã€so-vits-svc/DDSP-SVCã€‘å˜å£°ï¼›æŒ‡ä»¤ååŒSDç”»å›¾ã€‚\nGitHub - 3b1b/manim: Animation engine for explanatory math videos\nGitHub - ManimCommunity/manim: A community-maintained Python framework for creating mathematical animations.\nGitHub - KindXiaoming/pykan: Kolmogorov Arnold Networks\nGitHub - PeterH0323/Streamer-Sales: Streamer-Sales é”€å†  â€”â€” å–è´§ä¸»æ’­å¤§æ¨¡å‹ï¼Œä¸€ä¸ªèƒ½å¤Ÿæ ¹æ®ç»™å®šçš„å•†å“ç‰¹ç‚¹å¯¹å•†å“è¿›è¡Œè§£è¯´å¹¶æ¿€å‘ç”¨æˆ·çš„è´­ä¹°æ„æ„¿çš„å–è´§ä¸»æ’­æ¨¡å‹\nFujiwaraChoki/MoneyPrinter: Automate Creation of YouTube Shorts using MoviePy.\nprinceton-nlp/SWE-agent: SWE-agent takes a GitHub issue and tries to automatically fix it, using GPT-4. It solves 12.29% of bugs in the SWE-bench evaluation set (comparable to Devin) and take just 1.5 minutes to run (7x faster than Devin).\nharry0703/MoneyPrinterTurbo: åˆ©ç”¨AIå¤§æ¨¡å‹ï¼Œä¸€é”®ç”Ÿæˆé«˜æ¸…çŸ­è§†é¢‘ Generate short videos with one click using AI LLM.\nidootop/mi-gpt: ğŸ  å°†å°çˆ±éŸ³ç®±æ¥å…¥ ChatGPT å’Œè±†åŒ…ï¼Œæ”¹é€ æˆä½ çš„ä¸“å±è¯­éŸ³åŠ©æ‰‹ã€‚\nwan-h/awesome-digital-human-live2d: Awesome Digital Human\nopenai/swarm: Educational framework exploring ergonomic, lightweight multi-agent orchestration. Managed by OpenAI Solution team.\nmeta-llama/llama-recipes: Scripts for fine-tuning Meta Llama with composable FSDP \u0026 PEFT methods to cover single/multi-node GPUs. Supports default \u0026 custom datasets for applications such as summarization and Q\u0026A. Supporting a number of candid inference solutions such as HF TGI, VLLM for local or cloud deployment. Demo apps to showcase Meta Llama for WhatsApp \u0026 Messenger.\nHqWu-HITCS/Awesome-Chinese-LLM: æ•´ç†å¼€æºçš„ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹ï¼Œä»¥è§„æ¨¡è¾ƒå°ã€å¯ç§æœ‰åŒ–éƒ¨ç½²ã€è®­ç»ƒæˆæœ¬è¾ƒä½çš„æ¨¡å‹ä¸ºä¸»ï¼ŒåŒ…æ‹¬åº•åº§æ¨¡å‹ï¼Œå‚ç›´é¢†åŸŸå¾®è°ƒåŠåº”ç”¨ï¼Œæ•°æ®é›†ä¸æ•™ç¨‹ç­‰ã€‚\nHannibal046/Awesome-LLM: Awesome-LLM: a curated list of Large Language Model\nexcalidraw/excalidraw: Virtual whiteboard for sketching hand-drawn like diagrams\nmeltylabs/melty: Chat first code editor. To download the packaged app:\ngpt-omni/mini-omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex Capabilitiesã€‚\n",
    "description": "",
    "tags": null,
    "title": "é¡¹ç›®çš„ GitHub ä¸»é¡µ",
    "uri": "/01_aigc_object/02_github/"
  },
  {
    "content": "é¡¹ç›®çš„ Hugging Face Space OminiControl - a Hugging Face Space by Yuanshi 2024-11-27\nACE-Chat - a Hugging Face Space by scepter-studio\nMoGe - a Hugging Face Space by Ruicheng\nEzAudio - a Hugging Face Space by OpenSound\nNaturalSpeech3 FACodec - a Hugging Face Space by amphion\nIDM VTON - a Hugging Face Space by yisol\nAnimateDiff-Lightning - a Hugging Face Space by ByteDance\nOmost - a Hugging Face Space by lllyasviel\nCLIP Interrogator - a Hugging Face Space by pharmapsychotic\nPyramid Flow - a Hugging Face Space by Pyramid-Flow\nJoy Caption Alpha Two - a Hugging Face Space by fancyfeast\nIC Light V2 - a Hugging Face Space by lllyasviel\nMaskGCT TTS Demo - a Hugging Face Space by amphion\nOmniGen - a Hugging Face Space by Shitao\nMotionCLR - a Hugging Face Space by EvanTHU\nSeedEdit-APP-V1.0 - a Hugging Face Space by ByteDance\nFramer - a Hugging Face Space by wwen1997\nBRIA RMBG 2.0 - a Hugging Face Space by briaai\nMinerU - a Hugging Face Space by opendatalab\nQwen Turbo 1M Demo - a Hugging Face Space by Qwen\nDimensionX - a Hugging Face Space by fffiloni\nPhotoMaker V2 - a Hugging Face Space by TencentARC\nOOTDiffusion - a Hugging Face Space by levihsu\nmoondream2 - a Hugging Face Space by vikhyatk\n",
    "description": "",
    "tags": null,
    "title": "Hugging Face Space",
    "uri": "/01_aigc_object/03_hugging/"
  },
  {
    "content": "AIGC ç›¸å…³ç½‘ç«™ Discover and download free videos - Pixabay\nDanbooru: Anime Image Board\nDiscover the Best GPTs\nAIå·¥å…·é›† | 700+ AIå·¥å…·é›†åˆå®˜ç½‘ï¼Œå›½å†…å¤–AIå·¥å…·é›†å¯¼èˆªå¤§å…¨\nSupertools | Best AI Tools Guide\nAIGCå¯¼èˆª | 1500+å…¨å“ç±»AIGCåˆ›ä½œå·¥å…·_æ¢ç´¢æ›´å¤šå¯èƒ½ï¼\næ’ç”»äº¤æµç½‘ç«™[pixiv]\nArtStation - Explore\nAIbase - æ™ºèƒ½åŒ¹é…æœ€é€‚åˆæ‚¨çš„AIäº§å“å’Œç½‘ç«™\nNewsfeed - Sketchfab\nAI Model \u0026 API Providers Analysis | Artificial Analysis\nxAI\nGGACæ•°å­—è‰ºæœ¯å¹³å°\nWeird Wonderful AI Art | ART of the future - now!\nç›¸å…³æ–‡æ¡£èµ„æ–™ ä½¿ç”¨ diffusers è®­ç»ƒä½ è‡ªå·±çš„ ControlNet ğŸ§¨\nStable Diffusion QR Code 101\nE-Hentai/íƒœê·¸ - ë‚˜ë¬´ìœ„í‚¤\né­”å’’ç™¾ç§‘è¯å…¸\nSo-VITS-SVC 4.1 æ•´åˆåŒ…å®Œå…¨æŒ‡å—\nStable Diffusion 3.5 Prompt Guide â€” Stability AI\nä½¿ç”¨ ChatGPT è¿›è¡Œå†™ä½œçš„å­¦ç”ŸæŒ‡å— |å¼€æ”¾äººå·¥æ™ºèƒ½ â€” A Studentâ€™s Guide to Writing with ChatGPT | OpenAI\nrichards199999/Thinking-Claude: Let your Claude able to think\nhesamsheikh/ml-retreat: Machine Learning Journal for Intermediate to Advanced Topics.\nMidjourney Documentation and User Guide\nå½’æ¡£(å¯ä»¥ä¸ç”¨çœ‹) Resources for GAN Artists\nDisco Diffusion Portrait Study (by @enviraldesign) - Google æ–‡æ¡£\nalibaba/animate-anything: Fine-Grained Open Domain Image Animation with Motion Guidance\nGitHub - prophesier/diff-svc: Singing Voice Conversion via diffusion model\nTencentARC/GFPGAN: GFPGAN aims at developing Practical Algorithms for Real-world Face Restoration.\nguide to installing disco v5+ locally on windows\nclip_interrogator.ipynb - Colaboratory\nA Travelerâ€™s Guide to the Latent Space\nCoarâ€™s Disco Diffusion Guide\nDisco Diffusion Illustrated Settings\nAi generative art tools\nAIç»˜ç”»çš„å…³é”®è¯ï¼ˆç¾¤å‹ä»¬çš„ç”» ï¼‰\nArtist Studies by @remi_durant\nCLIP Prompt Engineering for Generative Art - matthewmcateer.me\næ•°æ®é›†-LAION-400-MILLION OPEN DATASET | LAION\n",
    "description": "",
    "tags": null,
    "title": "AIGC ç›¸å…³ç½‘ç«™",
    "uri": "/01_aigc_object/04_web/"
  },
  {
    "content": "ç›¸å…³æ–‡æ¡£èµ„æ–™ ä½¿ç”¨ diffusers è®­ç»ƒä½ è‡ªå·±çš„ ControlNet ğŸ§¨\nStable Diffusion QR Code 101\nE-Hentai/íƒœê·¸ - ë‚˜ë¬´ìœ„í‚¤\né­”å’’ç™¾ç§‘è¯å…¸\nSo-VITS-SVC 4.1 æ•´åˆåŒ…å®Œå…¨æŒ‡å—\nStable Diffusion 3.5 Prompt Guide â€” Stability AI\nä½¿ç”¨ ChatGPT è¿›è¡Œå†™ä½œçš„å­¦ç”ŸæŒ‡å— |å¼€æ”¾äººå·¥æ™ºèƒ½ â€” A Studentâ€™s Guide to Writing with ChatGPT | OpenAI\nrichards199999/Thinking-Claude: Let your Claude able to think\nhesamsheikh/ml-retreat: Machine Learning Journal for Intermediate to Advanced Topics.\nMidjourney Documentation and User Guide\nå½’æ¡£(å¯ä»¥ä¸ç”¨çœ‹) Resources for GAN Artists\nDisco Diffusion Portrait Study (by @enviraldesign) - Google æ–‡æ¡£\nalibaba/animate-anything: Fine-Grained Open Domain Image Animation with Motion Guidance\nGitHub - prophesier/diff-svc: Singing Voice Conversion via diffusion model\nTencentARC/GFPGAN: GFPGAN aims at developing Practical Algorithms for Real-world Face Restoration.\nguide to installing disco v5+ locally on windows\nclip_interrogator.ipynb - Colaboratory\nA Travelerâ€™s Guide to the Latent Space\nCoarâ€™s Disco Diffusion Guide\nDisco Diffusion Illustrated Settings\nAi generative art tools\nAIç»˜ç”»çš„å…³é”®è¯ï¼ˆç¾¤å‹ä»¬çš„ç”» ï¼‰\nArtist Studies by @remi_durant\nCLIP Prompt Engineering for Generative Art - matthewmcateer.me\næ•°æ®é›†-LAION-400-MILLION OPEN DATASET | LAION\n",
    "description": "",
    "tags": null,
    "title": "ç›¸å…³æ–‡æ¡£èµ„æ–™",
    "uri": "/01_aigc_object/05_doc/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "å…³äºæˆ‘",
    "uri": "/about/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Categories",
    "uri": "/categories/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Tags",
    "uri": "/tags/"
  }
]
