<!DOCTYPE html>
<html lang="zh-cn">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.101.0">
    <meta name="generator" content="Relearn 5.2.1+tip">
    <meta name="description" content="">
    <meta name="author" content="å´æ˜æ–‡">
    <title>ACGC é¡¹ç›®èµ„æºé›† - aiart.website</title>
    <link href="/01_aigc_object/index.xml" rel="alternate" type="application/rss+xml" title="aiart.website"><link rel="icon" href="/favicon.png" type="image/png" />
    <!-- https://github.com/filamentgroup/loadCSS/blob/master/README.md#how-to-use -->
    <link href="/css/fontawesome-all.min.css?1737954595" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/css/fontawesome-all.min.css?1737954595" rel="stylesheet"></noscript>
    <link href="/css/featherlight.min.css?1737954595" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/css/featherlight.min.css?1737954595" rel="stylesheet"></noscript>
    <link href="/css/auto-complete.css?1737954595" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/css/auto-complete.css?1737954595" rel="stylesheet"></noscript>
    <link href="/css/perfect-scrollbar.min.css?1737954595" rel="stylesheet">
    <link href="/css/nucleus.css?1737954595" rel="stylesheet">
    <link href="/css/fonts.css?1737954595" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/css/fonts.css?1737954595" rel="stylesheet"></noscript>
    <link href="/css/theme.css?1737954595" rel="stylesheet">
    <link href="/css/theme-black.css?1737954595" rel="stylesheet" id="variant-style">
    <link href="/css/ie.css?1737954595" rel="stylesheet">
    <link href="/css/variant.css?1737954595" rel="stylesheet">
    <link href="/css/print.css?1737954595" rel="stylesheet" media="print">
    <script src="/js/variant.js?1737954595"></script>
    <script>
      // hack to let hugo tell us how to get to the root when using relativeURLs, it needs to be called *url= for it to do its magic:
      // https://github.com/gohugoio/hugo/blob/145b3fcce35fbac25c7033c91c1b7ae6d1179da8/transform/urlreplacers/absurlreplacer.go#L72
      var index_url="/index.json";
      var root_url="/";
      var baseUri=root_url.replace(/\/$/, '');
      // translations
      window.T_Copy_to_clipboard = 'å¤åˆ¶åˆ°å‰ªè´´æ¿';
      window.T_Copied_to_clipboard = 'å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼';
      window.T_Copy_link_to_clipboard = 'å°†é“¾æ¥å¤åˆ¶åˆ°å‰ªè´´æ¿';
      window.T_Link_copied_to_clipboard = 'é“¾æ¥å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼';
      // some further base stuff
      var baseUriFull='/';
      window.variants && variants.init( [ 'black' ] );
    </script>
    <script src="/js/jquery.min.js?1737954595" defer></script>
  </head>
  <body class="mobile-support html" data-url="/01_aigc_object/">
    <div id="body" class="default-animation">
      <div id="sidebar-overlay"></div>
      <div id="toc-overlay"></div>
      <nav id="topbar" class="highlightable">
        <div>
          <div id="breadcrumbs">
            <span id="sidebar-toggle-span">
              <a href="#" id="sidebar-toggle" title='å¯¼èˆª (CTRL+ALT+m)'><i class="fas fa-bars fa-fw"></i></a>
            </span>
            <span id="toc-menu" title='ç›®å½• (CTRL+ALT+t)'><i class="fas fa-list-alt fa-fw"></i></span>
            <ol class="links" itemscope itemtype="http://schema.org/BreadcrumbList">
              <meta itemprop="itemListOrder" content="Descending" />
              <li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><meta itemprop="position" content="2" /><a itemprop="item" href="/"><span itemprop="name">aiart.website</span></a> > </li>
              <li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><meta itemprop="position" content="1" /><a itemprop="item" href="/01_aigc_object/" aria-disabled="true"><span itemprop="name">ACGC é¡¹ç›®èµ„æºé›†</span></a></li>
            </ol>
          </div>
          <div class="default-animation progress">
            <div class="wrapper">
<nav id="TableOfContents">
  <ul>
    <li><a href="#é¡¹ç›®å®˜æ–¹ç½‘ç«™">é¡¹ç›®å®˜æ–¹ç½‘ç«™</a></li>
    <li><a href="#github-é¡¹ç›®">GitHub é¡¹ç›®</a></li>
    <li><a href="#hugging-face">Hugging Face</a></li>
    <li><a href="#ç­‰å¾…ä¸­çš„é¡¹ç›®">ç­‰å¾…ä¸­çš„é¡¹ç›®</a></li>
    <li><a href="#é¡¹ç›®å®˜æ–¹ç½‘ç«™-1">é¡¹ç›®å®˜æ–¹ç½‘ç«™</a></li>
    <li><a href="#github-é¡¹ç›®-1">GitHub é¡¹ç›®</a></li>
    <li><a href="#hugging-face-1">Hugging Face</a></li>
    <li><a href="#ç­‰å¾…ä¸­çš„é¡¹ç›®-1">ç­‰å¾…ä¸­çš„é¡¹ç›®</a></li>
    <li><a href="#é¡¹ç›®å®˜æ–¹ç½‘ç«™-2">é¡¹ç›®å®˜æ–¹ç½‘ç«™</a></li>
    <li><a href="#github-é¡¹ç›®-2">GitHub é¡¹ç›®</a></li>
    <li><a href="#hugging-face-2">Hugging Face</a></li>
    <li><a href="#ç­‰å¾…ä¸­çš„é¡¹ç›®-2">ç­‰å¾…ä¸­çš„é¡¹ç›®</a></li>
    <li><a href="#é¡¹ç›®å®˜æ–¹ç½‘ç«™-3">é¡¹ç›®å®˜æ–¹ç½‘ç«™</a></li>
    <li><a href="#github-é¡¹ç›®-3">GitHub é¡¹ç›®</a></li>
    <li><a href="#hugging-face-3">Hugging Face</a></li>
    <li><a href="#ç­‰å¾…ä¸­çš„é¡¹ç›®-3">ç­‰å¾…ä¸­çš„é¡¹ç›®</a></li>
    <li><a href="#é¡¹ç›®å®˜æ–¹ç½‘ç«™-4">é¡¹ç›®å®˜æ–¹ç½‘ç«™</a></li>
    <li><a href="#github-é¡¹ç›®-4">GitHub é¡¹ç›®</a></li>
    <li><a href="#hugging-face-4">Hugging Face</a></li>
    <li><a href="#ç­‰å¾…ä¸­çš„é¡¹ç›®-4">ç­‰å¾…ä¸­çš„é¡¹ç›®</a></li>
    <li><a href="#é¡¹ç›®å®˜æ–¹ç½‘ç«™-5">é¡¹ç›®å®˜æ–¹ç½‘ç«™</a></li>
    <li><a href="#github-é¡¹ç›®-5">GitHub é¡¹ç›®</a></li>
    <li><a href="#hugging-face-5">Hugging Face</a></li>
    <li><a href="#ç­‰å¾…ä¸­çš„é¡¹ç›®-5">ç­‰å¾…ä¸­çš„é¡¹ç›®</a></li>
    <li><a href="#é¡¹ç›®å®˜æ–¹ç½‘ç«™-6">é¡¹ç›®å®˜æ–¹ç½‘ç«™</a></li>
    <li><a href="#github-é¡¹ç›®-6">GitHub é¡¹ç›®</a></li>
    <li><a href="#hugging-face-6">Hugging Face</a></li>
    <li><a href="#ç­‰å¾…ä¸­çš„é¡¹ç›®-6">ç­‰å¾…ä¸­çš„é¡¹ç›®</a></li>
    <li><a href="#é¡¹ç›®å®˜æ–¹ç½‘ç«™-7">é¡¹ç›®å®˜æ–¹ç½‘ç«™</a></li>
    <li><a href="#github-é¡¹ç›®-7">GitHub é¡¹ç›®</a></li>
    <li><a href="#hugging-face-7">Hugging Face</a></li>
    <li><a href="#ç­‰å¾…ä¸­çš„é¡¹ç›®-7">ç­‰å¾…ä¸­çš„é¡¹ç›®</a></li>
    <li><a href="#é¡¹ç›®å®˜æ–¹ç½‘ç«™-8">é¡¹ç›®å®˜æ–¹ç½‘ç«™</a></li>
    <li><a href="#github-é¡¹ç›®-8">GitHub é¡¹ç›®</a></li>
    <li><a href="#hugging-face-8">Hugging Face</a></li>
    <li><a href="#ç­‰å¾…ä¸­çš„é¡¹ç›®-8">ç­‰å¾…ä¸­çš„é¡¹ç›®</a></li>
  </ul>
</nav>
            </div>
          </div>
        </div>
      </nav>
      <main id="body-inner" class="highlightable default" tabindex="-1">
        <div class="flex-block-wrapper">
          <div id="head-tags">
          </div>
          <article class="default">
<h1>ACGC é¡¹ç›®èµ„æºé›†</h1>

<!-- raw HTML omitted -->
<p>AI å‘å±•æ—¥æ–°æœˆå¼‚, å„ç§ é¡¹ç›®/åº”ç”¨/å·¥å…·/èµ„æº&hellip; ä»¤äººå…´å¥‹, è€Œä¸”å¾ˆå¤šéƒ½æ˜¯å…è´¹ä½¿ç”¨, æˆ–è€…å¼€æº.</p>
<p>å†…å®¹ä¸»è¦åˆ†ä¸º <code>é¡¹ç›®çš„å®˜æ–¹ç½‘ç«™</code>, <code>é¡¹ç›®çš„ GitHub ä¸»é¡µ</code>, <code>é¡¹ç›®çš„ Hugging Face Space (å¯åœ¨çº¿è¯•ç”¨)</code>, <code>AIGC ç›¸å…³ç½‘ç«™</code>, <code>ç›¸å…³æ–‡æ¡£èµ„æ–™</code>. å®ƒä»¬ä¹‹é—´å¯èƒ½ä¼šæœ‰é‡å çš„é¡¹ç›®, ä½†éå¸¸å°‘, æˆ‘åšäº†å»é‡, ç¡®ä¿å”¯ä¸€æ€§.</p>
<p>ä»¥ä¸‹é¡¹ç›®æ˜¯æˆªè‡³ 2024 å¹´ 12 æœˆ 9 æ—¥æœé›†æ•´ç†å¹¶åˆ†ç±»:</p>

<ul class="children children-li children-sort-weight">
<li><a href="/01_aigc_object/01_object/" >é¡¹ç›®çš„å®˜æ–¹ç½‘ç«™</a></li><ul></ul>
<li><a href="/01_aigc_object/02_github/" >é¡¹ç›®çš„ GitHub ä¸»é¡µ</a></li><ul></ul>
<li><a href="/01_aigc_object/03_hugging/" >Hugging Face Space</a></li><ul></ul>
<li><a href="/01_aigc_object/04_web/" >AIGC ç›¸å…³ç½‘ç«™</a></li><ul></ul>
<li><a href="/01_aigc_object/05_doc/" >ç›¸å…³æ–‡æ¡£èµ„æ–™</a></li><ul></ul>
<li><a href="/01_aigc_object/06_wait/" >ç­‰å¾…ä¸­çš„é¡¹ç›®</a></li><ul></ul>
</ul>
<p>åé¢æ–°æ·»åŠ , éƒ½ä¼šæ ‡æ³¨æ—¥æœŸ:</p>
<h2 id="é¡¹ç›®å®˜æ–¹ç½‘ç«™">é¡¹ç›®å®˜æ–¹ç½‘ç«™</h2>
<p><a href="https://vercel.com/">Vercel: Build and deploy the best web experiences with the Frontend Cloud</a> 2025-01-27</p>
<p><a href="https://cogagent.aminer.cn/home#/">GLM-PC</a> 2025-01-27</p>
<p><a href="https://www.comfycopilot.dev/">Comfy Copilot</a> 2025-01-27</p>
<h2 id="github-é¡¹ç›®">GitHub é¡¹ç›®</h2>
<p><a href="https://github.com/Mintplex-Labs/anything-llm">Mintplex-Labs/anything-llm: The all-in-one Desktop &amp; Docker AI application with built-in RAG, AI agents, and more.</a> 2025-01-27</p>
<p><a href="https://github.com/chatchat-space/Langchain-Chatchat">chatchat-space/Langchain-Chatchat: Langchain-Chatchatï¼ˆåŸLangchain-ChatGLMï¼‰åŸºäº Langchain ä¸ ChatGLM, Qwen ä¸ Llama ç­‰è¯­è¨€æ¨¡å‹çš„ RAG ä¸ Agent åº”ç”¨ | Langchain-Chatchat (formerly langchain-ChatGLM), local knowledge based LLM (like ChatGLM, Qwen and Llama) RAG and Agent app with langchain</a> 2025-01-27</p>
<p><a href="https://github.com/mudler/LocalAI">mudler/LocalAI: :robot: The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more models architectures. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P inference</a> 2025-01-27</p>
<p><a href="https://github.com/bytedance/UI-TARS">bytedance/UI-TARS</a> 2025-01-27</p>
<p><a href="https://github.com/bytedance/UI-TARS-desktop">bytedance/UI-TARS-desktop: A GUI Agent application based on UI-TARS(Vision-Lanuage Model) that allows you to control your computer using natural language.</a> 2025-01-27</p>
<p><a href="https://github.com/bytedance/X-Dyna">bytedance/X-Dyna: [ArXiv 2024] X-Dyna: Expressive Dynamic Human Image Animation</a> 2025-01-27</p>
<p><a href="https://github.com/baichuan-inc/Baichuan-M1-14B">baichuan-inc/Baichuan-M1-14B</a> 2025-01-27</p>
<p><a href="https://github.com/BoyuanJiang/FitDiT">BoyuanJiang/FitDiT: Official implementation of &ldquo;FitDiT: Advancing the Authentic Garment Details for High-fidelity Virtual Try-on&rdquo;</a> 2025-01-27</p>
<p><a href="https://github.com/hkust-nlp/simpleRL-reason">hkust-nlp/simpleRL-reason: This is a replicate of DeepSeek-R1-Zero and DeepSeek-R1 training on small models with limited data</a> 2025-01-27</p>
<p><a href="https://github.com/huggingface/open-r1">huggingface/open-r1: Fully open reproduction of DeepSeek-R1</a> 2025-01-27</p>
<p><a href="https://github.com/microsoft/AIOpsLab">microsoft/AIOpsLab</a> 2025-01-27</p>
<p><a href="https://github.com/bytedance/pasa">bytedance/pasa: PaSa &ndash; an advanced paper search agent powered by large language models. It can autonomously make a series of decisions, including invoking search tools, reading papers, and selecting relevant references, to ultimately obtain comprehensive and accurate results for complex scholarly queries.</a> 2025-01-27</p>
<h2 id="hugging-face">Hugging Face</h2>
<p><a href="https://huggingface.co/spaces/vincentamato/ARIA">ARIA - a Hugging Face Space by vincentamato</a> 2025-01-27</p>
<p><a href="https://huggingface.co/spaces/FiditeNemini/danbooru-tags-transformer-v2-with-wd-tagger">Danbooru Tags Transformer V2 with WD Tagger &amp; Florence 2 Flux Captioner - a Hugging Face Space by FiditeNemini</a> 2025-01-27</p>
<p><a href="https://huggingface.co/spaces/BoyuanJiang/FitDiT">FitDiT - a Hugging Face Space by BoyuanJiang</a> 2025-01-27</p>
<h2 id="ç­‰å¾…ä¸­çš„é¡¹ç›®">ç­‰å¾…ä¸­çš„é¡¹ç›®</h2>
<p><a href="https://text2edit.github.io/">Text-to-Edit: Controllable End-to-End Video Ad Creation via Multimodal LLMs</a> 2025-01-27</p>
<hr>
<h2 id="é¡¹ç›®å®˜æ–¹ç½‘ç«™-1">é¡¹ç›®å®˜æ–¹ç½‘ç«™</h2>
<p><a href="https://agi.taobao.com/">ä¸‡ç›¸è¥é€ </a> 2025-01-22</p>
<p><a href="https://eko.fellou.ai/">Eko - Production-ready Agent Framework for Developers</a> 2025-01-22</p>
<p><a href="https://www.vidu.cn/">Vidu AI - å…¨çƒé¢†å…ˆçš„AIå†…å®¹ç”Ÿäº§å¹³å°</a> 2025-01-22</p>
<p><a href="https://lumier.iaiuse.com/">Lumier AI</a> 2025-01-22</p>
<p><a href="https://dream-machine.lumalabs.ai/">Boards | Dream Machine</a> 2025-01-22</p>
<p><a href="https://grok.com/">Grok</a> 2025-01-22</p>
<p><a href="https://www.kinetix.tech/">Kinetix | AI Technologies for Character Animation</a> 2025-01-22</p>
<p><a href="https://matrix.tencent.com/ai-detect/ai_gen">å¤§æ¨¡å‹æ£€æµ‹</a> 2025-01-22</p>
<p><a href="https://3d.hunyuan.tencent.com/">è…¾è®¯æ··å…ƒ3D</a> 2025-01-22</p>
<p><a href="https://www.trae.ai/home">Trae - Ship Faster with Trae</a> 2025-01-22</p>
<p><a href="https://github.com/MatrixTeam-AI/RAIN">MatrixTeam-AI/RAIN</a> 2025-01-22</p>
<p><a href="https://www.krea.ai/">KREA</a> 2025-01-22</p>
<p><a href="https://www.firecrawl.dev/">Firecrawl</a> 2025-01-22</p>
<p><a href="https://jina.ai/">Jina AI - æ‚¨çš„æœç´¢ï¼Œå¦‚è™æ·»ç¿¼ï¼</a> 2025-01-22</p>
<p><a href="https://www.co.dev/">Build Full-Stack Web Applications in Minutes with Codev | AI App Builder</a> 2025-01-22</p>
<p><a href="https://llamacoder.together.ai/">Llama Coder â€“ AI Code Generator</a> 2025-01-22</p>
<h2 id="github-é¡¹ç›®-1">GitHub é¡¹ç›®</h2>
<p><a href="https://github.com/mbzuai-oryx/LlamaV-o1">mbzuai-oryx/LlamaV-o1: Rethinking Step-by-step Visual Reasoning in LLMs</a> 2025-01-22</p>
<p><a href="https://github.com/FellouAI/eko">FellouAI/eko: Eko (Eko Keeps Operating) - Build Production-ready Agentic Workflow with Natural Language - eko.fellou.ai</a> 2025-01-22</p>
<p><a href="https://github.com/OpenBMB/MiniCPM-o">OpenBMB/MiniCPM-o: MiniCPM-o 2.6: A GPT-4o Level MLLM for Vision, Speech and Multimodal Live Streaming on Your Phone</a> 2025-01-22</p>
<p><a href="https://github.com/MiniMax-AI/MiniMax-01">MiniMax-AI/MiniMax-01</a> 2025-01-22</p>
<p><a href="https://github.com/ali-vilab/MangaNinjia">ali-vilab/MangaNinjia: Official implementation of &ldquo;MangaNinja: Line Art Colorization with Precise Reference Following&rdquo;</a> 2025-01-22</p>
<p><a href="https://github.com/openai/whisper">openai/whisper: Robust Speech Recognition via Large-Scale Weak Supervision</a> 2025-01-22</p>
<p><a href="https://github.com/rany2/edge-tts">rany2/edge-tts: Use Microsoft Edge&rsquo;s online text-to-speech service from Python WITHOUT needing Microsoft Edge or Windows or an API key</a> 2025-01-22</p>
<p><a href="https://github.com/PRIME-RL/PRIME">PRIME-RL/PRIME: Scalable RL solution for advanced reasoning of language models</a> 2025-01-22</p>
<p><a href="https://github.com/Tencent/Hunyuan3D-2">Tencent/Hunyuan3D-2: High-Resolution 3D Assets Generation with Large Scale Hunyuan3D Diffusion Models.</a> 2025-01-22</p>
<p><a href="https://github.com/VGenAI-Netflix-Eyeline-Research/Go-with-the-Flow">VGenAI-Netflix-Eyeline-Research/Go-with-the-Flow: Motion-Controllable Video Diffusion via Warped Noise</a> 2025-01-22</p>
<p><a href="https://github.com/jixiaozhong/Sonic">jixiaozhong/Sonic: Official implementation of &ldquo;Sonic: Shifting Focus to Global Audio Perception in Portrait Animation&rdquo;</a> 2025-01-22</p>
<h2 id="hugging-face-1">Hugging Face</h2>
<p><a href="https://huggingface.co/spaces/FunAudioLLM/CosyVoice2-0.5B">CosyVoice2-0.5B - a Hugging Face Space by FunAudioLLM</a> 2025-01-22</p>
<p><a href="https://huggingface.co/spaces/ysharma/Make_Custom_Voices_With_KokoroTTS">Make Custom Voices With KokoroTTS - a Hugging Face Space by ysharma</a> 2025-01-22</p>
<h2 id="ç­‰å¾…ä¸­çš„é¡¹ç›®-1">ç­‰å¾…ä¸­çš„é¡¹ç›®</h2>
<p><a href="https://yuzhou914.github.io/ConceptMaster/">ConceptMaster</a> 2025-01-22</p>
<p><a href="https://igl-hkust.github.io/das/">Diffusion as Shader: 3D-aware Video Diffusion for Versatile Video Generation Control</a> 2025-01-22</p>
<p><a href="https://www.microsoft.com/en-us/research/publication/mattergen-a-generative-model-for-inorganic-materials-design/">MatterGen: a generative model for inorganic materials design - Microsoft Research</a> 2025-01-22</p>
<p><a href="https://github.com/YBYBZhang/FramePainter">YBYBZhang/FramePainter: [arXiv 2025] Official pytorch implementation of &ldquo;FramePainter: Endowing Interactive Image Editing with Video Diffusion Priors&rdquo;</a> 2025-01-22</p>
<p><a href="https://lingtengqiu.github.io/2024/AniGS/">AniGS</a> 2025-01-22</p>
<hr>
<h2 id="é¡¹ç›®å®˜æ–¹ç½‘ç«™-2">é¡¹ç›®å®˜æ–¹ç½‘ç«™</h2>
<p><a href="https://www.iamcreate.ai/en-US">CreateAI</a> 2025-01-14</p>
<p><a href="https://minimaxi.com/">MiniMax-ä¸ç”¨æˆ·å…±åˆ›æ™ºèƒ½</a> 2025-01-14</p>
<p><a href="https://mplx.run/">MiniPerplx</a> 2025-01-14</p>
<p><a href="https://idx.dev/">Project IDX</a> 2025-01-14</p>
<p><a href="https://marketplace.dify.ai/">Dify Marketplace</a> 2025-01-14</p>
<p><a href="https://aic.oceanengine.com/login">å³åˆ› - ä¸€ç«™å¼æ™ºèƒ½åˆ›æ„ç”Ÿäº§ä¸ç®¡ç†å¹³å°</a> 2025-01-14</p>
<p><a href="https://tongyi.aliyun.com/wanxiang/">é€šä¹‰ä¸‡ç›¸_AIåˆ›æ„ä½œç”»_AIç»˜ç”»_äººå·¥æ™ºèƒ½-é˜¿é‡Œäº‘</a> 2025-01-14</p>
<p><a href="https://chat.qwenlm.ai/">Qwen</a> 2025-01-14</p>
<h2 id="github-é¡¹ç›®-2">GitHub é¡¹ç›®</h2>
<p><a href="https://github.com/DrewThomasson/ebook2audiobook">DrewThomasson/ebook2audiobook: Convert ebooks to audiobooks with chapters and metadata using dynamic AI models and voice cloning. Supports 1,107+ languages!</a> 2025-01-14</p>
<p><a href="https://github.com/Snowfallingplum/SHMT">Snowfallingplum/SHMT: [NeurIPS 2024] SHMT: Self-supervised Hierarchical Makeup Transfer via Latent Diffusion Models</a> 2025-01-14</p>
<p><a href="https://github.com/xyfJASON/ctrlora">xyfJASON/ctrlora: Codebase for &ldquo;CtrLoRA: An Extensible and Efficient Framework for Controllable Image Generation&rdquo;</a> 2025-01-14</p>
<p><a href="https://github.com/VITA-MLLM/VITA">VITA-MLLM/VITA: âœ¨âœ¨VITA-1.5: Towards GPT-4o Level Real-Time Vision and Speech Interaction</a> 2025-01-14</p>
<p><a href="https://github.com/NJU-PCALab/STAR">NJU-PCALab/STAR: STAR: Spatial-Temporal Augmentation with Text-to-Video Models for Real-World Video Super-Resolution</a> 2025-01-14</p>
<p><a href="https://github.com/wileewang/TransPixar">wileewang/TransPixar</a> 2025-01-14</p>
<p><a href="https://github.com/Stability-AI/stable-point-aware-3d">Stability-AI/stable-point-aware-3d</a> 2025-01-14</p>
<p><a href="https://github.com/SagiPolaczek/NeuralSVG">SagiPolaczek/NeuralSVG: Official implementation of NerualSVG</a> 2025-01-14</p>
<p><a href="https://github.com/ali-vilab/TeaCache">ali-vilab/TeaCache: Timestep Embedding Tells: It&rsquo;s Time to Cache for Video Diffusion Model</a> 2025-01-14</p>
<p><a href="https://github.com/LituRout/RF-Inversion">LituRout/RF-Inversionï¼šæ•´æµæµåæ¼”ï¼ˆRF-Inversionï¼‰ &mdash; LituRout/RF-Inversion: Rectified Flow Inversion (RF-Inversion)</a> 2025-01-14</p>
<p><a href="https://github.com/fudan-generative-vision/hallo3">fudan-generative-vision/hallo3: Hallo3: Highly Dynamic and Realistic Portrait Image Animation with Diffusion Transformer Networks</a> 2025-01-14</p>
<p><a href="https://github.com/sczhou/Upscale-A-Video">sczhou/Upscale-A-Video: [CVPR 2024] Upscale-A-Video: Temporal-Consistent Diffusion Model for Real-World Video Super-Resolution</a> 2025-01-14</p>
<p><a href="https://github.com/somanchiu/ReSwapper">somanchiu/ReSwapper: ReSwapper aims to reproduce the implementation of inswapper. This repository provides code for training, inference, and includes pretrained weights.</a> 2025-01-14</p>
<p><a href="https://github.com/wangzhiyaoo/SVFR">wangzhiyaoo/SVFR: Official implementation of SVFR.</a> 2025-01-14</p>
<h2 id="hugging-face-2">Hugging Face</h2>
<p><a href="https://huggingface.co/spaces/drewThomasson/ebook2audiobook">Ebook2audiobook V2.0 Beta - a Hugging Face Space by drewThomasson</a> 2025-01-14</p>
<p><a href="https://huggingface.co/spaces/fffiloni/LatentSync">LatentSync - a Hugging Face Space by fffiloni</a> 2025-01-14</p>
<h2 id="ç­‰å¾…ä¸­çš„é¡¹ç›®-2">ç­‰å¾…ä¸­çš„é¡¹ç›®</h2>
<p><a href="https://iceclear.github.io/projects/seedvr/">SeedVR</a> 2025-01-14</p>
<p><a href="https://www.wlyu.me/FaceLift/">FaceLift: Single Image to 3D Head with View Generation and GS-LRM</a> 2025-01-14</p>
<hr>
<h2 id="é¡¹ç›®å®˜æ–¹ç½‘ç«™-3">é¡¹ç›®å®˜æ–¹ç½‘ç«™</h2>
<p><a href="https://deepseek-artifacts.vercel.app/?">Deepseek Artifacts - Experience the power of the world&rsquo;s best open source model.</a> 2025-01-05</p>
<p><a href="https://www.typingmind.com/?">TypingMind â€” LLM Frontend Chat UI for AI models</a> 2025-01-05</p>
<p><a href="https://storm.genie.stanford.edu/">STORM</a> 2025-01-05</p>
<p><a href="https://zoo.dev/">CAD Software for Hardware Design | Zoo</a> 2025-01-05</p>
<p><a href="https://openbayes.com/">è®©è®¡ç®—æ›´ç®€å• | OpenBayes è´å¼è®¡ç®—</a> 2025-01-05</p>
<h2 id="github-é¡¹ç›®-3">GitHub é¡¹ç›®</h2>
<p><a href="https://github.com/Fanghua-Yu/SUPIR">Fanghua-Yu/SUPIR: SUPIR aims at developing Practical Algorithms for Photo-Realistic Image Restoration In the Wild. Our new online demo is also released at suppixel.ai.</a> 2025-01-05</p>
<p><a href="https://github.com/declare-lab/TangoFlux">declare-lab/TangoFlux: TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow Matching</a> 2025-01-05</p>
<p><a href="https://github.com/n8n-io/n8n">n8n-io/n8n: Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.</a> 2025-01-05</p>
<p><a href="https://github.com/FoundationVision/Infinity">FoundationVision/Infinity: Infinity âˆ : Scaling Bitwise AutoRegressive Modeling for High-Resolution Image Synthesis</a> 2025-01-05</p>
<p><a href="https://github.com/supermemoryai/supermemory">supermemoryai/supermemory: Build your own second brain with supermemory. It&rsquo;s a ChatGPT for your bookmarks. Import tweets or save websites and content using the chrome extension.</a> 2025-01-05</p>
<p><a href="https://github.com/jianzongwu/DiffSensei">jianzongwu/DiffSensei: Implementation of &ldquo;DiffSensei: Bridging Multi-Modal LLMs and Diffusion Models for Customized Manga Generation&rdquo;</a> 2025-01-05</p>
<p><a href="https://github.com/bytedance/LatentSync">bytedance/LatentSync: Taming Stable Diffusion for Lip Sync!</a> 2025-01-05</p>
<p><a href="https://github.com/DAMO-NLP-SG/multimodal_textbook?tab=readme-ov-file">DAMO-NLP-SG/multimodal_textbook: The official repository for &ldquo;2.5 Years in Class: A Multimodal Textbook for Vision-Language Pretraining&rdquo;</a> 2025-01-05</p>
<p><a href="https://github.com/DAMO-NLP-SG/multimodal_textbook">DAMO-NLP-SG/multimodal_textbook: The official repository for &ldquo;2.5 Years in Class: A Multimodal Textbook for Vision-Language Pretraining&rdquo;</a> 2025-01-05</p>
<p><a href="https://github.com/DAMO-NLP-SG/VideoRefer">DAMO-NLP-SG/VideoRefer: The code for &ldquo;VideoRefer Suite: Advancing Spatial-Temporal Object Understanding with Video LLM&rdquo;</a> 2025-01-05</p>
<p><a href="https://github.com/hustvl/LightningDiT">hustvl/LightningDiT: [arXiv'25] Reconstruction vs. Generation: Taming Optimization Dilemma in Latent Diffusion Models</a> 2025-01-05</p>
<h2 id="hugging-face-3">Hugging Face</h2>
<p><a href="https://huggingface.co/spaces/declare-lab/TangoFlux">TangoFlux - a Hugging Face Space by declare-lab</a> 2025-01-05</p>
<p><a href="https://huggingface.co/spaces/hexgrad/Kokoro-TTS">Kokoro TTS - a Hugging Face Space by hexgrad</a> 2025-01-05</p>
<p><a href="https://huggingface.co/spaces/ZJYang/AniPortrait_official">AniPortrait Official - a Hugging Face Space by ZJYang</a> 2025-01-05</p>
<h2 id="ç­‰å¾…ä¸­çš„é¡¹ç›®-3">ç­‰å¾…ä¸­çš„é¡¹ç›®</h2>
<p><a href="https://videoanydoor.github.io/">VideoAnydoor: High-fidelity Video Object Insertion with Precise Motion Control</a> 2025-01-05</p>
<p><a href="https://codeelo-bench.github.io/">CodeElo</a> 2025-01-05</p>
<hr>
<h2 id="é¡¹ç›®å®˜æ–¹ç½‘ç«™-4">é¡¹ç›®å®˜æ–¹ç½‘ç«™</h2>
<p><a href="https://lovable.dev/">Lovable</a> 2025-01-02</p>
<p><a href="https://monica.im/">Monica - ChatGPT AI Assistant | GPT-4o, Claude 3.5, Gemini 1.5</a> 2025-01-02</p>
<p><a href="https://voicenotes.com/">Voicenotes: Transcribe notes, meetings &amp; ask AI</a> 2025-01-02</p>
<p><a href="https://youmind.ai/">YouMind - AI Creation System</a> 2025-01-02</p>
<h2 id="github-é¡¹ç›®-4">GitHub é¡¹ç›®</h2>
<p><a href="https://github.com/IDEA-Research/GroundingDINO">IDEA-Research/GroundingDINO: [ECCV 2024] Official implementation of the paper &ldquo;Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection&rdquo;</a> 2025-01-02</p>
<p><a href="https://github.com/Yuan-ManX/ai-game-devtools">Yuan-ManX/ai-game-devtools: Here we will keep track of the latest AI Game Development Tools, including LLM, Agent, Code, Writer, Image, Texture, Shader, 3D Model, Animation, Video, Audio, Music, Singing Voice and Analytics. ğŸ”¥</a> 2025-01-02</p>
<p><a href="https://github.com/yandex-research/switti">yandex-research/switti: The code and models for the paper: Switti: Designing Scale-Wise Transformers for Text-to-Image Synthesis</a> 2025-01-02</p>
<p><a href="https://github.com/FreedomIntelligence/HuatuoGPT-o1">FreedomIntelligence/HuatuoGPT-o1: Medical o1, Towards medical complex reasoning with LLMs</a> 2025-01-02</p>
<p><a href="https://github.com/vllm-project/vllm">vllm-project/vllm: A high-throughput and memory-efficient inference and serving engine for LLMs</a> 2025-01-02</p>
<p><a href="https://github.com/sgl-project/sglang">sgl-project/sglang: SGLang is a fast serving framework for large language models and vision language models.</a> 2025-01-02</p>
<p><a href="https://github.com/modelscope/DiffSynth-Studio">modelscope/DiffSynth-Studio: Enjoy the magic of Diffusion models!</a> 2025-01-02</p>
<p><a href="https://github.com/cline/cline">cline/cline: Autonomous coding agent right in your IDE, capable of creating/editing files, executing commands, using the browser, and more with your permission every step of the way.</a> 2025-01-02</p>
<p><a href="https://github.com/OpenDriveLab/agibot-world">OpenDriveLab/AgiBot-World: World&rsquo;s First Large-scale High-quality Robotic Manipulation Benchmark</a> 2025-01-02</p>
<p><a href="https://github.com/huggingface/smolagents">huggingface/smolagents: ğŸ¤— smolagents: a barebones library for agents. Agents write python code to call tools and orchestrate other agents.</a> 2025-01-02</p>
<p><a href="https://github.com/TMElyralab/MusePose">TMElyralab/MusePose: MusePose: a Pose-Driven Image-to-Video Framework for Virtual Human Generation</a> 2025-01-02</p>
<p><a href="https://github.com/SpatialVision/Orient-Anything">SpatialVision/Orient-Anything</a> 2025-01-02</p>
<p><a href="https://github.com/ixarchakos/try-off-anyone">ixarchakos/try-off-anyone: Official repository of &ldquo;TryOffAnyone: Tiled Cloth Generation from a Dressed Person&rdquo;</a> 2025-01-02</p>
<h2 id="hugging-face-4">Hugging Face</h2>
<p><a href="https://huggingface.co/spaces/hkchengrex/MMAudio">MMAudio â€” generating synchronized audio from video/text - a Hugging Face Space by hkchengrex</a> 2025-01-02</p>
<p><a href="https://huggingface.co/spaces/akhaliq/anychat">Anychat - a Hugging Face Space by akhaliq</a> 2025-01-02</p>
<p><a href="https://huggingface.co/spaces/jbilcke-hf/FacePoke">FacePoke - a Hugging Face Space by jbilcke-hf</a> 2025-01-02</p>
<p><a href="https://huggingface.co/spaces/jbilcke-hf/ai-comic-factory">AI Comic Factory - a Hugging Face Space by jbilcke-hf</a> 2025-01-02</p>
<p><a href="https://huggingface.co/spaces/dbaranchuk/Switti-1024">Switti - a Hugging Face Space by dbaranchuk</a> 2025-01-02</p>
<p><a href="https://huggingface.co/spaces/ginipick/Dokdo-multimodal">Dokdo Multimodal - a Hugging Face Space by ginipick</a> 2025-01-02</p>
<p><a href="https://huggingface.co/spaces/ginigen/Dokdo">Dokdo - a Hugging Face Space by ginigen</a> 2025-01-02</p>
<h2 id="ç­‰å¾…ä¸­çš„é¡¹ç›®-4">ç­‰å¾…ä¸­çš„é¡¹ç›®</h2>
<p><a href="https://fanegg.github.io/Feat2GS/">Feat2GS</a> 2025-01-02</p>
<p><a href="https://m-usamasaleem.github.io/publication/GenHMR/GenHMR.html">GenHMR: Generative Human Mesh Recovery</a> 2025-01-02</p>
<p><a href="https://chenglin-yang.github.io/1.58bit.flux.github.io/">1.58-bit FLUX</a> 2025-01-02</p>
<p><a href="https://muelea.github.io/hsfm/">HSfM</a> 2025-01-02</p>
<p><a href="https://hyunsoocha.github.io/perse/">PERSE: Personalized 3D Generative Avatars from A Single Portrait</a> 2025-01-02</p>
<p><a href="https://vmix-diffusion.github.io/VMix/">VMix: Improving Text-to-Image Diffusion Model with Cross-Attention Mixing Control</a> 2025-01-02</p>
<hr>
<h2 id="é¡¹ç›®å®˜æ–¹ç½‘ç«™-5">é¡¹ç›®å®˜æ–¹ç½‘ç«™</h2>
<p><a href="https://www.projectodyssey.ai/">Project Odyssey</a> 2024-12-30</p>
<p><a href="https://www.comfyonline.app/zh">åœ¨çº¿è¿è¡Œ ComfyUI å·¥ä½œæµå¹¶ä¸€é”®éƒ¨ç½² API - ComfyOnline</a> 2024-12-30</p>
<p><a href="https://www.bigmodel.cn/">æ™ºè°±AIå¼€æ”¾å¹³å°</a> 2024-12-30</p>
<p><a href="https://replit.com/">Replit â€“Â Build apps and sites with AI</a> 2024-12-30</p>
<p><a href="https://aigcpanel.com/">AIGCPanel | å¼€æºAIæ•°å­—äººç³»ç»Ÿ</a> 2024-12-30</p>
<p><a href="https://platform.stepfun.com/">é˜¶è·ƒæ˜Ÿè¾°å¼€æ”¾å¹³å°</a> 2024-12-30</p>
<p><a href="https://fireworks.ai/">Fireworks - Fastest Inference for Generative AI</a> 2024-12-30</p>
<p><a href="https://platform.baichuan-ai.com/homePage">ç™¾å·å¤§æ¨¡å‹-æ±‡èšä¸–ç•ŒçŸ¥è¯† åˆ›ä½œå¦™ç¬”ç”ŸèŠ±-ç™¾å·æ™ºèƒ½</a> 2024-12-30</p>
<p><a href="https://domoai.app/">DomoAI | AI Art Generator &amp; Video to Animation Converter</a> 2024-12-30</p>
<p><a href="https://www.iamcreate.ai/zh-CN/">CreateAI</a> 2024-12-30</p>
<p><a href="https://magnific.ai/">Magnific AI â€” The magic image Upscaler &amp; Enhancer</a> 2024-12-30</p>
<p><a href="https://odyssey.systems/">Odyssey</a> 2024-12-30</p>
<p><a href="https://nexa.ai/">Nexa AI | Enterprise-Grade On-Device AI for Every Device</a> 2024-12-30</p>
<p><a href="https://humane.com/">Humane Ai Pin | See the World, Not Your Screen. | Humane</a> 2024-12-30</p>
<p><a href="https://intern-ai.org.cn/home">ä¹¦ç”Ÿ</a> 2024-12-30</p>
<p><a href="https://taipy.io/">Taipy â€” Build Python Data &amp; BI web applications</a> 2024-12-30</p>
<h2 id="github-é¡¹ç›®-5">GitHub é¡¹ç›®</h2>
<p><a href="https://github.com/facebookresearch/blt">facebookresearch/blt: Code for BLT research paper</a> 2024-12-30</p>
<p><a href="https://github.com/VideoVerses/VideoVAEPlus">VideoVerses/VideoVAEPlus</a> 2024-12-30</p>
<p><a href="https://github.com/TencentARC/DI-PCG">TencentARC/DI-PCG: Code release of our paper &ldquo;DI-PCG: Diffusion-based Efficient Inverse Procedural Content Generation for High-quality 3D Asset Creation&rdquo;.</a> 2024-12-30</p>
<p><a href="https://github.com/QwenLM/Qwen2-VL">QwenLM/Qwen2-VL: Qwen2-VL is the multimodal large language model series developed by Qwen team, Alibaba Cloud.</a> 2024-12-30</p>
<p><a href="https://github.com/web-infra-dev/midscene">web-infra-dev/midscene: An AI-powered automation SDK can control the page, perform assertions, and extract data in JSON format using natural language.</a> 2024-12-30</p>
<p><a href="https://github.com/hpcaitech/Open-Sora">hpcaitech/Open-Sora: Open-Sora: Democratizing Efficient Video Production for All</a> 2024-12-30</p>
<p><a href="https://github.com/osanseviero/geminiCoder">osanseviero/geminiCoder: Create apps with Gemini</a> 2024-12-30</p>
<p><a href="https://github.com/IamCreateAI/Ruyi-Models">IamCreateAI/Ruyi-Models</a> 2024-12-30</p>
<p><a href="https://github.com/rasbt/LLMs-from-scratch">rasbt/LLMs-from-scratch: Implement a ChatGPT-like LLM in PyTorch from scratch, step by step</a> 2024-12-30</p>
<p><a href="https://github.com/getmaxun/maxun">getmaxun/maxun: ğŸ”¥ Open-source no-code web data extraction platform. Turn websites to APIs and spreadsheets with no-code robots in minutes! [In Beta]</a> 2024-12-30</p>
<p><a href="https://github.com/SakanaAI/asal">SakanaAI/asal: Automating the Search for Artificial Life with Foundation Models!</a> 2024-12-30</p>
<p><a href="https://github.com/fallenshock/FlowEdit">fallenshock/FlowEdit: Official implementation of the paper: &ldquo;FlowEdit: Inversion-Free Text-Based Editing Using Pre-Trained Flow Models&rdquo;</a> 2024-12-30</p>
<p><a href="https://github.com/mingyuan-zhang/LMM">mingyuan-zhang/LMM: Large Motion Model for Unified Multi-Modal Motion Generation</a> 2024-12-30</p>
<p><a href="https://github.com/TencentARC/StereoCrafter">TencentARC/StereoCrafter: A framework to convert any 2D videos to immersive stereoscopic 3D</a> 2024-12-30</p>
<p><a href="https://github.com/THUDM/CogAgent">THUDM/CogAgent: An open-sourced end-to-end VLM-based GUI Agent</a> 2024-12-30</p>
<p><a href="https://github.com/AriaUI/Aria-UI">AriaUI/Aria-UI: Aria-UI: Visual Grounding for GUI Instructions</a> 2024-12-30</p>
<p><a href="https://github.com/modstart-lib/aigcpanel">modstart-lib/aigcpanel: AigcPanel æ˜¯ä¸€ä¸ªç®€å•æ˜“ç”¨çš„ä¸€ç«™å¼AIæ•°å­—äººç³»ç»Ÿï¼Œæ”¯æŒè§†é¢‘åˆæˆã€å£°éŸ³åˆæˆã€å£°éŸ³å…‹éš†ï¼Œç®€åŒ–æœ¬åœ°æ¨¡å‹ç®¡ç†ã€ä¸€é”®å¯¼å…¥å’Œä½¿ç”¨AIæ¨¡å‹ã€‚</a> 2024-12-30</p>
<p><a href="https://github.com/krystalan/DRT-o1">krystalan/DRT-o1: DRT-o1: Optimized Deep Reasoning Translation via Long Chain-of-Thought</a> 2024-12-30</p>
<p><a href="https://github.com/zsyOAOA/InvSR">zsyOAOA/InvSR: Arbitrary-steps Image Super-resolution via Diffusion Inversion</a> 2024-12-30</p>
<p><a href="https://github.com/livekit/agents">livekit/agents: Build real-time multimodal AI applications ğŸ¤–ğŸ™ï¸ğŸ“¹</a> 2024-12-30</p>
<p><a href="https://github.com/modelscope/ClearerVoice-Studio">modelscope/ClearerVoice-Studio: An AI-Powered Speech Processing Toolkit and Open Source SOTA Pretrained Models, Supporting Speech Enhancement, Separation, and Target Speaker Extraction, etc.</a> 2024-12-30</p>
<p><a href="https://github.com/baaivision/See3D">baaivision/See3D: You See it, You Got it: Learning 3D Creation on Pose-Free Videos at Scale</a> 2024-12-30</p>
<p><a href="https://github.com/Nutlope/picmenu">Nutlope/picMenu: Visualize menus in seconds with AI</a> 2024-12-30</p>
<p><a href="https://github.com/Avaiga/taipy">Avaiga/taipy: Turns Data and AI algorithms into production-ready web applications in no time.</a> 2024-12-30</p>
<h2 id="hugging-face-5">Hugging Face</h2>
<p><a href="https://huggingface.co/spaces/Qwen/QVQ-72B-preview">QVQ 72B Preview - a Hugging Face Space by Qwen</a> 2024-12-30</p>
<p><a href="https://huggingface.co/spaces/lllyasviel/LuminaBrush">LuminaBrush - a Hugging Face Space by lllyasviel</a> 2024-12-30</p>
<p><a href="https://huggingface.co/spaces/OAOA/InvSR">InvSR - a Hugging Face Space by OAOA</a> 2024-12-30</p>
<p><a href="https://huggingface.co/spaces/alibabasglab/ClearVoice">ClearerVoice-Studio (Speech Enhancement, Separation and Extraction) - a Hugging Face Space by alibabasglab</a> 2024-12-30</p>
<h2 id="ç­‰å¾…ä¸­çš„é¡¹ç›®-5">ç­‰å¾…ä¸­çš„é¡¹ç›®</h2>
<p><a href="https://lijiaman.github.io/projects/mvlift/">Lifting Motion to the 3D World via 2D Diffusion</a> 2024-12-30</p>
<p><a href="https://boyiliee.github.io/3DHM.github.io/">Synthesizing Moving People with 3D Control</a> 2024-12-30</p>
<p><a href="https://github.com/pkulwj1994/diff_instruct_pp">pkulwj1994/diff_instruct_pp: We introduce Diff-Instruct++, a novel approach for human preference alignment of 1-step text-to-image generation.</a> 2024-12-30</p>
<p><a href="https://mega-sam.github.io/">MegaSaM</a> 2024-12-30</p>
<p><a href="https://hugofloresgarcia.art/sketch2sound/">Sketch2Sound</a> 2024-12-30</p>
<p><a href="https://grisoon.github.io/INFP/">INFP: Audio-Driven Interactive Head Generation in Dyadic Conversations</a> 2024-12-30</p>
<p><a href="https://causvid.github.io/">From Slow Bidirectional to Fast Causal Video Generators</a> 2024-12-30</p>
<hr>
<h2 id="é¡¹ç›®å®˜æ–¹ç½‘ç«™-6">é¡¹ç›®å®˜æ–¹ç½‘ç«™</h2>
<p><a href="https://zenodo.org/">Zenodo</a> 2024-12-20</p>
<p><a href="https://labs.google/fx/zh/tools/whisk">Whisk</a> 2024-12-20</p>
<p><a href="https://labs.google/fx/zh">labs.google/fx</a> 2024-12-20</p>
<p><a href="https://cloud.infini-ai.com/platform/ai">æ— é—®èŠ¯ç©¹ä¸€ç«™å¼AIå¹³å°</a> 2024-12-20</p>
<p><a href="https://videolingo.io/zh">VideoLingo - AI Subtitles Translation</a> 2024-12-20</p>
<h2 id="github-é¡¹ç›®-6">GitHub é¡¹ç›®</h2>
<p><a href="https://github.com/RedAIGC/Flux-version-LayerDiffuse">RedAIGC/Flux-version-LayerDiffuse</a> 2024-12-20</p>
<p><a href="https://github.com/microsoft/markitdown">microsoft/markitdown: Python tool for converting files and office documents to Markdown.</a> 2024-12-20</p>
<p><a href="https://github.com/franciszzj/Leffa">franciszzj/Leffa: Learning Flow Fields in Attention for Controllable Person Image Generation</a> 2024-12-20</p>
<p><a href="https://github.com/wzhouxiff/ObjCtrl-2.5D">wzhouxiff/ObjCtrl-2.5D: ObjCtrl-2.5D</a> 2024-12-20</p>
<p><a href="https://github.com/ali-vilab/FreeScale">ali-vilab/FreeScale: Code for FreeScale, a tuning-free method for higher-resolution visual generation</a> 2024-12-20</p>
<p><a href="https://github.com/tumurzakov/AnimateDiff">tumurzakov/AnimateDiff: AnimationDiff with train</a> 2024-12-20</p>
<p><a href="https://github.com/hkchengrex/MMAudio">hkchengrex/MMAudio: [arXiv 2024] Taming Multimodal Joint Training for High-Quality Video-to-Audio Synthesis</a> 2024-12-20</p>
<p><a href="https://github.com/TencentARC/BrushEdit">TencentARC/BrushEdit: The official implementation of paper &ldquo;BrushEdit: All-In-One Image Inpainting and Editing&rdquo;</a> 2024-12-20</p>
<p><a href="https://github.com/TencentARC/ColorFlow">TencentARC/ColorFlow: The official implementation of paper &ldquo;ColorFlow: Retrieval-Augmented Image Sequence Colorization&rdquo;</a> 2024-12-20</p>
<p><a href="https://github.com/IamCreateAI/Ruyi-Models/tree/main">IamCreateAI/Ruyi-Models</a> 2024-12-20</p>
<p><a href="https://github.com/Genesis-Embodied-AI/Genesis">Genesis-Embodied-AI/Genesis: A generative world for general-purpose robotics &amp; embodied AI learning.</a> 2024-12-20</p>
<p><a href="https://github.com/Kedreamix/Linly-Dubbing">Kedreamix/Linly-Dubbing: æ™ºèƒ½è§†é¢‘å¤šè¯­è¨€AIé…éŸ³/ç¿»è¯‘å·¥å…· - Linly-Dubbing â€” â€œAIèµ‹èƒ½ï¼Œè¯­è¨€æ— ç•Œâ€</a> 2024-12-20</p>
<p><a href="https://github.com/genmoai/mochi/tree/main">genmoai/mochi: The best OSS video generation models</a> 2024-12-20</p>
<p><a href="https://github.com/guoyww/animatediff/">guoyww/AnimateDiff: Official implementation of AnimateDiff.</a> 2024-12-20</p>
<h2 id="hugging-face-6">Hugging Face</h2>
<p><a href="https://huggingface.co/spaces/TencentARC/BrushEdit">BrushEdit - a Hugging Face Space by TencentARC</a> 2024-12-20</p>
<p><a href="https://huggingface.co/spaces/JeffreyXiang/TRELLIS">TRELLIS - a Hugging Face Space by JeffreyXiang</a> 2024-12-20</p>
<h2 id="ç­‰å¾…ä¸­çš„é¡¹ç›®-6">ç­‰å¾…ä¸­çš„é¡¹ç›®</h2>
<p><a href="https://motion-prompting.github.io/">Motion Prompting: Controlling Video Generation with Motion Trajectories</a> 2024-12-20</p>
<p><a href="https://snap-research.github.io/wonderland/">snap-research.github.io/wonderland/</a> 2024-12-20</p>
<p><a href="https://byteaigc.github.io/X-Portrait2/">X-Portrait 2: Highly Expressive Portrait Animation</a> 2024-12-20</p>
<hr>
<h2 id="é¡¹ç›®å®˜æ–¹ç½‘ç«™-7">é¡¹ç›®å®˜æ–¹ç½‘ç«™</h2>
<p><a href="https://glhf.chat/chat/create">New Chat | glhf.chat</a> 2024-12-15</p>
<p><a href="https://build.nvidia.com/shutterstock/edify-3d">edify-3d Model by Shutterstock | NVIDIA NIM</a> 2024-12-15</p>
<p><a href="https://www.marscode.cn/dashboard">è±†åŒ… MarsCode - å·¥ä½œå°</a> 2024-12-15</p>
<p><a href="https://devin.ai/">Devin</a> 2024-12-15</p>
<p><a href="https://chat.deepseek.com/">DeepSeek - æ¢ç´¢æœªè‡³ä¹‹å¢ƒ</a> 2024-12-15</p>
<p><a href="https://sora.com/">Sora</a> 2024-12-15</p>
<p><a href="https://learn.deeplearning.ai/">DeepLearning.AI - Learning Platform</a> 2024-12-15</p>
<p><a href="https://www.d5render.cn/">D5æ¸²æŸ“å™¨å®˜ç½‘ | å®æ—¶å…‰è¿½æ¸²æŸ“æŠ€æœ¯ï¼Œé‡å¡‘3Dåˆ›ä½œå·¥ä½œæµ</a> 2024-12-15</p>
<p><a href="https://promptperfect.jina.ai/interactive">PromptPerfect - AI Prompt Generator and Optimizer</a> 2024-12-15</p>
<p><a href="https://learnprompting.org/">Learn Prompting: Your Guide to Communicating with AI</a> 2024-12-15</p>
<h2 id="github-é¡¹ç›®-7">GitHub é¡¹ç›®</h2>
<p><a href="https://github.com/hacksider/Deep-Live-Cam">hacksider/Deep-Live-Cam: real time face swap and one-click video deepfake with only a single image</a> 2024-12-15</p>
<p><a href="https://github.com/datawhalechina/llm-cookbook">datawhalechina/llm-cookbook: é¢å‘å¼€å‘è€…çš„ LLM å…¥é—¨æ•™ç¨‹ï¼Œå´æ©è¾¾å¤§æ¨¡å‹ç³»åˆ—è¯¾ç¨‹ä¸­æ–‡ç‰ˆ</a> 2024-12-15</p>
<p><a href="https://github.com/f/awesome-chatgpt-prompts">f/awesome-chatgpt-prompts: This repo includes ChatGPT prompt curation to use ChatGPT better.</a> 2024-12-15</p>
<p><a href="https://github.com/Stability-AI/stable-audio-tools">Stability-AI/stable-audio-tools: Generative models for conditional audio generation</a> 2024-12-15</p>
<p><a href="https://github.com/isarandi/nlf">isarandi/nlf: [NeurIPS 2024] Neural Localizer Fields for Continuous 3D Human Pose and Shape Estimation</a> 2024-12-15</p>
<p><a href="https://github.com/Stability-AI/stable-fast-3d">Stability-AI/stable-fast-3d: SF3D: Stable Fast 3D Mesh Reconstruction with UV-unwrapping and Illumination Disentanglement</a> 2024-12-15</p>
<p><a href="https://github.com/lihxxx/DisPose">lihxxx/DisPose: This repository is the official implementation of DisPose</a> 2024-12-15</p>
<p><a href="https://github.com/fkryan/gazelle">fkryan/gazelle</a> 2024-12-15</p>
<p><a href="https://github.com/tdrussell/diffusion-pipe">tdrussell/diffusion-pipe: A pipeline parallel training script for diffusion models.</a> 2024-12-15</p>
<p><a href="https://github.com/openai/openai-cookbook">openai/openai-cookbook: Examples and guides for using the OpenAI API</a> 2024-12-15</p>
<p><a href="https://github.com/promptslab/Awesome-Prompt-Engineering">promptslab/Awesome-Prompt-Engineering: This repository contains a hand-curated resources for Prompt Engineering with a focus on Generative Pre-trained Transformer (GPT), ChatGPT, PaLM etc</a> 2024-12-15</p>
<p><a href="https://github.com/thunlp/Delta-CoMe">thunlp/Delta-CoMe: Delta-CoMe can achieve near loss-less 1-bit compressin which has been accepted by NeurIPS 2024</a> 2024-12-15</p>
<h2 id="hugging-face-7">Hugging Face</h2>
<p><a href="https://huggingface.co/spaces/fallenshock/FlowEdit">FlowEdit - a Hugging Face Space by fallenshock</a> 2024-12-15</p>
<h2 id="ç­‰å¾…ä¸­çš„é¡¹ç›®-7">ç­‰å¾…ä¸­çš„é¡¹ç›®</h2>
<p><a href="https://deepmind.google/technologies/project-astra/">Project Astra - Google DeepMind</a> 2024-12-15</p>
<p><a href="https://deepmind.google/technologies/project-mariner/">Project Mariner - Google DeepMind</a> 2024-12-15</p>
<p><a href="https://labs.google.com/jules/home">Jules (Confidential)</a> 2024-12-15</p>
<p><a href="https://motionshop-diffusion.github.io/">MotionShop: Zero-Shot Motion Transfer in Video Diffusion Models with Mixture of Score Guidance</a> 2024-12-15</p>
<p><a href="https://swift-edit.github.io/">SwiftEdit</a> 2024-12-15</p>
<p><a href="https://mfischer-ucl.github.io/sama/">Michael Fischer</a> 2024-12-15</p>
<p><a href="https://diffusion-vas.github.io/">Using Diffusion Priors for Video Amodal Segmentation</a> 2024-12-15</p>
<hr>
<h2 id="é¡¹ç›®å®˜æ–¹ç½‘ç«™-8">é¡¹ç›®å®˜æ–¹ç½‘ç«™</h2>
<p><a href="https://fish.audio/zh-CN/">Fish Audio: Free Generative AI Text To Speech &amp; Voice Cloning</a> 2024-12-09</p>
<p><a href="https://aws.amazon.com/cn/ai/generative-ai/nova/?">Generative Foundation Model - Amazon Nova - AWS</a> 2024-12-09</p>
<p><a href="https://www.runcomfy.com/">RunComfy: Top ComfyUI Platform - Fast &amp; Easy, No Setup</a> 2024-12-09</p>
<p><a href="https://www.promptingguide.ai/zh">æç¤ºå·¥ç¨‹æŒ‡å— | Prompt Engineering Guide</a> 2024-12-09</p>
<p><a href="https://www.promptingguide.ai/">Prompt Engineering Guide | Prompt Engineering Guide</a> 2024-12-09</p>
<p><a href="https://www.hailuo.ai/audio">Hailuo AI Audio: Create lifelike speech</a> 2024-12-09</p>
<h2 id="github-é¡¹ç›®-8">GitHub é¡¹ç›®</h2>
<p><a href="https://github.com/FunAudioLLM/CosyVoice">FunAudioLLM/CosyVoice: Multi-lingual large voice generation model, providing inference, training and deployment full-stack ability.</a> 2024-12-09</p>
<p><a href="https://github.com/FunAudioLLM/SenseVoice">FunAudioLLM/SenseVoice: Multilingual Voice Understanding Model</a> 2024-12-09</p>
<p><a href="https://github.com/modelscope/FunASR">modelscope/FunASR: A Fundamental End-to-End Speech Recognition Toolkit and Open Source SOTA Pretrained Models, Supporting Speech Recognition, Voice Activity Detection, Text Post-processing etc.</a> 2024-12-09</p>
<p><a href="https://github.com/yformer/EfficientTAM">yformer/EfficientTAM: Efficient Track Anything</a> 2024-12-09</p>
<p><a href="https://github.com/jingyaogong/minimind">jingyaogong/minimind: ã€Œå¤§æ¨¡å‹ã€3å°æ—¶å®Œå…¨ä»0è®­ç»ƒ26Mçš„å°å‚æ•°GPTï¼Œä¸ªäººæ˜¾å¡å³å¯æ¨ç†è®­ç»ƒï¼</a> 2024-12-09</p>
<p><a href="https://github.com/kijai/ComfyUI-HunyuanVideoWrapper">kijai/ComfyUI-HunyuanVideoWrapper</a> 2024-12-09</p>
<p><a href="https://github.com/jianchang512/clone-voice">jianchang512/clone-voice: A sound cloning tool with a web interface, using your voice or any sound to record audio / ä¸€ä¸ªå¸¦webç•Œé¢çš„å£°éŸ³å…‹éš†å·¥å…·ï¼Œä½¿ç”¨ä½ çš„éŸ³è‰²æˆ–ä»»æ„å£°éŸ³æ¥å½•åˆ¶éŸ³é¢‘</a> 2024-12-09</p>
<p><a href="https://github.com/dair-ai/Prompt-Engineering-Guide">dair-ai/Prompt-Engineering-Guide: ğŸ™ Guides, papers, lecture, notebooks and resources for prompt engineering</a> 2024-12-09</p>
<p><a href="https://github.com/memoavatar/memo">memoavatar/memo: Memory-Guided Diffusion for Expressive Talking Video Generation</a> 2024-12-09</p>
<p><a href="https://github.com/1jsingh/negtome">1jsingh/negtome: Official Implementation for paper: Negative Token Merging: Image-based Adversarial Feature Guidance</a> 2024-12-09</p>
<p><a href="https://github.com/microsoft/TRELLIS">microsoft/TRELLIS: Official repo for paper &ldquo;Structured 3D Latents for Scalable and Versatile 3D Generation&rdquo;.</a> 2024-12-09</p>
<p><a href="https://github.com/Francis-Rings/StableAnimator">Francis-Rings/StableAnimator: We present StableAnimator, the first end-to-end ID-preserving video diffusion framework, which synthesizes high-quality videos without any post-processing, conditioned on a reference image and a sequence of poses.</a> 2024-12-09</p>
<h2 id="hugging-face-8">Hugging Face</h2>
<p><a href="https://www.modelscope.cn/studios/iic/CosyVoice-300M">CosyVoice-300M Â· åˆ›ç©ºé—´</a> 2024-12-09</p>
<p><a href="https://huggingface.co/spaces/taa/ChatTTS_Speaker">ChatTTS Speaker - a Hugging Face Space by taa</a> 2024-12-09</p>
<p><a href="https://huggingface.co/spaces/multimodalart/flux-fill-outpaint">Flux Fill Outpainting - a Hugging Face Space by multimodalart</a> 2024-12-09</p>
<p><a href="https://huggingface.co/spaces/jasperai/Flux.1-dev-Controlnet-Upscaler">Flux.1-dev Upscaler - a Hugging Face Space by jasperai</a> 2024-12-09</p>
<p><a href="https://huggingface.co/spaces/Nymbo/Flux.1-dev-Controlnet-Upscaler">Flux.1-dev Upscaler - a Hugging Face Space by Nymbo</a> 2024-12-09</p>
<h2 id="ç­‰å¾…ä¸­çš„é¡¹ç›®-8">ç­‰å¾…ä¸­çš„é¡¹ç›®</h2>
<p><a href="https://muse.art/">Muse</a> 2024-12-09</p>
<p><a href="https://cloud.google.com/blog/products/ai-machine-learning/introducing-veo-and-imagen-3-on-vertex-ai?utm_source=twitter&amp;utm_medium=unpaidsoc&amp;utm_campaign=fy24q4-googlecloud-blog-ai-in_feed-no-brand-global&amp;utm_content=-&amp;utm_term=-&amp;linkId=11948812">Introducing Veo and Imagen 3 on Vertex AI | Google Cloud Blog</a> 2024-12-09</p>
<p><a href="https://deepbrainai-research.github.io/float/">FLOAT</a> 2024-12-09</p>
<p><a href="https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/">Genie 2: A large-scale foundation world model - Google DeepMind</a> 2024-12-09</p>
<p><a href="https://solami-ai.github.io/">SOLAMI: Social Vision-Language-Action Modeling for Immersive Interaction with 3D Autonomous Characters</a> 2024-12-09</p>
<p><a href="https://digital-life-project.com/">Digital Life Project</a> 2024-12-09</p>
<p><a href="https://wanquanf.github.io/I2VControl">I2VControl: Disentangled and Unified Video Motion Synthesis Control</a> 2024-12-09</p>
<p><a href="https://dualpm.github.io/">DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction</a> 2024-12-09</p>
<p><a href="https://fugatto.github.io/">fugatto.github.io</a> 2024-12-09</p>
<p><a href="https://cat-4d.github.io/">CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models</a> 2024-12-09</p>
<p><a href="https://snoopi-onestep.github.io/">SNOOPI: Supercharged One-step Diffusion Distillation with Proper Guidance</a> 2024-12-09</p>
<p><a href="https://vision-xl.github.io/">vision-xl</a> 2024-12-09</p>
<hr>

            <footer class="footline">
            </footer>
          </article>
        </div>
      </main>
    </div>
    <aside id="sidebar" class="default-animation">
      <div id="header-wrapper" class="default-animation">
        <div id="header" class="default-animation">
          <a id="logo" href="/">
            <img width="280px" src="/hb.png"></img>
            <br><font face="serif" size="5" color="#FF0000"><b>æ˜ æ–‡ è§† ç•Œ</b></font>
          </a>
        </div>
        <div class="searchbox default-animation">
          <label for="search-by"><i class="fas fa-search"></i></label>
          <input data-search-input id="search-by" type="search" placeholder="æœç´¢...">
          <span data-search-clear=""><i class="fas fa-times"></i></span>
        </div>
        <script>
          var contentLangs=['zh'];
        </script>
        <script src="/js/auto-complete.js?1737954595" defer></script>
        <script src="/js/lunr.min.js?1737954595" defer></script>
        <script src="/js/lunr.stemmer.support.min.js?1737954595" defer></script>
        <script src="/js/lunr.multi.min.js?1737954595" defer></script>
        <script src="/js/lunr.zh.min.js?1737954595" defer></script>
        <script src="/js/search.js?1737954595" defer></script>
      </div>
      <div id="content-wrapper" class="highlightable">
        <ul class="topics">
          <li data-nav-id="/04_prompt-engineering/" title="&lt;&lt;è‡ªç„¶è¯­è¨€æç¤ºå·¥ç¨‹å…¥é—¨&gt;&gt;" class="dd-item"><input type="checkbox" id="section-e5b35d3b038fb5ec64923f071f9232c3" class="toggle"/><label for="section-e5b35d3b038fb5ec64923f071f9232c3" ></label><a href="/04_prompt-engineering/">&lt;&lt;è‡ªç„¶è¯­è¨€æç¤ºå·¥ç¨‹å…¥é—¨&gt;&gt;</a><ul>
          <li data-nav-id="/04_prompt-engineering/01-prompt-engineering/" title="1. å¼€èƒƒç‚¹å¿ƒ, ä»å‡ ä¸ªæ¡ˆä¾‹å¼€å§‹" class="dd-item"><a href="/04_prompt-engineering/01-prompt-engineering/">1. å¼€èƒƒç‚¹å¿ƒ, ä»å‡ ä¸ªæ¡ˆä¾‹å¼€å§‹</a></li>
          <li data-nav-id="/04_prompt-engineering/02-prompt-engineering/" title="2. æç¤ºå·¥ç¨‹æ—¥å¸¸ä½¿ç”¨æŠ€å·§" class="dd-item"><input type="checkbox" id="section-85b0cf03ed8d259501be9914547856fd" class="toggle"/><label for="section-85b0cf03ed8d259501be9914547856fd" ></label><a href="/04_prompt-engineering/02-prompt-engineering/">2. æç¤ºå·¥ç¨‹æ—¥å¸¸ä½¿ç”¨æŠ€å·§</a><ul>
          <li data-nav-id="/04_prompt-engineering/02-prompt-engineering/daily-skills01/" title="2.1. çƒ­èº«, ç†Ÿæ‚‰åŸºæœ¬æ¦‚å¿µå’Œç¼–å†™è¦ç‚¹" class="dd-item"><a href="/04_prompt-engineering/02-prompt-engineering/daily-skills01/">2.1. çƒ­èº«, ç†Ÿæ‚‰åŸºæœ¬æ¦‚å¿µå’Œç¼–å†™è¦ç‚¹</a></li>
          <li data-nav-id="/04_prompt-engineering/02-prompt-engineering/daily-skills02/" title="2.2. é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬æç¤º" class="dd-item"><a href="/04_prompt-engineering/02-prompt-engineering/daily-skills02/">2.2. é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬æç¤º</a></li>
          <li data-nav-id="/04_prompt-engineering/02-prompt-engineering/daily-skills03/" title="2.3. æ€ç»´é“¾ä¸å·¦å³äº’æ" class="dd-item"><a href="/04_prompt-engineering/02-prompt-engineering/daily-skills03/">2.3. æ€ç»´é“¾ä¸å·¦å³äº’æ</a></li>
          <li data-nav-id="/04_prompt-engineering/02-prompt-engineering/daily-skills04/" title="2.4. è§’è‰²æ‰®æ¼”æç¤º" class="dd-item"><a href="/04_prompt-engineering/02-prompt-engineering/daily-skills04/">2.4. è§’è‰²æ‰®æ¼”æç¤º</a></li>
          <li data-nav-id="/04_prompt-engineering/02-prompt-engineering/daily-skills05/" title="2.5. å°†æç¤ºæ‹†åˆ†ä¸ºæç¤ºé“¾" class="dd-item"><a href="/04_prompt-engineering/02-prompt-engineering/daily-skills05/">2.5. å°†æç¤ºæ‹†åˆ†ä¸ºæç¤ºé“¾</a></li>
          <li data-nav-id="/04_prompt-engineering/02-prompt-engineering/daily-skills06/" title="2.6. æ•…äº‹æç¤º" class="dd-item"><a href="/04_prompt-engineering/02-prompt-engineering/daily-skills06/">2.6. æ•…äº‹æç¤º</a></li></ul></li>
          <li data-nav-id="/04_prompt-engineering/03-prompt-engineering/" title="3. æç¤ºå·¥ç¨‹æ—¥å¸¸ä½¿ç”¨æ¡ˆä¾‹å¤§å…¨" class="dd-item"><a href="/04_prompt-engineering/03-prompt-engineering/">3. æç¤ºå·¥ç¨‹æ—¥å¸¸ä½¿ç”¨æ¡ˆä¾‹å¤§å…¨</a></li>
          <li data-nav-id="/04_prompt-engineering/04-prompt-engineering/" title="4. é«˜çº§æç¤ºå·¥ç¨‹æ¦‚è¿°" class="dd-item"><a href="/04_prompt-engineering/04-prompt-engineering/">4. é«˜çº§æç¤ºå·¥ç¨‹æ¦‚è¿°</a></li></ul></li>
          <li data-nav-id="/01_aigc_object/" title="ACGC é¡¹ç›®èµ„æºé›†" class="dd-item active parent"><input type="checkbox" id="section-33ed1d2a346ed20d642e8be7edffce65" class="toggle" checked/><label for="section-33ed1d2a346ed20d642e8be7edffce65" ></label><a href="/01_aigc_object/">ACGC é¡¹ç›®èµ„æºé›†</a><ul>
          <li data-nav-id="/01_aigc_object/01_object/" title="é¡¹ç›®çš„å®˜æ–¹ç½‘ç«™" class="dd-item"><a href="/01_aigc_object/01_object/">é¡¹ç›®çš„å®˜æ–¹ç½‘ç«™</a></li>
          <li data-nav-id="/01_aigc_object/02_github/" title="é¡¹ç›®çš„ GitHub ä¸»é¡µ" class="dd-item"><a href="/01_aigc_object/02_github/">é¡¹ç›®çš„ GitHub ä¸»é¡µ</a></li>
          <li data-nav-id="/01_aigc_object/03_hugging/" title="Hugging Face Space" class="dd-item"><a href="/01_aigc_object/03_hugging/">Hugging Face Space</a></li>
          <li data-nav-id="/01_aigc_object/04_web/" title="AIGC ç›¸å…³ç½‘ç«™" class="dd-item"><a href="/01_aigc_object/04_web/">AIGC ç›¸å…³ç½‘ç«™</a></li>
          <li data-nav-id="/01_aigc_object/05_doc/" title="ç›¸å…³æ–‡æ¡£èµ„æ–™" class="dd-item"><a href="/01_aigc_object/05_doc/">ç›¸å…³æ–‡æ¡£èµ„æ–™</a></li>
          <li data-nav-id="/01_aigc_object/06_wait/" title="ç­‰å¾…ä¸­çš„é¡¹ç›®" class="dd-item"><a href="/01_aigc_object/06_wait/">ç­‰å¾…ä¸­çš„é¡¹ç›®</a></li></ul></li>
          <li data-nav-id="/02_comfyui/" title="ComfyUI èµ„æº, æ•™ç¨‹" class="dd-item"><input type="checkbox" id="section-b139ed5ac8d7ecf0bdd93cad7cc2ee6f" class="toggle"/><label for="section-b139ed5ac8d7ecf0bdd93cad7cc2ee6f" ></label><a href="/02_comfyui/">ComfyUI èµ„æº, æ•™ç¨‹</a><ul>
          <li data-nav-id="/02_comfyui/01_interface/" title="ç•Œé¢ä»‹ç»" class="dd-item"><a href="/02_comfyui/01_interface/">ç•Œé¢ä»‹ç»</a></li>
          <li data-nav-id="/02_comfyui/02_basic/" title="åŸºæœ¬æ¦‚å¿µ" class="dd-item"><a href="/02_comfyui/02_basic/">åŸºæœ¬æ¦‚å¿µ</a></li>
          <li data-nav-id="/02_comfyui/03_built-in/" title="å†…ç½®èŠ‚ç‚¹" class="dd-item"><input type="checkbox" id="section-a56a67957678d144c2719c346d47faa5" class="toggle"/><label for="section-a56a67957678d144c2719c346d47faa5" ></label><a href="/02_comfyui/03_built-in/">å†…ç½®èŠ‚ç‚¹</a><ul>
          <li data-nav-id="/02_comfyui/03_built-in/01-built-in/" title="å†…ç½®èŠ‚ç‚¹ 1" class="dd-item"><a href="/02_comfyui/03_built-in/01-built-in/">å†…ç½®èŠ‚ç‚¹ 1</a></li>
          <li data-nav-id="/02_comfyui/03_built-in/02-built-in/" title="å†…ç½®èŠ‚ç‚¹ 2" class="dd-item"><a href="/02_comfyui/03_built-in/02-built-in/">å†…ç½®èŠ‚ç‚¹ 2</a></li>
          <li data-nav-id="/02_comfyui/03_built-in/03-built-in/" title="å†…ç½®èŠ‚ç‚¹ 3" class="dd-item"><a href="/02_comfyui/03_built-in/03-built-in/">å†…ç½®èŠ‚ç‚¹ 3</a></li></ul></li>
          <li data-nav-id="/02_comfyui/04_common-nodes/" title="å¸¸ç”¨è‡ªå®šä¹‰èŠ‚ç‚¹" class="dd-item"><a href="/02_comfyui/04_common-nodes/">å¸¸ç”¨è‡ªå®šä¹‰èŠ‚ç‚¹</a></li></ul></li>
          <li data-nav-id="/03_prompts/" title="æç¤ºå·¥ç¨‹èµ„æº, æ¡ˆä¾‹é›†" class="dd-item"><input type="checkbox" id="section-019abe92d153661cf1e3ed2ecad53b65" class="toggle"/><label for="section-019abe92d153661cf1e3ed2ecad53b65" ></label><a href="/03_prompts/">æç¤ºå·¥ç¨‹èµ„æº, æ¡ˆä¾‹é›†</a><ul>
          <li data-nav-id="/03_prompts/01-prompt-sources/" title="æç¤ºå·¥ç¨‹èµ„æºæ•´ç†" class="dd-item"><a href="/03_prompts/01-prompt-sources/">æç¤ºå·¥ç¨‹èµ„æºæ•´ç†</a></li></ul></li>
        </ul>
        <div id="shortcuts">
          <div class="nav-title"></div>
          <ul>
            <li><a class="padding" href="/about">å…³æ³¨æˆ‘</a></li>
          </ul>
        </div>
        <div class="footermargin footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter"></div>
        <hr class="default-animation footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter"/>
        <div id="prefooter" class="footerLangSwitch footerVariantSwitch footerVisitedLinks">
          <ul>
            <li id="select-language-container" class="footerLangSwitch">
              <a class="padding select-container">
                <i class="fas fa-language fa-fw"></i>
                <span>&nbsp;</span>
                <div class="select-style">
                  <select id="select-language" onchange="location = baseUri + this.value;">
                  </select>
                </div>
                <div class="select-clear"></div>
              </a>
            </li>
            <li id="select-variant-container" class="footerVariantSwitch">
              <a class="padding select-container">
                <i class="fas fa-paint-brush fa-fw"></i>
                <span>&nbsp;</span>
                <div class="select-style">
                  <select id="select-variant" onchange="window.variants && variants.changeVariant( this.value );">
                    <option id="black" value="black" selected>Black</option>
                  </select>
                </div>
                <div class="select-clear"></div>
              </a>
              <script>window.variants && variants.markSelectedVariant();</script>
            </li>
            <li class="footerVisitedLinks"><a class="padding" onclick="clearHistory();"><i class="fas fa-history fa-fw"></i> æ¸…ç†å†å²è®°å½•</a></li>
          </ul>
        </div>
        <div id="footer" class="footerFooter showFooter">      <p>ç²¤ICPå¤‡ <a href="https://beian.miit.gov.cn/#/Integrated/index">20041225å·</a></p>
      <p></a><img src="/beian.png" >ç²¤å…¬ç½‘å®‰å¤‡<a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=44030702003010"> 44030702003010å·</a>
      <p>Â©2022 <a href="https://jupyter.fun/">ğŸ Jupyter.fun</a></p>
        </div>
      </div>
    </aside>
    <script src="/js/clipboard.min.js?1737954595" defer></script>
    <script src="/js/perfect-scrollbar.min.js?1737954595" defer></script>
    <script src="/js/featherlight.min.js?1737954595" defer></script>
    <script>
      function useMathJax( config ){
        if( !Object.assign ){
          
          return;
        }
        window.MathJax = Object.assign( window.MathJax || {}, {
          loader: {
            load: ['[tex]/mhchem']
          },
          startup: {
            elements: [
              '.math'
            ]
          },
          tex: {
            inlineMath: [
              ['$', '$'], 
              ['\\(', '\\)']
            ]
          },
          options: {
            enableMenu: false 
          }
        }, config );
      }
      useMathJax( JSON.parse("{}") );
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="/js/jquery.svg.pan.zoom.js?1737954595" defer></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js" defer></script>
    <script>
      window.themeUseMermaid = JSON.parse("{ \"theme\": \"default\" }");
    </script>
    <script src="https://unpkg.com/rapidoc/dist/rapidoc-min.js" defer></script>
    <script>
      window.themeUseSwagger = JSON.parse("{ \"theme\": \"light\" }");
    </script>
    <script src="/js/theme.js?1737954595" defer></script>
  </body>
</html>
