# æ˜æ–‡è§†ç•Œ çš„ AI ç«™

<picture>
  <source srcset="https://fonts.gstatic.com/s/e/notoemoji/latest/1f30f/512.webp" type="image/webp">
  <img src="https://fonts.gstatic.com/s/e/notoemoji/latest/1f30f/512.gif" alt="ğŸŒ" width="32" height="32">
</picture>

AI å‘å±•æ—¥æ–°æœˆå¼‚, ä»¥ä¸‹é¡¹ç›®æ˜¯ç›®è‡ª 2024-11-23 èµ·, æœé›†æ•´ç†çš„éå¸¸æ£’çš„é¡¹ç›®/åº”ç”¨/èµ„æº... 

åé¢æ–°æ·»åŠ , éƒ½ä¼šæ ‡æ³¨æ—¥æœŸ:

## é¡¹ç›®å®˜æ–¹ç½‘ç«™

[New Chat | glhf.chat](https://glhf.chat/chat/create) 2024-12-15

[edify-3d Model by Shutterstock | NVIDIA NIM](https://build.nvidia.com/shutterstock/edify-3d) 2024-12-15

[è±†åŒ… MarsCode - å·¥ä½œå°](https://www.marscode.cn/dashboard) 2024-12-15

[Devin](https://devin.ai/) 2024-12-15

[DeepSeek - æ¢ç´¢æœªè‡³ä¹‹å¢ƒ](https://chat.deepseek.com/) 2024-12-15

[Sora](https://sora.com/) 2024-12-15

[DeepLearning.AI - Learning Platform](https://learn.deeplearning.ai/) 2024-12-15

[D5æ¸²æŸ“å™¨å®˜ç½‘ | å®æ—¶å…‰è¿½æ¸²æŸ“æŠ€æœ¯ï¼Œé‡å¡‘3Dåˆ›ä½œå·¥ä½œæµ](https://www.d5render.cn/) 2024-12-15

[PromptPerfect - AI Prompt Generator and Optimizer](https://promptperfect.jina.ai/interactive) 2024-12-15

[Learn Prompting: Your Guide to Communicating with AI](https://learnprompting.org/) 2024-12-15

## GitHub é¡¹ç›®

[hacksider/Deep-Live-Cam: real time face swap and one-click video deepfake with only a single image](https://github.com/hacksider/Deep-Live-Cam) 2024-12-15

[datawhalechina/llm-cookbook: é¢å‘å¼€å‘è€…çš„ LLM å…¥é—¨æ•™ç¨‹ï¼Œå´æ©è¾¾å¤§æ¨¡å‹ç³»åˆ—è¯¾ç¨‹ä¸­æ–‡ç‰ˆ](https://github.com/datawhalechina/llm-cookbook) 2024-12-15

[f/awesome-chatgpt-prompts: This repo includes ChatGPT prompt curation to use ChatGPT better.](https://github.com/f/awesome-chatgpt-prompts) 2024-12-15

[Stability-AI/stable-audio-tools: Generative models for conditional audio generation](https://github.com/Stability-AI/stable-audio-tools) 2024-12-15

[isarandi/nlf: [NeurIPS 2024] Neural Localizer Fields for Continuous 3D Human Pose and Shape Estimation](https://github.com/isarandi/nlf) 2024-12-15

[Stability-AI/stable-fast-3d: SF3D: Stable Fast 3D Mesh Reconstruction with UV-unwrapping and Illumination Disentanglement](https://github.com/Stability-AI/stable-fast-3d) 2024-12-15

[lihxxx/DisPose: This repository is the official implementation of DisPose](https://github.com/lihxxx/DisPose) 2024-12-15

[fkryan/gazelle](https://github.com/fkryan/gazelle) 2024-12-15

[tdrussell/diffusion-pipe: A pipeline parallel training script for diffusion models.](https://github.com/tdrussell/diffusion-pipe) 2024-12-15

[openai/openai-cookbook: Examples and guides for using the OpenAI API](https://github.com/openai/openai-cookbook) 2024-12-15

[promptslab/Awesome-Prompt-Engineering: This repository contains a hand-curated resources for Prompt Engineering with a focus on Generative Pre-trained Transformer (GPT), ChatGPT, PaLM etc](https://github.com/promptslab/Awesome-Prompt-Engineering) 2024-12-15

[thunlp/Delta-CoMe: Delta-CoMe can achieve near loss-less 1-bit compressin which has been accepted by NeurIPS 2024](https://github.com/thunlp/Delta-CoMe) 2024-12-15

## Hugging Face

[FlowEdit - a Hugging Face Space by fallenshock](https://huggingface.co/spaces/fallenshock/FlowEdit) 2024-12-15

## ç­‰å¾…ä¸­çš„é¡¹ç›®

[Project Astra - Google DeepMind](https://deepmind.google/technologies/project-astra/) 2024-12-15

[Project Mariner - Google DeepMind](https://deepmind.google/technologies/project-mariner/) 2024-12-15

[Jules (Confidential)](https://labs.google.com/jules/home) 2024-12-15

[MotionShop: Zero-Shot Motion Transfer in Video Diffusion Models with Mixture of Score Guidance](https://motionshop-diffusion.github.io/) 2024-12-15

[SwiftEdit](https://swift-edit.github.io/) 2024-12-15

[Michael Fischer](https://mfischer-ucl.github.io/sama/) 2024-12-15

[Using Diffusion Priors for Video Amodal Segmentation](https://diffusion-vas.github.io/) 2024-12-15

---------

## é¡¹ç›®å®˜æ–¹ç½‘ç«™

[Fish Audio: Free Generative AI Text To Speech & Voice Cloning](https://fish.audio/zh-CN/) 2024-12-09

[Generative Foundation Model - Amazon Nova - AWS](https://aws.amazon.com/cn/ai/generative-ai/nova/?) 2024-12-09

[RunComfy: Top ComfyUI Platform - Fast & Easy, No Setup](https://www.runcomfy.com/) 2024-12-09

[æç¤ºå·¥ç¨‹æŒ‡å— | Prompt Engineering Guide](https://www.promptingguide.ai/zh) 2024-12-09

[Prompt Engineering Guide | Prompt Engineering Guide](https://www.promptingguide.ai/) 2024-12-09

[Hailuo AI Audio: Create lifelike speech](https://www.hailuo.ai/audio) 2024-12-09

## GitHub é¡¹ç›®

[FunAudioLLM/CosyVoice: Multi-lingual large voice generation model, providing inference, training and deployment full-stack ability.](https://github.com/FunAudioLLM/CosyVoice) 2024-12-09

[FunAudioLLM/SenseVoice: Multilingual Voice Understanding Model](https://github.com/FunAudioLLM/SenseVoice) 2024-12-09

[modelscope/FunASR: A Fundamental End-to-End Speech Recognition Toolkit and Open Source SOTA Pretrained Models, Supporting Speech Recognition, Voice Activity Detection, Text Post-processing etc.](https://github.com/modelscope/FunASR) 2024-12-09

[yformer/EfficientTAM: Efficient Track Anything](https://github.com/yformer/EfficientTAM) 2024-12-09

[jingyaogong/minimind: ã€Œå¤§æ¨¡å‹ã€3å°æ—¶å®Œå…¨ä»0è®­ç»ƒ26Mçš„å°å‚æ•°GPTï¼Œä¸ªäººæ˜¾å¡å³å¯æ¨ç†è®­ç»ƒï¼](https://github.com/jingyaogong/minimind) 2024-12-09

[kijai/ComfyUI-HunyuanVideoWrapper](https://github.com/kijai/ComfyUI-HunyuanVideoWrapper) 2024-12-09

[jianchang512/clone-voice: A sound cloning tool with a web interface, using your voice or any sound to record audio / ä¸€ä¸ªå¸¦webç•Œé¢çš„å£°éŸ³å…‹éš†å·¥å…·ï¼Œä½¿ç”¨ä½ çš„éŸ³è‰²æˆ–ä»»æ„å£°éŸ³æ¥å½•åˆ¶éŸ³é¢‘](https://github.com/jianchang512/clone-voice) 2024-12-09

[dair-ai/Prompt-Engineering-Guide: ğŸ™ Guides, papers, lecture, notebooks and resources for prompt engineering](https://github.com/dair-ai/Prompt-Engineering-Guide) 2024-12-09

[memoavatar/memo: Memory-Guided Diffusion for Expressive Talking Video Generation](https://github.com/memoavatar/memo) 2024-12-09

[1jsingh/negtome: Official Implementation for paper: Negative Token Merging: Image-based Adversarial Feature Guidance](https://github.com/1jsingh/negtome) 2024-12-09

[microsoft/TRELLIS: Official repo for paper "Structured 3D Latents for Scalable and Versatile 3D Generation".](https://github.com/microsoft/TRELLIS) 2024-12-09

[Francis-Rings/StableAnimator: We present StableAnimator, the first end-to-end ID-preserving video diffusion framework, which synthesizes high-quality videos without any post-processing, conditioned on a reference image and a sequence of poses.](https://github.com/Francis-Rings/StableAnimator) 2024-12-09

## Hugging Face

[CosyVoice-300M Â· åˆ›ç©ºé—´](https://www.modelscope.cn/studios/iic/CosyVoice-300M) 2024-12-09

[ChatTTS Speaker - a Hugging Face Space by taa](https://huggingface.co/spaces/taa/ChatTTS_Speaker) 2024-12-09

[Flux Fill Outpainting - a Hugging Face Space by multimodalart](https://huggingface.co/spaces/multimodalart/flux-fill-outpaint) 2024-12-09

[Flux.1-dev Upscaler - a Hugging Face Space by jasperai](https://huggingface.co/spaces/jasperai/Flux.1-dev-Controlnet-Upscaler) 2024-12-09

[Flux.1-dev Upscaler - a Hugging Face Space by Nymbo](https://huggingface.co/spaces/Nymbo/Flux.1-dev-Controlnet-Upscaler) 2024-12-09

## ç­‰å¾…ä¸­çš„é¡¹ç›®

[Muse](https://muse.art/) 2024-12-09

[Introducing Veo and Imagen 3 on Vertex AI | Google Cloud Blog](https://cloud.google.com/blog/products/ai-machine-learning/introducing-veo-and-imagen-3-on-vertex-ai?utm_source=twitter&utm_medium=unpaidsoc&utm_campaign=fy24q4-googlecloud-blog-ai-in_feed-no-brand-global&utm_content=-&utm_term=-&linkId=11948812) 2024-12-09

[FLOAT](https://deepbrainai-research.github.io/float/) 2024-12-09

[Genie 2: A large-scale foundation world model - Google DeepMind](https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/) 2024-12-09

[SOLAMI: Social Vision-Language-Action Modeling for Immersive Interaction with 3D Autonomous Characters](https://solami-ai.github.io/) 2024-12-09

[Digital Life Project](https://digital-life-project.com/) 2024-12-09

[I2VControl: Disentangled and Unified Video Motion Synthesis Control](https://wanquanf.github.io/I2VControl) 2024-12-09

[DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction](https://dualpm.github.io/) 2024-12-09

[fugatto.github.io](https://fugatto.github.io/) 2024-12-09

[CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models](https://cat-4d.github.io/) 2024-12-09

[SNOOPI: Supercharged One-step Diffusion Distillation with Proper Guidance](https://snoopi-onestep.github.io/) 2024-12-09

[vision-xl](https://vision-xl.github.io/) 2024-12-09

---------

## é¡¹ç›®å®˜æ–¹ç½‘ç«™

[è¯­é²¸](https://lingowhale.com/home) 2024-12-03

[æ·±è¨€è¾¾æ„ â€“ æ‰¾è¯æ‰¾å¥](https://www.shenyandayi.com/) 2024-12-03

[çˆ±æ ¡å¯¹å®˜ç½‘-å…è´¹é«˜æ•ˆçš„é”™åˆ«å­—æ£€æŸ¥å·¥å…·](https://www.ijiaodui.com/) 2024-12-03

[Learn About](https://learning.google.com/experiments/learn-about?) 2024-12-03

[World Labs](https://www.worldlabs.ai/) 2024-12-03

[é€šä¹‰tongyi.ai_ä½ çš„å…¨èƒ½AIåŠ©æ‰‹-é€šä¹‰åƒé—®](https://tongyi.aliyun.com/) 2024-12-03

[å¤©å·¥AI - æœç´¢æ›´æ·±åº¦ï¼Œé˜…è¯»æ›´å¤šå½©](https://www.tiangong.cn/) 2024-12-03

[è®¯é£æ˜Ÿç«å¤§æ¨¡å‹-AIå¤§è¯­è¨€æ¨¡å‹-æ˜Ÿç«å¤§æ¨¡å‹-ç§‘å¤§è®¯é£](https://xinghuo.xfyun.cn/desk) 2024-12-03

[æ–‡å¿ƒä¸€è¨€](https://yiyan.baidu.com/) 2024-12-03

[Home â€¢ Hume AI](https://www.hume.ai/) 2024-12-03

[Cohere | The leading AI platform for enterprise](https://cohere.com/) 2024-12-03

[è…¾è®¯æ··å…ƒæ–‡ç”Ÿè§†é¢‘](https://video.hunyuan.tencent.com/) 2024-12-03

[PixelDance - PixelDance AI - é¢†å…ˆçš„AIè§†é¢‘ç”Ÿæˆå¹³å°](https://pixeldance.io/zh) 2024-12-03

## GitHub é¡¹ç›®

[hiroi-sora/Umi-OCR: OCR software, free and offline. å¼€æºã€å…è´¹çš„ç¦»çº¿OCRè½¯ä»¶ã€‚æ”¯æŒæˆªå±/æ‰¹é‡å¯¼å…¥å›¾ç‰‡ï¼ŒPDFæ–‡æ¡£è¯†åˆ«ï¼Œæ’é™¤æ°´å°/é¡µçœ‰é¡µè„šï¼Œæ‰«æ/ç”ŸæˆäºŒç»´ç ã€‚å†…ç½®å¤šå›½è¯­è¨€åº“ã€‚](https://github.com/hiroi-sora/Umi-OCR) 2024-12-03

[Significant-Gravitas/AutoGPT: AutoGPT is the vision of accessible AI for everyone, to use and to build on. Our mission is to provide the tools, so that you can focus on what matters.](https://github.com/Significant-Gravitas/AutoGPT) 2024-12-03

[OpenBMB/ChatDev: Create Customized Software using Natural Language Idea (through LLM-powered Multi-Agent Collaboration)](https://github.com/OpenBMB/ChatDev) 2024-12-03

[prs-eth/RollingDepth: Video Depth without Video Models](https://github.com/prs-eth/rollingdepth) 2024-12-03

[Tencent/HunyuanVideo](https://github.com/Tencent/HunyuanVideo) 2024-12-03

## Hugging Face

[TryOffDiff - a Hugging Face Space by rizavelioglu](https://huggingface.co/spaces/rizavelioglu/tryoffdiff) 2024-12-03

## ç­‰å¾…ä¸­çš„é¡¹ç›®

[Freditor](https://aigc3d.github.io/freditor/) 2024-12-03

[mayuelala/FollowYourClick: [arXiv 2024] Follow-Your-Click: This repo is the official implementation of "Follow-Your-Click: Open-domain Regional Image Animation via Short Prompts"](https://github.com/mayuelala/FollowYourClick?tab=readme-ov-file) 2024-12-03

------
------
------

## é¡¹ç›®ç½‘ç«™

### æœç´¢é—®ç­”

[çº³ç±³æœç´¢](https://n.cn/) 2024-12-02

[ä¹¦ç”ŸÂ·æµ¦è¯­](https://internlm-chat.intern-ai.org.cn/) 2024-12-02

[Kimi](https://kimi.moonshot.cn/)

[chatgpt](https://chatgpt.com/)

[ç§˜å¡”](https://metaso.cn/)

[perplexity](https://www.perplexity.ai/)

[Meta AI](https://www.meta.ai/)

[è…¾è®¯å…ƒå®](https://yuanbao.tencent.com/discovery)

[è±†åŒ… - æŠ–éŸ³æ——ä¸‹ AI æ™ºèƒ½åŠ©æ‰‹](https://www.doubao.com/chat/?channel=baidu_sem&source=db_sem_baidu_htl_pc_1_ocpc&keywordid=751265762256&ad_platform_id=baidusearch_lead&account_id=52024153&a_planid=477748213&a_unitid=9513180824&a_keywordid=751265762256&a_creative=93832488550&a_matchtype=1&a_dongtai=0&a_trig_flag=nm&a_crowdid=0&a_kw_enc_utf8=%E8%B1%86%E5%8C%85%E5%A4%A7%E6%A8%A1%E5%9E%8B&ug_semver=v2.0.0&bd_vid=11275434556537774190)

[Google AI Studio](https://aistudio.google.com/app/prompts/new_chat)

[Claude](https://claude.ai/login?returnTo=%2F%3F#)

[çŸ¥ä¹ç›´ç­”](https://zhida.zhihu.com/)

[360æœ](https://www.sou.com/)

[Poe](https://poe.com/)

[HuggingChat](https://huggingface.co/chat/)

### è§†é¢‘, è¯­éŸ³, ç»˜å›¾ç­‰ç»¼åˆ

[æ™ºè°±æ¸…è¨€](https://chatglm.cn/main/alltoolsdetail?lang=zh)

[å³æ¢¦AI - ä¸€ç«™å¼AIåˆ›ä½œå¹³å°](https://jimeng.jianying.com/ai-tool/home)

[å¯çµ AI - æ–°ä¸€ä»£ AI åˆ›æ„ç”Ÿäº§åŠ›å¹³å°](https://klingai.kuaishou.com/)

[æµ·èº AI](https://hailuoai.com/)

[è·ƒé—®](https://yuewen.cn/chats/new)

[Luma Dream Machine | AI Video Generator](https://lumalabs.ai/dream-machine)

[KREA AI - AIGCé›†åˆ-é£æ ¼-å›¾æœ‰å…è´¹](https://www.krea.ai/home)

[Home - Leonardo.Ai](https://app.leonardo.ai/)

[AI Test Kitchen](https://aitestkitchen.withgoogle.com/zh)

[LimeWire](https://limewire.com/)

[Le Chat - Mistral AI](https://chat.mistral.ai/chat)

[WHEE - é«˜å“è´¨çš„AIç´ æç”Ÿæˆå™¨](https://www.whee.com/)

### è§†é¢‘

[VidAU Creative Center](https://app.vidau.ai/site/creativeCenter) 2024-12-02

[kaze.ai - AI-powered Free Online Removing Watermark and Logos Tool](https://kaze.ai/) 2024-11-27

[Viduï¼Œè®©æƒ³è±¡å‘ç”Ÿ](https://www.vidu.studio/zh)

[Hailuo AI Video Generator - Reimagine Video Creation](https://hailuoai.video/)

[Runway](https://app.runwayml.com/video-tools/teams/billwuhao2018/dashboard)

[è®²æ•…äº‹çš„æ–¹å¼å‘ç”Ÿäº†è½¬å˜LTXå·¥ä½œå®¤ --- Storytelling Transformed | LTX Studio](https://app.ltx.studio/)

[Noisee AI éŸ³ä¹ç”ŸæˆMV](https://noisee.ai/)

[Pika](https://pika.art/)

[Genmo. Create videos and images with AI.](https://www.genmo.ai/)

[Home | PixVerse](https://app.pixverse.ai/home)

[Viggle AI](https://viggle.ai/home)

[ä¸‡å¾·åŠ¨åŠ› --- Wonder Dynamics](https://app.wonderdynamics.com/)

[HeyGen - AI Spokesperson Video Creator](https://app.heygen.com/home)

[Aiuni](https://aiuni.ai/)

[DomoAI: video to video, video to animation and more](https://www.domoai.app/zh-Hant/home)

[Flair](https://app.flair.ai/templates)

[Warpvideo AI: Change Video Style with AI](https://warpvideo.ai/)

[Hedra æ•°å­—äºº](https://www.hedra.com/)

[AI æ“æŠ± - å…è²»ç·šä¸Š AI æ“æŠ±å½±ç‰‡ç”Ÿæˆå™¨](https://aihug.ai/tw)

[MOKI - æˆ‘ç”¨AIåšçŸ­ç‰‡](https://www.moki.cn/home)

[Meshcapade | ç¼–è¾‘äººç‰©åŠ¨ä½œ](https://meshcapade.com/)

[BoomCut - çˆ†å‰ªè¾‘ - å°å½±ç§‘æŠ€æ——ä¸‹ AI å†…å®¹åˆ›æ„äº§å“ä¸æœåŠ¡å¹³å°](https://boomcutai.com/)

### ç»˜ç”»è®¾è®¡

[Create stunning visuals in seconds with AI.](https://clipdrop.co/)

[è¶…èƒ½ç”»å¸ƒé¦–é¡µ](https://photo.baidu.com/photasy/home)

[Adobe Firefly](https://firefly.adobe.com/)

[Design - Playground](https://playground.com/design)

[Skybox AI 360Â°å…¨æ™¯](https://skybox.blockadelabs.com/)

[Magic Studioï¼šåˆ©ç”¨ AI åˆ¶ä½œç²¾ç¾å›¾åƒ](https://magicstudio.com/zh/)

[midjourney](https://www.midjourney.com/explore?tab=top)

[Remove Background from Image for Free â€“ remove.bg](https://www.remove.bg/)

[Craiyon, formerly DALL-E mini](https://www.craiyon.com/)

[Create - Artbreeder](https://www.artbreeder.com/create)

[NightCafe Creator](https://creator.nightcafe.studio/my-creations)

[Projects - Recraft](https://www.recraft.ai/projects)

[Blendbox.ai å¤šå›¾ç»„åˆ](https://app.blendbox.ai/create)

[Ideogram ç”»å¸ƒ](https://ideogram.ai/t/explore)

[Logo-creator.io â€“ Generate a logo](https://www.logo-creator.io/)

[åœ¨çº¿æŠ å›¾è½¯ä»¶_å›¾ç‰‡å»é™¤èƒŒæ™¯ | remove.bg â€“ remove.bg](https://www.remove.bg/zh)

[è§¦æ‰‹AI](https://ai.smalld.cn/#/)

### 3D

[Meshy - Free 3D Models Generated from Images and Text](https://www.meshy.ai/)

[Immersity AI | Convert Image and Video to 3D](https://www.immersity.ai/)

[Tripo AI - ç”¨æ–‡å­—æˆ–å›¾ç‰‡å…è´¹ç”Ÿæˆ3Dæ¨¡å‹](https://www.tripo3d.ai/)

### è¯­éŸ³, éŸ³ä¹

[Suno](https://suno.com/)

[æµ·ç»µéŸ³ä¹](https://www.haimianyinyue.com/featured)

[Free Text to Speech & AI Voice Generator | ElevenLabs](https://elevenlabs.io/)

[Udio AI Music Generator - Make Original Tracks in Seconds](https://www.udio.com/home)

[Stable Audio - Generate](https://www.stableaudio.com/generate)

[åœ¨çº¿å…è´¹æ–‡æœ¬è½¬è¯­éŸ³ - TTS-Online | å¤šç§å£°éŸ³ä¸äºŒæ¬¡å…ƒè¯­éŸ³](https://www.ttson.cn/)

[Soundboard - TUNA - Download Unlimited Free Meme Sounds](https://tuna.voicemod.net/)

[èŠ‚å¥ç”Ÿæˆå™¨-Beat Blender éŸ³ä¹](https://experiments.withgoogle.com/ai/beat-blender/view/)

[ç½‘æ˜“å¤©éŸ³ - ä¸€ç«™å¼AIéŸ³ä¹åˆ›ä½œå·¥å…· - å®˜ç½‘](https://tianyin.music.163.com/#/)

### æç¤ºè¯

[promptoMANIA:ç»˜ç”»æç¤ºç”Ÿæˆå™¨](https://promptomania.com/)

[Lexica](https://lexica.art/)

[PromptHero - æç¤ºè¯å¤§å…¨](https://prompthero.com/)

### ä»£ç 

[Codeium Â· Free AI Code Completion & Chat](https://codeium.com/) 2024-12-02

[MarsCode - AI IDE](https://www.marscode.com/home)

[Cursor](https://www.cursor.com/)

[bolt.new](https://bolt.new/)

[ScriptEcho | AIç”Ÿæˆç”Ÿäº§çº§ä»£ç  |](https://scriptecho.cn/index.html)

### å…¶ä»–

[NotebookLM | Note Taking & Research Assistant Powered by AI](https://notebooklm.google/)

[æ‰£å­ - AI æ™ºèƒ½ä½“å¼€å‘å¹³å°](https://www.coze.cn/)

[ Figma](https://www.figma.com/files/team/1441808069682903816/recents-and-sharing?fuid=1441808067539027124)

[Illuminate | Learn Your Way](https://illuminate.google.com/home?pli=1)

[Chat Nio](https://chatnio.net/)

[LlamaOCR.com â€“ Document to markdown](https://llamaocr.com/)

[Neo AI engineer](https://heyneo.so/)

[Excalidraw](https://excalidraw.com/)

### ç­‰å¾…ä¸­çš„é¡¹ç›®

[AnchorCrafter](https://cangcz.github.io/Anchor-Crafter/) 2024-12-02

[Generative Omnimatte: Learning to Decompose Video into Layers](https://gen-omnimatte.github.io/) 2024-12-02

[lehduong/OneDiffusion](https://github.com/lehduong/OneDiffusion) 2024-12-02

[LipDub AI | The most realistic AI lip sync and video translation](https://www.lipdub.ai/) 2024-12-02

[MyTimeMachine: Personalized Facial Age Transformation](https://mytimemachine.github.io/) 2024-12-02

[Buffer Anytime: Zero-Shot Video Depth and Normal from Image Priors](https://bufferanytime.github.io/) 2024-12-02

[MultiFoley](https://ificl.github.io/MultiFoley/) 2024-12-02

[Sonic: Shifting Focus to Global Audio Perception in Audio-driven Portrait Animation](https://jixiaozhong.github.io/Sonic/) 2024-12-02

[lewandofskee/MobileMamba: Official implementation of `MobileMamba: Lightweight Multi-Receptive Visual Mamba Network.'](https://github.com/lewandofskee/MobileMamba) 2024-12-02

[Baking Gaussian Splatting into Diffusion Denoiser for Fast and Scalable Single-stage Image-to-3D Generation](https://caiyuanhao1998.github.io/project/DiffusionGS/) 2024-11-27

[Fugatto, Worldâ€™s Most Flexible Sound Machine, Debuts | NVIDIA Blog](https://blogs.nvidia.com/blog/fugatto-gen-ai-sound-model/) 2024-11-27

[Fashion-VDM: Video Diffusion Model for Virtual Try-On](https://johannakarras.github.io/Fashion-VDM/)

[Inverse Painting: Reconstructing The Painting Process](https://inversepainting.github.io/)

[é¦–é¡µ |å‰§é›†ä¸»ç®¡ --- Home | Showrunner](https://www.showrunner.xyz/)

[æ‚ èˆ¹](https://desktop.youchuan.cn/#/imagine)

[Video Oceanè§†é¢‘å¤§æ¨¡å‹ - äººäººçš†å¯¼æ¼”](https://video.luchentech.com/zh-CN)

[PersonaTalk: Bring Attention to Your Persona in Visual Dubbing](https://grisoon.github.io/PersonaTalk/)

[MarDini: Masked Auto-Regressive Diffusion for Video Generation at Scale -- Meta AI Research](https://mardini-vidgen.github.io/)

[ç‚‰ç±³Lumi](https://artistrylab.net/login)

[loopyavatar.github.io/?ref=aihub.cn](https://loopyavatar.github.io/?ref=aihub.cn)

[Google Vidsï¼šåœ¨çº¿è§†é¢‘åˆ›å»ºå’Œç¼–è¾‘å™¨ | Google Vidsè°·æ­Œå·¥ä½œåŒº --- Google Vids: Online Video Creator and Editor | Google Workspace](https://workspace.google.com/products/vids/#vids-create)

[SkyReels](https://skyreels.ai/beta)

[URAvatar: Universal Relightable Gaussian Codec Avatars](https://junxuan-li.github.io/urgca-website/)

[MikuDance](https://kebii.github.io/MikuDance/)

[Add-it](https://research.nvidia.com/labs/par/addit/)

[DanceFusion: A Spatio-Temporal Skeleton Diffusion Transformer for Audio-Driven Dance Motion Reconstruction.](https://th-mlab.github.io/DanceFusion/#)

[AnimateAnything](https://yu-shaonian.github.io/Animate_Anything/?utm_source=ai-bot.cn)

[MIMO](https://menyifang.github.io/projects/MIMO/index.html)

[InstructAvatar](https://wangyuchi369.github.io/InstructAvatar/)

### æ¨¡å‹, èµ„æº, å·¥ä½œæµ

[Discovery | OpenArt](https://openart.ai/)

[Shakker - Generative AI design tool with diverse models](https://www.shakker.ai/home)

[é¦–é¡µ Â· é­”æ­ç¤¾åŒº](https://www.modelscope.cn/home)

[Comfy Workflows](https://comfyworkflows.com/)

[OpenModelDB](https://openmodeldb.info/)

[FREE online image generator and model hosting site! | Tensor.Art](https://tusiart.com/)

[Civitai: The Home of Open-Source Generative AI](https://civitai.com/)

[CodeWithGPU | èƒ½å¤ç°æ‰æ˜¯å¥½ç®—æ³•](https://www.codewithgpu.com/image)

[LiblibAI-å“©å¸ƒå“©å¸ƒAI - ä¸­å›½é¢†å…ˆçš„AIåˆ›ä½œå¹³å°](https://www.liblib.art/)

[ComfyUIå·¥ä½œæµ - åœ¨çº¿è¿è¡Œï¼Œé€Ÿåº¦å¿«ï¼Œä¸æŠ¥é”™](https://www.runninghub.cn/)

[FREE online image generator and model hosting site! | Tensor.Art](https://tensor.art/)

[Cephalon Cloud ç«¯è„‘äº‘ - AIGC åº”ç”¨å¹³å°](https://cephalon.cloud/#/aigc)

## ç›¸å…³ç½‘ç«™

[Discover and download free videos - Pixabay](https://pixabay.com/videos/search/?order=ec)

[Danbooru: Anime Image Board](https://danbooru.donmai.us/)

[Discover the Best GPTs](https://gptsmenu.com/)

[AIå·¥å…·é›† | 700+ AIå·¥å…·é›†åˆå®˜ç½‘ï¼Œå›½å†…å¤–AIå·¥å…·é›†å¯¼èˆªå¤§å…¨](https://ai-bot.cn/)

[Supertools | Best AI Tools Guide](https://supertools.therundown.ai/)

[AIGCå¯¼èˆª | 1500+å…¨å“ç±»AIGCåˆ›ä½œå·¥å…·_æ¢ç´¢æ›´å¤šå¯èƒ½ï¼](https://www.aigc.cn/)

[æ’ç”»äº¤æµç½‘ç«™[pixiv]](https://www.pixiv.net/?lang=zh&return_to=)

[ArtStation - Explore](https://www.artstation.com/)

[AIbase - æ™ºèƒ½åŒ¹é…æœ€é€‚åˆæ‚¨çš„AIäº§å“å’Œç½‘ç«™](https://top.aibase.com/)

[Newsfeed - Sketchfab](https://sketchfab.com/feed)

[AI Model & API Providers Analysis | Artificial Analysis](https://artificialanalysis.ai/)

[xAI](https://x.ai/)

[GGACæ•°å­—è‰ºæœ¯å¹³å°](https://www.ggac.com/home)

[Weird Wonderful AI Art | ART of the future - now!](https://weirdwonderfulai.art/)

## GitHub é¡¹ç›®

### è§†é¢‘

[hmrishavbandy/FlipSketch: FlipSketch: Flipping Static Drawings to Text-Guided Sketch Animations](https://github.com/hmrishavbandy/FlipSketch) 2024-12-02

[KwaiVGI/LivePortrait: Bring portraits to life!](https://github.com/KwaiVGI/LivePortrait) 2024-12-02

[C0untFloyd/roop-unleashed: Evolved Fork of roop with Web Server and lots of additions](https://github.com/C0untFloyd/roop-unleashed) 2024-12-02

[jdh-algo/JoyVASA](https://github.com/jdh-algo/JoyVASA) 2024-12-02

[PKU-YuanGroup/ConsisID: Identity-Preserving Text-to-Video Generation by Frequency Decomposition](https://github.com/PKU-YuanGroup/ConsisID) 2024-12-02

[rhymes-ai/Allegro: Allegro is a powerful text-to-video model that generates high-quality videos up to 6 seconds at 15 FPS and 720p resolution from simple text input.](https://github.com/rhymes-ai/Allegro) 2024-12-02

[k4yt3x/video2x: A machine learning-based lossless video super resolution framework. Est. Hack the Valley II, 2018.](https://github.com/k4yt3x/video2x) 2024-11-27

[facefusion/facefusion: Industry leading face manipulation platform](https://github.com/facefusion/facefusion) 2024-11-27

[yangchris11/samurai: Official repository of "SAMURAI: Adapting Segment Anything Model for Zero-Shot Visual Tracking with Motion-Aware Memory"](https://github.com/yangchris11/samurai)

[alibaba/Tora: The official repository for paper "Tora: Trajectory-oriented Diffusion Transformer for Video Generation"](https://github.com/alibaba/Tora?tab=readme-ov-file)

[aigc-apps/CogVideoX-Fun: ğŸ“¹ A more flexible CogVideoX that can generate videos at any resolution and creates videos from images.](https://github.com/aigc-apps/CogVideoX-Fun)

[aigc-apps/EasyAnimate: ğŸ“º An End-to-End Solution for High-Resolution and Long Video Generation Based on Transformer Diffusion](https://github.com/aigc-apps/EasyAnimate)

[GitHub - HVision-NKU/StoryDiffusion: Create Magic Story!](https://github.com/HVision-NKU/StoryDiffusion)

[hpcaitech/Open-Sora: Open-Sora: Democratizing Efficient Video Production for All](https://github.com/hpcaitech/Open-Sora?tab=readme-ov-file)

[Vision-CAIR/MiniGPT4-video](https://github.com/Vision-CAIR/MiniGPT4-video)

[hkchengrex/Cutie: [CVPR 2024 Highlight] Putting the Object Back Into Video Object Segmentation](https://github.com/hkchengrex/Cutie)

[Picsart-AI-Research/StreamingT2V: StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text](https://github.com/Picsart-AI-Research/StreamingT2V)

[aigc-apps/EasyAnimate: ğŸ“º An End-to-End Solution for High-Resolution and Long Video Generation Based on Transformer Diffusion](https://github.com/aigc-apps/EasyAnimate/)

[Tencent/MimicMotion: High-Quality Human Motion Video Generation with Confidence-aware Pose Guidance](https://github.com/Tencent/MimicMotion)

[jianchang512/pyvideotrans: Translate the video from one language to another and add dubbing. å°†è§†é¢‘ä»ä¸€ç§è¯­è¨€ç¿»è¯‘ä¸ºå¦ä¸€ç§è¯­è¨€ï¼Œå¹¶æ”¯æŒapiè°ƒç”¨](https://github.com/jianchang512/pyvideotrans)

[Hillobar/Rope: GUI-focused roop](https://github.com/Hillobar/Rope)

[GitHub - sczhou/CodeFormer: [NeurIPS 2022] Towards Robust Blind Face Restoration with Codebook Lookup Transformer](https://github.com/sczhou/CodeFormer)

[Huanshere/VideoLingo: Netflix-level subtitle cutting, translation, alignment, and even dubbing - one-click fully automated AI video subtitle team | Netflixçº§å­—å¹•åˆ‡å‰²ã€ç¿»è¯‘ã€å¯¹é½ã€ç”šè‡³åŠ ä¸Šé…éŸ³ï¼Œä¸€é”®å…¨è‡ªåŠ¨è§†é¢‘æ¬è¿AIå­—å¹•ç»„](https://github.com/Huanshere/VideoLingo)

[jy0205/Pyramid-Flow: Code of Pyramidal Flow Matching for Efficient Video Generative Modeling](https://github.com/jy0205/Pyramid-Flow)

[Vision-CAIR/LongVU](https://github.com/Vision-CAIR/LongVU)

[Doubiiu/ToonCrafter: [SIGGRAPH Asia 2024, Journal Track] ToonCrafter: Generative Cartoon Interpolation](https://github.com/Doubiiu/ToonCrafter)

[VectorSpaceLab/Video-XL: ğŸ”¥ğŸ”¥First-ever hour scale video understanding models](https://github.com/VectorSpaceLab/Video-XL)

[anliyuan/Ultralight-Digital-Human: ä¸€ä¸ªè¶…è½»é‡çº§ã€å¯ä»¥åœ¨ç§»åŠ¨ç«¯å®æ—¶è¿è¡Œçš„æ•°å­—äººæ¨¡å‹](https://github.com/anliyuan/Ultralight-Digital-Human)

[antgroup/echomimic_v2: EchoMimicV2: Towards Striking, Simplified, and Semi-Body Human Animation](https://github.com/antgroup/echomimic_v2)

[Zejun-Yang/AniPortrait: AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animation](https://github.com/Zejun-Yang/AniPortrait)

[fudan-generative-vision/hallo2: Hallo2: Long-Duration and High-Resolution Audio-driven Portrait Image Animation](https://github.com/fudan-generative-vision/hallo2)

[antgroup/echomimic: EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditioning](https://github.com/antgroup/echomimic)

[LordLiang/DrawingSpinUp: (SIGGRAPH Asia 2024) This is the official PyTorch implementation of SIGGRAPH Asia 2024 paper: DrawingSpinUp: 3D Animation from Single Character Drawings](https://github.com/LordLiang/DrawingSpinUp)

[HelloVision/HelloMeme: The official HelloMeme GitHub site](https://github.com/HelloVision/HelloMeme)

[Kmcode1/SG-I2V: This is the official implementation of SG-I2V: Self-Guided Trajectory Control in Image-to-Video Generation.](https://github.com/Kmcode1/SG-I2V)

[facebookresearch/sapiens: High-resolution models for human tasks.](https://github.com/facebookresearch/sapiens)

[AlonzoLeeeooo/StableV2V: The official implementation of the paper titled "StableV2V: Stablizing Shape Consistency in Video-to-Video Editing".](https://github.com/AlonzoLeeeooo/StableV2V)

[genmoai/mochi: The best OSS video generation models](https://github.com/genmoai/mochi)

[THUDM/CogVideo: text and image to video generation: CogVideoX (2024) and CogVideo (ICLR 2023)](https://github.com/THUDM/CogVideo?tab=readme-ov-file)

[CyberAgentAILab/TANGO: Official implementation of the paper "TANGO: Co-Speech Gesture Video Reenactment with Hierarchical Audio-Motion Embedding and Diffusion Interpolation"](https://github.com/CyberAgentAILab/TANGO)

[IDEA-Research/MotionCLR: [Arxiv 2024] MotionCLR: Motion Generation and Training-free Editing via Understanding Attention Mechanisms](https://github.com/IDEA-Research/MotionCLR)

[Ji4chenLi/t2v-turbo: Code repository for T2V-Turbo and T2V-Turbo-v2](https://github.com/Ji4chenLi/t2v-turbo)

[Lightricks/LTX-Video: Official repository for LTX-Video](https://github.com/Lightricks/LTX-Video)

### ComfyUI

[sipie800/ComfyUI-PuLID-Flux-Enhanced](https://github.com/sipie800/ComfyUI-PuLID-Flux-Enhanced) 2024-12-02

[EvilBT/ComfyUI_SLK_joy_caption_two: ComfyUI Node](https://github.com/EvilBT/ComfyUI_SLK_joy_caption_two?tab=readme-ov-file) 2024-11-27

[huchenlei/ComfyUI-layerdiffuse: Layer Diffuse custom nodes](https://github.com/huchenlei/ComfyUI-layerdiffuse) 2024-11-27

[kijai/ComfyUI-IC-Light: Using IC-LIght models in ComfyUI](https://github.com/kijai/ComfyUI-IC-Light) 2024-11-27

[kijai/ComfyUI-CogVideoXWrapper](https://github.com/kijai/ComfyUI-CogVideoXWrapper)

[Lightricks/ComfyUI-LTXVideo: LTX-Video Support for ComfyUI](https://github.com/Lightricks/ComfyUI-LTXVideo)

[smthemex/ComfyUI_EchoMimic: You can using EchoMimic in ComfyUI](https://github.com/smthemex/ComfyUI_EchoMimic)

[AIFSH/ACE-ComfyUI](https://github.com/AIFSH/ACE-ComfyUI?tab=readme-ov-file)

[logtd/ComfyUI-MochiEdit: ComfyUI nodes to edit videos using Genmo Mochi](https://github.com/logtd/ComfyUI-MochiEdit)

[kijai/ComfyUI-SUPIR: SUPIR upscaling wrapper for ComfyUI](https://github.com/kijai/ComfyUI-SUPIR)

[HelloVision/ComfyUI_HelloMeme: Official comfyui repository of Hellomeme](https://github.com/HelloVision/ComfyUI_HelloMeme)

[alimama-creative/SDXL_EcomID_ComfyUI](https://github.com/alimama-creative/SDXL_EcomID_ComfyUI)

[AIGODLIKE/AIGODLIKE-ComfyUI-Studio: Improve the interactive experience of using ComfyUI, such as making the loading of ComfyUI models more intuitive and making it easier to create model thumbnails](https://github.com/AIGODLIKE/AIGODLIKE-ComfyUI-Studio)

[ssitu/ComfyUI_UltimateSDUpscale: ComfyUI nodes for the Ultimate Stable Diffusion Upscale script by Coyote-A.](https://github.com/ssitu/ComfyUI_UltimateSDUpscale)

[Gourieff/comfyui-reactor-node: Fast and Simple Face Swap Extension Node for ComfyUI](https://github.com/Gourieff/comfyui-reactor-node)

[lldacing/ComfyUI_BiRefNet_ll](https://github.com/lldacing/ComfyUI_BiRefNet_ll)

[AIGODLIKE/ComfyUI-BlenderAI-node: Used for AI model generation, next-generation Blender rendering engine, texture enhancement&generation (based on ComfyUI)](https://github.com/AIGODLIKE/ComfyUI-BlenderAI-node)

[smthemex/ComfyUI_Hallo2: ComfyUI_Hallo2: Long-Duration and High-Resolution Audio-driven Portrait Image Animation](https://github.com/smthemex/ComfyUI_Hallo2)

[kijai/ComfyUI-Florence2: Inference Microsoft Florence2 VLM](https://github.com/kijai/ComfyUI-Florence2)

[CY-CHENYUE/ComfyUI-Molmo: Generate detailed image descriptions and analysis using Molmo models in ComfyUI.](https://github.com/CY-CHENYUE/ComfyUI-Molmo)

[yolain/ComfyUI-Easy-Use: In order to make it easier to use the ComfyUI, I have made some optimizations and integrations to some commonly used nodes.](https://github.com/yolain/ComfyUI-Easy-Use)

[sipherxyz/comfyui-art-venture](https://github.com/sipherxyz/comfyui-art-venture)

[GiusTex/ComfyUI-DiffusersImageOutpaint: Diffusers Image Outpaint for ComfyUI](https://github.com/GiusTex/ComfyUI-DiffusersImageOutpaint)

[XLabs-AI/x-flux-comfyui](https://github.com/XLabs-AI/x-flux-comfyui)

[T8star1984/Comfyui-Aix-NodeMap: Comfyui's latest node organization and annotation, continuously updated, and supported by the Aix team/comfyuiæœ€æ–°èŠ‚ç‚¹æ•´ç†åŠæ³¨é‡Šï¼ŒæŒç»­æ›´æ–°ï¼ŒAIXå›¢é˜Ÿ](https://github.com/T8star1984/Comfyui-Aix-NodeMap)

[T8star1984/Comfyui-Aix-NodeMap: Comfyui's latest node organization and annotation, continuously updated, and supported by the Aix team/comfyuiæœ€æ–°èŠ‚ç‚¹æ•´ç†åŠæ³¨é‡Šï¼ŒæŒç»­æ›´æ–°ï¼ŒAIXå›¢é˜Ÿ](https://github.com/T8star1984/Comfyui-Aix-NodeMap/tree/main)

[logtd/ComfyUI-Fluxtapoz: Nodes for image juxtaposition for Flux in ComfyUI](https://github.com/logtd/ComfyUI-Fluxtapoz)

[WASasquatch/was-node-suite-comfyui: An extensive node suite for ComfyUI with over 210 new nodes](https://github.com/WASasquatch/was-node-suite-comfyui)

[cubiq/ComfyUI_IPAdapter_plus](https://github.com/cubiq/ComfyUI_IPAdapter_plus)

[cubiq/ComfyUI_InstantID](https://github.com/cubiq/ComfyUI_InstantID)

[cubiq/ComfyUI_InstantID](https://github.com/cubiq/ComfyUI_InstantID?tab=readme-ov-file)

[ZHO-ZHO-ZHO/ComfyUI-InstantID: Unofficial implementation of InstantID for ComfyUI](https://github.com/ZHO-ZHO-ZHO/ComfyUI-InstantID)

[kijai/ComfyUI-MochiWrapper](https://github.com/kijai/ComfyUI-MochiWrapper)

[kijai/ComfyUI-LivePortraitKJ: ComfyUI nodes for LivePortrait](https://github.com/kijai/ComfyUI-LivePortraitKJ)

[PowerHouseMan/ComfyUI-AdvancedLivePortrait](https://github.com/PowerHouseMan/ComfyUI-AdvancedLivePortrait)

[TemryL/ComfyUI-IDM-VTON: ComfyUI adaptation of IDM-VTON for virtual try-on.](https://github.com/TemryL/ComfyUI-IDM-VTON)

[city96/ComfyUI-GGUF: GGUF Quantization support for native ComfyUI models](https://github.com/city96/ComfyUI-GGUF)

[FizzleDorf/ComfyUI_FizzNodes: Custom Nodes for Comfyui](https://github.com/FizzleDorf/ComfyUI_FizzNodes)

[balazik/ComfyUI-PuLID-Flux: PuLID-Flux ComfyUI implementation](https://github.com/balazik/ComfyUI-PuLID-Flux)

[kijai/ComfyUI-PyramidFlowWrapper](https://github.com/kijai/ComfyUI-PyramidFlowWrapper)

[stavsap/comfyui-ollama](https://github.com/stavsap/comfyui-ollama)

[ltdrdata/ComfyUI-Manager: ComfyUI-Manager is an extension designed to enhance the usability of ComfyUI. It offers management functions to install, remove, disable, and enable various custom nodes of ComfyUI. Furthermore, this extension provides a hub feature and convenience functions to access a wide range of information within ComfyUI.](https://github.com/ltdrdata/ComfyUI-Manager)

[erosDiffusion/ComfyUI-enricos-nodes: Compositor Node experiments](https://github.com/erosDiffusion/ComfyUI-enricos-nodes)

[StartHua/Comfyui_CXH_joy_caption: Recommended based on comfyui node pictures:Joy_caption + MiniCPMv2_6-prompt-generator + florence2](https://github.com/StartHua/Comfyui_CXH_joy_caption)

[ZHO-ZHO-ZHO/ComfyUI-YoloWorld-EfficientSAM: Unofficial implementation of YOLO-World + EfficientSAM for ComfyUI](https://github.com/ZHO-ZHO-ZHO/ComfyUI-YoloWorld-EfficientSAM)

[logtd/ComfyUI-Fluxtapoz: Nodes for image juxtaposition for Flux in ComfyUI](https://github.com/logtd/ComfyUI-Fluxtapoz?tab=readme-ov-file)

[GreenLandisaLie/AuraSR-ComfyUI: ComfyUI implementation of AuraSR](https://github.com/GreenLandisaLie/AuraSR-ComfyUI)

[Jonseed/ComfyUI-Detail-Daemon: A port of muerrilla's sd-webui-Detail-Daemon as a node for ComfyUI, to adjust sigmas that control detail.](https://github.com/Jonseed/ComfyUI-Detail-Daemon)

[taabata/ComfyCanvas: Canvas to use with ComfyUI](https://github.com/taabata/ComfyCanvas)

[jtydhr88/ComfyUI-Hunyuan3D-1-wrapper: ComfyUI Hunyuan3D-1-wrapper is a custom node that allows you to run Tencent/Hunyuan3D-1 in ComfyUI as a wrapper.](https://github.com/jtydhr88/ComfyUI-Hunyuan3D-1-wrapper)

[smthemex/ComfyUI_Sapiens: You can call Using Sapiens to get segï¼Œnormalï¼Œposeï¼Œdepthï¼Œmask](https://github.com/smthemex/ComfyUI_Sapiens)

[1038lab/ComfyUI-RMBG: A ComfyUI node for removing image backgrounds using RMBG-2.0.](https://github.com/1038lab/ComfyUI-RMBG)

[TTPlanetPig/Comfyui_Object_Migration: This is a study aim to transfer the single concept by using DIT model self-attention capablity](https://github.com/TTPlanetPig/Comfyui_Object_Migration)

[DoctorDiffusion/ComfyUI-BEN: Background Erase Network - Remove backgrounds from images within ComfyUI.](https://github.com/DoctorDiffusion/ComfyUI-BEN)

[marduk191/ComfyUI-Fluxpromptenhancer: A Prompt Enhancer for flux.1 in ComfyUI](https://github.com/marduk191/ComfyUI-Fluxpromptenhancer)

[Lightricks/ComfyUI-LTXVideo: LTX-Video Support for ComfyUI](https://github.com/Lightricks/ComfyUI-LTXVideo?tab=readme-ov-file)

### WebUI

[open-webui/open-webui: User-friendly AI Interface (Supports Ollama, OpenAI API, ...)](https://github.com/open-webui/open-webui)

[continue-revolution/sd-webui-segment-anything: Segment Anything for Stable Diffusion WebUI](https://github.com/continue-revolution/sd-webui-segment-anything)

[lllyasviel/stable-diffusion-webui-forge](https://github.com/lllyasviel/stable-diffusion-webui-forge)

[aigc-apps/sd-webui-EasyPhoto: ğŸ“· EasyPhoto | Your Smart AI Photo Generator.](https://github.com/aigc-apps/sd-webui-EasyPhoto)

### LLM

[THUDM/GLM-4-Voice: GLM-4-Voice | ç«¯åˆ°ç«¯ä¸­è‹±è¯­éŸ³å¯¹è¯æ¨¡å‹](https://github.com/THUDM/GLM-4-Voice)

[oobabooga/text-generation-webui: A Gradio web UI for Large Language Models.](https://github.com/oobabooga/text-generation-webui)

[janhq/jan: Jan is an open source alternative to ChatGPT that runs 100% offline on your computer. Multiple engine support (llama.cpp, TensorRT-LLM)](https://github.com/janhq/jan)

[ollama/ollama: Get up and running with Llama 3.2, Mistral, Gemma 2, and other large language models.](https://github.com/ollama/ollama)

[binary-husky/gpt_academic: ä¸ºGPT/GLMç­‰LLMå¤§è¯­è¨€æ¨¡å‹æä¾›å®ç”¨åŒ–äº¤äº’æ¥å£ï¼Œç‰¹åˆ«ä¼˜åŒ–è®ºæ–‡é˜…è¯»/æ¶¦è‰²/å†™ä½œä½“éªŒï¼Œæ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒè‡ªå®šä¹‰å¿«æ·æŒ‰é’®&å‡½æ•°æ’ä»¶ï¼Œæ”¯æŒPythonå’ŒC++ç­‰é¡¹ç›®å‰–æ&è‡ªè¯‘è§£åŠŸèƒ½ï¼ŒPDF/LaTexè®ºæ–‡ç¿»è¯‘&æ€»ç»“åŠŸèƒ½ï¼Œæ”¯æŒå¹¶è¡Œé—®è¯¢å¤šç§LLMæ¨¡å‹ï¼Œæ”¯æŒchatglm3ç­‰æœ¬åœ°æ¨¡å‹ã€‚æ¥å…¥é€šä¹‰åƒé—®, deepseekcoder, è®¯é£æ˜Ÿç«, æ–‡å¿ƒä¸€è¨€, llama2, rwkv, claude2, mossç­‰ã€‚](https://github.com/binary-husky/gpt_academic)

[SillyTavern/SillyTavern: LLM Frontend for Power Users.](https://github.com/SillyTavern/SillyTavern)

[mendableai/firecrawl: ğŸ”¥ Turn entire websites into LLM-ready markdown or structured data. Scrape, crawl and extract with a single API.](https://github.com/mendableai/firecrawl)

[InternLM/InternLM: Official release of InternLM2.5 base and chat models. 1M context support](https://github.com/InternLM/InternLM)

### è®­ç»ƒè„šæœ¬

[hiyouga/LLaMA-Factory: Unified Efficient Fine-Tuning of 100+ LLMs (ACL 2024)](https://github.com/hiyouga/LLaMA-Factory) 2024-12-02

[kohya-ss/sd-scripts](https://github.com/kohya-ss/sd-scripts)

[cocktailpeanut/fluxgym: Dead simple FLUX LoRA training UI with LOW VRAM support](https://github.com/cocktailpeanut/fluxgym)

[kijai/ComfyUI-FluxTrainer](https://github.com/kijai/ComfyUI-FluxTrainer)

[Releases Â· bmaltais/kohya_ss](https://github.com/bmaltais/kohya_ss)

[Akegarasu/lora-scripts: LoRA & Dreambooth training scripts & GUI use kohya-ss's trainer, for diffusion model.](https://github.com/Akegarasu/lora-scripts)

[Nerogar/OneTrainer: OneTrainer is a one-stop solution for all your stable diffusion training needs.](https://github.com/Nerogar/OneTrainer)

### å›¾åƒè®¾è®¡

[chengyou-jia/ChatGen](https://github.com/chengyou-jia/ChatGen?tab=readme-ov-file) 2024-12-02

[erwold/qwen2vl-flux](https://github.com/erwold/qwen2vl-flux) 2024-11-27

[Yuanshi9815/OminiControl: A minimal and universal controller for FLUX.1.](https://github.com/Yuanshi9815/OminiControl) 2024-11-27

[lllyasviel/sd-forge-layerdiffuse: [WIP] Layer Diffusion for WebUI (via Forge)](https://github.com/lllyasviel/sd-forge-layerdiffuse) 2024-11-27

[ali-vilab/ACE: All-round Creator and Editor](https://github.com/ali-vilab/ACE)

[mit-han-lab/hart: HART: Efficient Visual Generation with Hybrid Autoregressive Transformer](https://github.com/mit-han-lab/hart)

[ZhengPeng7/BiRefNet: [CAAI AIR'24] Bilateral Reference for High-Resolution Dichotomous Image Segmentation](https://github.com/ZhengPeng7/BiRefNet)

[YangLing0818/IterComp: IterComp: Iterative Composition-Aware Feedback Learning from Model Gallery for Text-to-Image Generation](https://github.com/YangLing0818/IterComp)

[xinsir6/ControlNetPlus: ControlNet++: All-in-one ControlNet for image generations and editing!](https://github.com/xinsir6/ControlNetPlus)

[Kwai-Kolors/Kolors: Kolors Team](https://github.com/Kwai-Kolors/Kolors)

[Xiaojiu-z/Stable-Hair: Stable-Hair: Real-World Hair Transfer via Diffusion Model](https://github.com/Xiaojiu-z/Stable-Hair)

[yisol/IDM-VTON: [ECCV2024] IDM-VTON : Improving Diffusion Models for Authentic Virtual Try-on in the Wild](https://github.com/yisol/IDM-VTON)

[bcmi/libcom: Image composition toolbox: everything you want to know about image composition or object insertion](https://github.com/bcmi/libcom)

[PixArt-alpha/PixArt-alpha: PixArt-Î±: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis](https://github.com/PixArt-alpha/PixArt-alpha)

[black-forest-labs/flux: Official inference repo for FLUX.1 models](https://github.com/black-forest-labs/flux)

[Stability-AI/sd3.5](https://github.com/Stability-AI/sd3.5)

[lllyasviel/Omost: Your image is almost there!](https://github.com/lllyasviel/Omost)

[gligen/GLIGEN: Open-Set Grounded Text-to-Image Generation](https://github.com/gligen/GLIGEN)

[Tencent/HunyuanDiT: Hunyuan-DiT : A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding](https://github.com/Tencent/HunyuanDiT)

[lllyasviel/IC-Light: More relighting!](https://github.com/lllyasviel/IC-Light)

[tencent-ailab/IP-Adapter: The image prompt adapter is designed to enable a pretrained text-to-image diffusion model to generate images with image prompt.](https://github.com/tencent-ailab/IP-Adapter)

[piddnad/DDColor: [ICCV 2023] Official implementation of "DDColor: Towards Photo-Realistic Image Colorization via Dual Decoders"](https://github.com/piddnad/DDColor)

[cumulo-autumn/StreamDiffusion: StreamDiffusion: A Pipeline-Level Solution for Real-Time Interactive Generation](https://github.com/cumulo-autumn/StreamDiffusion)

[ToTheBeginning/PuLID: [NeurIPS 2024] Official code for PuLID: Pure and Lightning ID Customization via Contrastive Alignment](https://github.com/ToTheBeginning/PuLID)

[KDE/krita: Krita is a free and open source cross-platform application that offers an end-to-end solution for creating digital art files from scratch built on the KDE and Qt frameworks.](https://github.com/KDE/krita)

[Acly/krita-ai-diffusion: Streamlined interface for generating images with AI in Krita. Inpaint and outpaint with optional text prompt, no tweaking required.](https://github.com/Acly/krita-ai-diffusion)

[instantX-research/InstantID: InstantID: Zero-shot Identity-Preserving Generation in Seconds ğŸ”¥](https://github.com/instantX-research/InstantID)

[jbilcke-hf/FacePoke: Select a portrait, click to move the head around (please use your own space / GPU!)](https://github.com/jbilcke-hf/FacePoke)

[catcathh/UltraPixel: Implementation of UltraPixel: Advancing Ultra-High-Resolution Image Synthesis to New Peaks](https://github.com/catcathh/UltraPixel)

[Zeyi-Lin/HivisionIDPhotos: âš¡ï¸HivisionIDPhotos: a lightweight and efficient AI ID photos tools. ä¸€ä¸ªè½»é‡çº§çš„AIè¯ä»¶ç…§åˆ¶ä½œç®—æ³•ã€‚](https://github.com/Zeyi-Lin/HivisionIDPhotos)

[VectorSpaceLab/OmniGen: OmniGen: Unified Image Generation. https://arxiv.org/pdf/2409.11340](https://github.com/VectorSpaceLab/OmniGen)

[shallowdream204/DreamClear: [NeurIPS 2024ğŸ”¥] DreamClear: High-Capacity Real-World Image Restoration with Privacy-Safe Dataset Curation](https://github.com/shallowdream204/DreamClear)

[NVlabs/consistory](https://github.com/NVlabs/consistory)

[instantX-research/Regional-Prompting-FLUX: Training-free Regional Prompting for Diffusion Transformers ğŸ”¥](https://github.com/instantX-research/Regional-Prompting-FLUX)

[ali-vilab/In-Context-LoRA: Official repository of In-Context LoRA for Diffusion Transformers](https://github.com/ali-vilab/In-Context-LoRA)

[mit-han-lab/nunchaku: SVDQuant: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion Models](https://github.com/mit-han-lab/nunchaku)

[ChenyangSi/FreeU: FreeU: Free Lunch in Diffusion U-Net (CVPR2024 Oral)](https://github.com/ChenyangSi/FreeU)

[magic-quill/MagicQuill: Official Implementations for Paper - MagicQuill: An Intelligent Interactive Image Editing System](https://github.com/magic-quill/MagicQuill)

[Nutlope/logocreator: A free + OSS logo generator powered by Flux on Together AI](https://github.com/Nutlope/logocreator)

[NVlabs/Sana: SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformer](https://github.com/NVlabs/Sana)

[JackAILab/ConsistentID: Customized ID Consistent for human](https://github.com/JackAILab/ConsistentID)

[DepthAnything/Depth-Anything-V2: [NeurIPS 2024] Depth Anything V2. A More Capable Foundation Model for Monocular Depth Estimation](https://github.com/DepthAnything/Depth-Anything-V2)

[tryonlabs/FLUX.1-dev-LoRA-Outfit-Generator: FLUX.1-dev LoRA Outfit Generator can create an outfit by detailing the color, pattern, fit, style, material, and type.](https://github.com/tryonlabs/FLUX.1-dev-LoRA-Outfit-Generator)

### è¯­éŸ³, éŸ³ä¹

[netease-youdao/EmotiVoice: EmotiVoice ğŸ˜Š: a Multi-Voice and Prompt-Controlled TTS Engine](https://github.com/netease-youdao/EmotiVoice?tab=readme-ov-file)

[haidog-yaqub/EzAudio: High-quality Text-to-Audio Generation with Efficient Diffusion Transformer](https://github.com/haidog-yaqub/EzAudio)

[2noise/ChatTTS: A generative speech model for daily dialogue.](https://github.com/2noise/ChatTTS)

[BytedanceSpeech/seed-tts-eval](https://github.com/BytedanceSpeech/seed-tts-eval)

[RVC-Project/Retrieval-based-Voice-Conversion-WebUI: Easily train a good VC model with voice data <= 10 mins!](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI)

[GitHub - yxlllc/DDSP-SVC: Real-time end-to-end singing voice conversion system based on DDSP (Differentiable Digital Signal Processing)](https://github.com/yxlllc/DDSP-SVC)

[voicepaw/so-vits-svc-fork: so-vits-svc fork with realtime support, improved interface and more features.](https://github.com/voicepaw/so-vits-svc-fork)

[GitHub - RVC-Boss/GPT-SoVITS: 1 min voice data can also be used to train a good TTS model! (few shot voice cloning)](https://github.com/RVC-Boss/GPT-SoVITS)

[SWivid/F5-TTS: Official code for "F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching"](https://github.com/SWivid/F5-TTS)

[misya11p/amt-apc: AMT-APC: AMT-APC: Automatic Piano Cover by Fine-Tuning an Automatic Music Transcription Model](https://github.com/misya11p/amt-apc)

[WEIFENG2333/AsrTools: âœ¨ AsrTools: æ™ºèƒ½è¯­éŸ³è½¬æ–‡å­—å·¥å…· | é«˜æ•ˆæ‰¹å¤„ç† | ç”¨æˆ·å‹å¥½ç•Œé¢ | æ— éœ€ GPU |æ”¯æŒ SRT/TXT è¾“å‡º | è®©æ‚¨çš„éŸ³é¢‘ç¬é—´å˜æˆç²¾ç¡®æ–‡å­—ï¼](https://github.com/WEIFENG2333/AsrTools)

[open-mmlab/Amphion: Amphion (/Ã¦mËˆfaÉªÉ™n/) is a toolkit for Audio, Music, and Speech Generation. Its purpose is to support reproducible research and help junior researchers and engineers get started in the field of audio, music, and speech generation research and development.](https://github.com/open-mmlab/Amphion)

[fishaudio/fish-speech: Brand new TTS solution](https://github.com/fishaudio/fish-speech)

### 3D

[VAST-AI-Research/TripoSR](https://github.com/VAST-AI-Research/TripoSR) 2024-11-27

[microsoft/MoGe: MoGe: Unlocking Accurate Monocular Geometry Estimation for Open-Domain Images with Optimal Training Supervision](https://github.com/microsoft/MoGe?tab=readme-ov-file)

[HengyiWang/spann3r: 3D Reconstruction with Spatial Memory](https://github.com/HengyiWang/spann3r)

[Tencent/Hunyuan3D-1](https://github.com/Tencent/Hunyuan3D-1)

[wenqsun/DimensionX: DimensionX: Create Any 3D and 4D Scenes from a Single Image with Controllable Video Diffusion](https://github.com/wenqsun/DimensionX)

### æ–‡æœ¬å¤„ç†

[zyddnys/manga-image-translator: Translate manga/image ä¸€é”®ç¿»è¯‘å„ç±»å›¾ç‰‡å†…æ–‡å­— https://cotrans.touhou.ai/](https://github.com/zyddnys/manga-image-translator)

[chidiwilliams/buzz: Buzz transcribes and translates audio offline on your personal computer. Powered by OpenAI's Whisper.](https://github.com/chidiwilliams/buzz)

[AgentEra/Agently-Daily-News-Collector: An open-source LLM based automatically daily news collecting workflow showcase powered by Agently AI application development framework.](https://github.com/AgentEra/Agently-Daily-News-Collector)

[LC044/WeChatMsg: æå–å¾®ä¿¡èŠå¤©è®°å½•ï¼Œå°†å…¶å¯¼å‡ºæˆHTMLã€Wordã€Excelæ–‡æ¡£æ°¸ä¹…ä¿å­˜ï¼Œå¯¹èŠå¤©è®°å½•è¿›è¡Œåˆ†æç”Ÿæˆå¹´åº¦èŠå¤©æŠ¥å‘Šï¼Œç”¨èŠå¤©æ•°æ®è®­ç»ƒä¸“å±äºä¸ªäººçš„AIèŠå¤©åŠ©æ‰‹](https://github.com/LC044/WeChatMsg)

[gabrielchua/open-notebooklm: Convert any PDF into a podcast episode!](https://github.com/gabrielchua/open-notebooklm)

[getomni-ai/zerox: Zero shot pdf OCR with gpt-4o-mini](https://github.com/getomni-ai/zerox)

[opendatalab/PDF-Extract-Kit: A Comprehensive Toolkit for High-Quality PDF Content Extraction](https://github.com/opendatalab/PDF-Extract-Kit)

[Nutlope/llama-ocr: Document to Markdown OCR library with Llama 3.2 vision](https://github.com/Nutlope/llama-ocr)

[opendatalab/MinerU: A high-quality tool for convert PDF to Markdown and JSON.ä¸€ç«™å¼å¼€æºé«˜è´¨é‡æ•°æ®æå–å·¥å…·ï¼Œå°†PDFè½¬æ¢æˆMarkdownå’ŒJSONæ ¼å¼ã€‚](https://github.com/opendatalab/MinerU)

### å…¶ä»–

[showlab/ShowUI: Repository for ShowUI: One Vision-Language-Action Model for GUI Visual Agent](https://github.com/showlab/ShowUI) 2024-12-02

[turboderp/exllamav2: A fast inference library for running LLMs locally on modern consumer-class GPUs](https://github.com/turboderp/exllamav2) 2024-12-02

[instructor-ai/instructor: structured outputs for llms](https://github.com/instructor-ai/instructor) 2024-12-02

[Comprehensive Guide to Prompting Techniques - Instructor](https://python.useinstructor.com/prompting/) 2024-12-02

[huggingface/transformers.js: State-of-the-art Machine Learning for the web. Run ğŸ¤— Transformers directly in your browser, with no need for a server!](https://github.com/huggingface/transformers.js) 2024-12-02

[Ucas-HaoranWei/GOT-OCR2.0: Official code implementation of General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model](https://github.com/Ucas-HaoranWei/GOT-OCR2.0)

[deepseek-ai/DeepSeek-VL: DeepSeek-VL: Towards Real-World Vision-Language Understanding](https://github.com/deepseek-ai/DeepSeek-VL)

[dynobo/normcap: OCR powered screen-capture tool to capture information instead of images](https://github.com/dynobo/normcap)

[modelscope/DiffSynth-Studio: Enjoy the magic of Diffusion models!](https://github.com/modelscope/DiffSynth-Studio?tab=readme-ov-file#usage-in-webui)

[abi/screenshot-to-code: Drop in a screenshot and convert it to clean code (HTML/Tailwind/React/Vue)](https://github.com/abi/screenshot-to-code)

[stackblitz/bolt.new: Prompt, run, edit, and deploy full-stack web applications](https://github.com/stackblitz/bolt.new)

[lean-dojo/LeanCopilot: LLMs as Copilots for Theorem Proving in Lean](https://github.com/lean-dojo/LeanCopilot)

[geekan/MetaGPT: ğŸŒŸ The Multi-Agent Framework: First AI Software Company, Towards Natural Language Programming](https://github.com/geekan/MetaGPT)

[princeton-nlp/SWE-agent: [NeurIPS 2024] SWE-agent takes a GitHub issue and tries to automatically fix it, using GPT-4, or your LM of choice. It can also be employed for offensive cybersecurity or competitive coding challenges.](https://github.com/princeton-nlp/SWE-agent)

[OpenCodeInterpreter/OpenCodeInterpreter: OpenCodeInterpreter is a suite of open-source code generation systems aimed at bridging the gap between large language models and sophisticated proprietary systems like the GPT-4 Code Interpreter. It significantly enhances code generation capabilities by integrating execution and iterative refinement functionalities.](https://github.com/OpenCodeInterpreter/OpenCodeInterpreter)

[Ikaros-521/AI-Vtuber: AI Vtuberæ˜¯ä¸€ä¸ªç”± ã€ChatterBot/ChatGPT/claude/langchain/chatglm/text-gen-webui/é—»è¾¾/åƒé—®/kimi/ollamaã€‘ é©±åŠ¨çš„è™šæ‹Ÿä¸»æ’­ã€Live2D/UE/xunirenã€‘ï¼Œå¯ä»¥åœ¨ ã€Bilibili/æŠ–éŸ³/å¿«æ‰‹/å¾®ä¿¡è§†é¢‘å·/æ‹¼å¤šå¤š/æ–—é±¼/YouTube/twitch/TikTokã€‘ ç›´æ’­ä¸­ä¸è§‚ä¼—å®æ—¶äº’åŠ¨ æˆ– ç›´æ¥åœ¨æœ¬åœ°è¿›è¡ŒèŠå¤©ã€‚å®ƒä½¿ç”¨TTSæŠ€æœ¯ã€edge-tts/VITS/elevenlabs/bark/bert-vits2/ç¿å£°ã€‘ç”Ÿæˆå›ç­”å¹¶å¯ä»¥é€‰æ‹©ã€so-vits-svc/DDSP-SVCã€‘å˜å£°ï¼›æŒ‡ä»¤ååŒSDç”»å›¾ã€‚](https://github.com/Ikaros-521/AI-Vtuber)

[GitHub - 3b1b/manim: Animation engine for explanatory math videos](https://github.com/3b1b/manim)

[GitHub - ManimCommunity/manim: A community-maintained Python framework for creating mathematical animations.](https://github.com/manimCommunity/manim)

[GitHub - KindXiaoming/pykan: Kolmogorov Arnold Networks](https://github.com/KindXiaoming/pykan)

[GitHub - PeterH0323/Streamer-Sales: Streamer-Sales é”€å†  â€”â€” å–è´§ä¸»æ’­å¤§æ¨¡å‹ï¼Œä¸€ä¸ªèƒ½å¤Ÿæ ¹æ®ç»™å®šçš„å•†å“ç‰¹ç‚¹å¯¹å•†å“è¿›è¡Œè§£è¯´å¹¶æ¿€å‘ç”¨æˆ·çš„è´­ä¹°æ„æ„¿çš„å–è´§ä¸»æ’­æ¨¡å‹](https://github.com/PeterH0323/Streamer-Sales)

[FujiwaraChoki/MoneyPrinter: Automate Creation of YouTube Shorts using MoviePy.](https://github.com/FujiwaraChoki/MoneyPrinter)

[princeton-nlp/SWE-agent: SWE-agent takes a GitHub issue and tries to automatically fix it, using GPT-4. It solves 12.29% of bugs in the SWE-bench evaluation set (comparable to Devin) and take just 1.5 minutes to run (7x faster than Devin).](https://github.com/princeton-nlp/swe-agent)

[harry0703/MoneyPrinterTurbo: åˆ©ç”¨AIå¤§æ¨¡å‹ï¼Œä¸€é”®ç”Ÿæˆé«˜æ¸…çŸ­è§†é¢‘ Generate short videos with one click using AI LLM.](https://github.com/harry0703/MoneyPrinterTurbo)

[idootop/mi-gpt: ğŸ  å°†å°çˆ±éŸ³ç®±æ¥å…¥ ChatGPT å’Œè±†åŒ…ï¼Œæ”¹é€ æˆä½ çš„ä¸“å±è¯­éŸ³åŠ©æ‰‹ã€‚](https://github.com/idootop/mi-gpt)

[wan-h/awesome-digital-human-live2d: Awesome Digital Human](https://github.com/wan-h/awesome-digital-human-live2d)

[openai/swarm: Educational framework exploring ergonomic, lightweight multi-agent orchestration. Managed by OpenAI Solution team.](https://github.com/openai/swarm)

[meta-llama/llama-recipes: Scripts for fine-tuning Meta Llama with composable FSDP & PEFT methods to cover single/multi-node GPUs. Supports default & custom datasets for applications such as summarization and Q&A. Supporting a number of candid inference solutions such as HF TGI, VLLM for local or cloud deployment. Demo apps to showcase Meta Llama for WhatsApp & Messenger.](https://github.com/meta-llama/llama-recipes)

[HqWu-HITCS/Awesome-Chinese-LLM: æ•´ç†å¼€æºçš„ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹ï¼Œä»¥è§„æ¨¡è¾ƒå°ã€å¯ç§æœ‰åŒ–éƒ¨ç½²ã€è®­ç»ƒæˆæœ¬è¾ƒä½çš„æ¨¡å‹ä¸ºä¸»ï¼ŒåŒ…æ‹¬åº•åº§æ¨¡å‹ï¼Œå‚ç›´é¢†åŸŸå¾®è°ƒåŠåº”ç”¨ï¼Œæ•°æ®é›†ä¸æ•™ç¨‹ç­‰ã€‚](https://github.com/HqWu-HITCS/Awesome-Chinese-LLM)

[Hannibal046/Awesome-LLM: Awesome-LLM: a curated list of Large Language Model](https://github.com/Hannibal046/Awesome-LLM)

[excalidraw/excalidraw: Virtual whiteboard for sketching hand-drawn like diagrams](https://github.com/excalidraw/excalidraw)

[meltylabs/melty: Chat first code editor. To download the packaged app:](https://github.com/meltylabs/melty)

[gpt-omni/mini-omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex Capabilitiesã€‚](https://github.com/gpt-omni/mini-omni2)

## Hugging Face

[Qwen2vl Flux Mini Demo - a Hugging Face Space by Djrango](https://huggingface.co/spaces/Djrango/qwen2vl-flux-mini-demo) 2024-12-02

[IC Light V2-Vary - a Hugging Face Space by lllyasviel](https://huggingface.co/spaces/lllyasviel/iclight-v2-vary) 2024-12-02

[IllusionDiffusion - a Hugging Face Space by AP123](https://huggingface.co/spaces/AP123/IllusionDiffusion) 2024-12-02

[ReplaceAnything - a Hugging Face Space by modelscope](https://huggingface.co/spaces/modelscope/ReplaceAnything) 2024-12-02

[QwQ-32B-Preview - a Hugging Face Space by Qwen](https://huggingface.co/spaces/Qwen/QwQ-32B-preview) 2024-12-02

[OminiControl - a Hugging Face Space by Yuanshi](https://huggingface.co/spaces/Yuanshi/OminiControl) 2024-11-27

[ACE-Chat - a Hugging Face Space by scepter-studio](https://huggingface.co/spaces/scepter-studio/ACE-Chat)

[MoGe - a Hugging Face Space by Ruicheng](https://huggingface.co/spaces/Ruicheng/MoGe)

[EzAudio - a Hugging Face Space by OpenSound](https://huggingface.co/spaces/OpenSound/EzAudio)

[NaturalSpeech3 FACodec - a Hugging Face Space by amphion](https://huggingface.co/spaces/amphion/naturalspeech3_facodec)

[IDM VTON - a Hugging Face Space by yisol](https://huggingface.co/spaces/yisol/IDM-VTON)

[AnimateDiff-Lightning - a Hugging Face Space by ByteDance](https://huggingface.co/spaces/ByteDance/AnimateDiff-Lightning)

[Omost - a Hugging Face Space by lllyasviel](https://huggingface.co/spaces/lllyasviel/Omost)

[CLIP Interrogator - a Hugging Face Space by pharmapsychotic](https://huggingface.co/spaces/pharmapsychotic/CLIP-Interrogator)

[Pyramid Flow - a Hugging Face Space by Pyramid-Flow](https://huggingface.co/spaces/Pyramid-Flow/pyramid-flow)

[Joy Caption Alpha Two - a Hugging Face Space by fancyfeast](https://huggingface.co/spaces/fancyfeast/joy-caption-alpha-two)

[IC Light V2 - a Hugging Face Space by lllyasviel](https://huggingface.co/spaces/lllyasviel/iclight-v2)

[MaskGCT TTS Demo - a Hugging Face Space by amphion](https://huggingface.co/spaces/amphion/maskgct)

[OmniGen - a Hugging Face Space by Shitao](https://huggingface.co/spaces/Shitao/OmniGen)

[MotionCLR - a Hugging Face Space by EvanTHU](https://huggingface.co/spaces/EvanTHU/MotionCLR)

[SeedEdit-APP-V1.0 - a Hugging Face Space by ByteDance](https://huggingface.co/spaces/ByteDance/SeedEdit-APP)

[Framer - a Hugging Face Space by wwen1997](https://huggingface.co/spaces/wwen1997/Framer)

[BRIA RMBG 2.0 - a Hugging Face Space by briaai](https://huggingface.co/spaces/briaai/BRIA-RMBG-2.0)

[MinerU - a Hugging Face Space by opendatalab](https://huggingface.co/spaces/opendatalab/MinerU)

[Qwen Turbo 1M Demo - a Hugging Face Space by Qwen](https://huggingface.co/spaces/Qwen/Qwen2.5-Turbo-1M-Demo)

[DimensionX - a Hugging Face Space by fffiloni](https://huggingface.co/spaces/fffiloni/DimensionX)

[PhotoMaker V2 - a Hugging Face Space by TencentARC](https://huggingface.co/spaces/TencentARC/PhotoMaker-V2)

[OOTDiffusion - a Hugging Face Space by levihsu](https://huggingface.co/spaces/levihsu/OOTDiffusion)

[moondream2 - a Hugging Face Space by vikhyatk](https://huggingface.co/spaces/vikhyatk/moondream2)

## æ–‡æ¡£èµ„æ–™

[ä½¿ç”¨ diffusers è®­ç»ƒä½ è‡ªå·±çš„ ControlNet ğŸ§¨](https://huggingface.co/blog/zh/train-your-controlnet)

[Stable Diffusion QR Code 101](https://antfu.me/posts/ai-qrcode-101)

[E-Hentai/íƒœê·¸ - ë‚˜ë¬´ìœ„í‚¤](https://namu.wiki/w/E-Hentai/%ED%83%9C%EA%B7%B8)

[é­”å’’ç™¾ç§‘è¯å…¸](https://aitag.top/)

[So-VITS-SVC 4.1 æ•´åˆåŒ…å®Œå…¨æŒ‡å—](https://www.yuque.com/umoubuton/ueupp5)

[Stable Diffusion 3.5 Prompt Guide â€” Stability AI](https://stability.ai/learning-hub/stable-diffusion-3-5-prompt-guide)

[ä½¿ç”¨ ChatGPT è¿›è¡Œå†™ä½œçš„å­¦ç”ŸæŒ‡å— |å¼€æ”¾äººå·¥æ™ºèƒ½ --- A Studentâ€™s Guide to Writing with ChatGPT | OpenAI](https://openai.com/chatgpt/use-cases/student-writing-guide/)

[richards199999/Thinking-Claude: Let your Claude able to think](https://github.com/richards199999/Thinking-Claude)

[hesamsheikh/ml-retreat: Machine Learning Journal for Intermediate to Advanced Topics.](https://github.com/hesamsheikh/ml-retreat)

[Midjourney Documentation and User Guide](https://docs.midjourney.com/)

## å½’æ¡£(å¯ä»¥ä¸ç”¨çœ‹)

[Resources for GAN Artists](https://docs.google.com/document/d/18BrtW9RzI9rRAAYnmxES59HOxeC_QH1_BT7VDcP-32E/mobilebasic)

[Disco Diffusion Portrait Study (by @enviraldesign) - Google æ–‡æ¡£](https://docs.google.com/document/d/1Ff8s8CX3xGrVr6AJ94hcvQ_PYqJ_mDAXzT3NGb5_K1w/edit)

[alibaba/animate-anything: Fine-Grained Open Domain Image Animation with Motion Guidance](https://github.com/alibaba/animate-anything/)

[GitHub - prophesier/diff-svc: Singing Voice Conversion via diffusion model](https://github.com/prophesier/diff-SVC)

[TencentARC/GFPGAN: GFPGAN aims at developing Practical Algorithms for Real-world Face Restoration.](https://github.com/TencentARC/GFPGAN/tree/master)

[guide to installing disco v5+ locally on windows](https://gist.github.com/MSFTserver/a05f637f32302918dd893318a4d9f62b)

[clip_interrogator.ipynb - Colaboratory](https://colab.research.google.com/github/pharmapsychotic/clip-interrogator/blob/main/clip_interrogator.ipynb#scrollTo=Pf6qkFG6MPRj)

[A Travelerâ€™s Guide to the Latent Space](https://sweet-hall-e72.notion.site/A-Traveler-s-Guide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f)

[Coarâ€™s Disco Diffusion Guide](https://coar.notion.site/coar/Coar-s-Disco-Diffusion-Guide-3d86d652c15d4ca986325e808bde06aa)

[Disco Diffusion Illustrated Settings](https://mpaugam.notion.site/Disco-Diffusion-Illustrated-Settings-cd4badf06e08440c99d8a93d4cd39f51)

[Ai generative art tools](https://pharmapsychotic.com/tools.html)

[AIç»˜ç”»çš„å…³é”®è¯ï¼ˆç¾¤å‹ä»¬çš„ç”» ï¼‰](https://397987634.notion.site/AI-764e6a50fbf04327945a12a07ce9654f)

[Artist Studies by @remi_durant](https://remidurant.com/artists/#)

[CLIP Prompt Engineering for Generative Art - matthewmcateer.me](https://matthewmcateer.me/blog/clip-prompt-engineering/)

[æ•°æ®é›†-LAION-400-MILLION OPEN DATASET | LAION](https://laion.ai/blog/laion-400-open-dataset/)
