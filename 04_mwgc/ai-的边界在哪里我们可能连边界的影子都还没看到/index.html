<!DOCTYPE html>
<html lang="zh-cn">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.147.7">
    <meta name="generator" content="Relearn 5.2.1+tip">
    <meta name="description" content="">
    <meta name="author" content="吴明文">
    <title>AI的边界在哪里？我们可能连边界的影子都还没看到 - aiart.website</title>
    <link href="/04_mwgc/ai-%E7%9A%84%E8%BE%B9%E7%95%8C%E5%9C%A8%E5%93%AA%E9%87%8C%E6%88%91%E4%BB%AC%E5%8F%AF%E8%83%BD%E8%BF%9E%E8%BE%B9%E7%95%8C%E7%9A%84%E5%BD%B1%E5%AD%90%E9%83%BD%E8%BF%98%E6%B2%A1%E7%9C%8B%E5%88%B0/index.xml" rel="alternate" type="application/rss+xml" title="aiart.website"><link rel="icon" href="/favicon.png" type="image/png" />
    <!-- https://github.com/filamentgroup/loadCSS/blob/master/README.md#how-to-use -->
    <link href="/css/fontawesome-all.min.css?1759564411" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/css/fontawesome-all.min.css?1759564411" rel="stylesheet"></noscript>
    <link href="/css/featherlight.min.css?1759564411" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/css/featherlight.min.css?1759564411" rel="stylesheet"></noscript>
    <link href="/css/auto-complete.css?1759564411" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/css/auto-complete.css?1759564411" rel="stylesheet"></noscript>
    <link href="/css/perfect-scrollbar.min.css?1759564411" rel="stylesheet">
    <link href="/css/nucleus.css?1759564411" rel="stylesheet">
    <link href="/css/fonts.css?1759564411" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/css/fonts.css?1759564411" rel="stylesheet"></noscript>
    <link href="/css/theme.css?1759564411" rel="stylesheet">
    <link href="/css/theme-black.css?1759564411" rel="stylesheet" id="variant-style">
    <link href="/css/ie.css?1759564411" rel="stylesheet">
    <link href="/css/variant.css?1759564411" rel="stylesheet">
    <link href="/css/print.css?1759564411" rel="stylesheet" media="print">
    <script src="/js/variant.js?1759564411"></script>
    <script>
      // hack to let hugo tell us how to get to the root when using relativeURLs, it needs to be called *url= for it to do its magic:
      // https://github.com/gohugoio/hugo/blob/145b3fcce35fbac25c7033c91c1b7ae6d1179da8/transform/urlreplacers/absurlreplacer.go#L72
      var index_url="/index.json";
      var root_url="/";
      var baseUri=root_url.replace(/\/$/, '');
      // translations
      window.T_Copy_to_clipboard = '复制到剪贴板';
      window.T_Copied_to_clipboard = '复制到剪贴板！';
      window.T_Copy_link_to_clipboard = '将链接复制到剪贴板';
      window.T_Link_copied_to_clipboard = '链接复制到剪贴板！';
      // some further base stuff
      var baseUriFull='/';
      window.variants && variants.init( [ 'black' ] );
    </script>
    <script src="/js/jquery.min.js?1759564411" defer></script>
  </head>
  <body class="mobile-support html" data-url="/04_mwgc/ai-%E7%9A%84%E8%BE%B9%E7%95%8C%E5%9C%A8%E5%93%AA%E9%87%8C%E6%88%91%E4%BB%AC%E5%8F%AF%E8%83%BD%E8%BF%9E%E8%BE%B9%E7%95%8C%E7%9A%84%E5%BD%B1%E5%AD%90%E9%83%BD%E8%BF%98%E6%B2%A1%E7%9C%8B%E5%88%B0/">
    <div id="body" class="default-animation">
      <div id="sidebar-overlay"></div>
      <div id="toc-overlay"></div>
      <nav id="topbar" class="highlightable">
        <div>
          <div id="breadcrumbs">
            <span id="sidebar-toggle-span">
              <a href="#" id="sidebar-toggle" title='导航 (CTRL+ALT+m)'><i class="fas fa-bars fa-fw"></i></a>
            </span>
            <span id="toc-menu" title='目录 (CTRL+ALT+t)'><i class="fas fa-list-alt fa-fw"></i></span>
            <ol class="links" itemscope itemtype="http://schema.org/BreadcrumbList">
              <meta itemprop="itemListOrder" content="Descending" />
              <li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><meta itemprop="position" content="3" /><a itemprop="item" href="/"><span itemprop="name">aiart.website</span></a> > </li>
              <li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><meta itemprop="position" content="2" /><a itemprop="item" href="/04_mwgc/"><span itemprop="name">《明文AI观察》</span></a> > </li>
              <li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement"><meta itemprop="position" content="1" /><a itemprop="item" href="/04_mwgc/ai-%E7%9A%84%E8%BE%B9%E7%95%8C%E5%9C%A8%E5%93%AA%E9%87%8C%E6%88%91%E4%BB%AC%E5%8F%AF%E8%83%BD%E8%BF%9E%E8%BE%B9%E7%95%8C%E7%9A%84%E5%BD%B1%E5%AD%90%E9%83%BD%E8%BF%98%E6%B2%A1%E7%9C%8B%E5%88%B0/" aria-disabled="true"><span itemprop="name">AI的边界在哪里？我们可能连边界的影子都还没看到</span></a></li>
            </ol>
          </div>
          <div class="default-animation progress">
            <div class="wrapper">
<nav id="TableOfContents">
  <ul>
    <li><a href="#芯片只是冰山一角">芯片只是冰山一角</a></li>
    <li><a href="#芯片战还能怎么打">芯片战还能怎么打</a></li>
    <li><a href="#传输和存储的隐形战争">传输和存储的隐形战争</a></li>
    <li><a href="#电力和散热的极限挑战">电力和散热的极限挑战</a></li>
    <li><a href="#算力的未来在哪">算力的未来在哪</a></li>
  </ul>

  <ul>
    <li><a href="#什么叫高质量数据">什么叫高质量数据</a></li>
    <li><a href="#合成数据的机会和陷阱">合成数据的机会和陷阱</a></li>
    <li><a href="#多模态数据的新战场">多模态数据的新战场</a></li>
    <li><a href="#私有数据和数据飞轮">私有数据和数据飞轮</a></li>
    <li><a href="#ai正在创造新数据">AI正在创造新数据</a></li>
    <li><a href="#数据的边界在哪里">数据的边界在哪里</a></li>
  </ul>

  <ul>
    <li><a href="#transformer的三大硬伤">Transformer的三大硬伤</a></li>
    <li><a href="#架构创新在哪里">架构创新在哪里</a></li>
    <li><a href="#神经符号融合的可能">神经符号融合的可能</a></li>
    <li><a href="#架构搜索和元学习">架构搜索和元学习</a></li>
    <li><a href="#智能体架构的新天地">智能体架构的新天地</a></li>
    <li><a href="#底层创新的长期价值">底层创新的长期价值</a></li>
    <li><a href="#算法边界还远没到">算法边界还远没到</a></li>
  </ul>

  <ul>
    <li><a href="#训练系统的隐形战争">训练系统的隐形战争</a></li>
    <li><a href="#推理系统的性能博弈">推理系统的性能博弈</a></li>
    <li><a href="#数据处理的精细活">数据处理的精细活</a></li>
    <li><a href="#工程债务的隐形成本">工程债务的隐形成本</a></li>
    <li><a href="#系统能力的护城河">系统能力的护城河</a></li>
    <li><a href="#工程的边界在哪里">工程的边界在哪里</a></li>
  </ul>

  <ul>
    <li><a href="#四个维度的同步突破">四个维度的同步突破</a></li>
    <li><a href="#ai加速ai的临界点">AI加速AI的临界点</a></li>
    <li><a href="#架构革命的可能性">架构革命的可能性</a></li>
    <li><a href="#应用爆发的连锁反应">应用爆发的连锁反应</a></li>
    <li><a href="#不变的是什么">不变的是什么</a></li>
    <li><a href="#边界还远着呢">边界还远着呢</a></li>
  </ul>
</nav>
            </div>
          </div>
        </div>
      </nav>
      <main id="body-inner" class="highlightable default" tabindex="-1">
        <div class="flex-block-wrapper">
          <div id="head-tags">
          </div>
          <article class="default">
<h1>AI的边界在哪里？我们可能连边界的影子都还没看到</h1>

<p>问AI的边界在哪里，我们来看看限制AI发展的四大支柱有边界吗？</p>
<p><strong>第一个边界，算力</strong>。</p>
<p><strong>第二个边界，数据</strong>。</p>
<p><strong>第三个边界，算法与模型架构</strong>。</p>
<p><strong>第四个边界，工程与系统能力</strong>。</p>
<h1 id="ai算力竞赛一场关于电力散热和钞能力的极限游戏">AI算力竞赛：一场关于电力、散热和钞能力的极限游戏</h1>
<p>2023年，OpenAI训练GPT-4花了多少钱？外界估算在1亿美元左右。这个数字里，芯片采购只是一部分，更大的开销是电费、散热、网络传输、存储这些看起来不性感的基础设施。</p>
<p>算力正在成为AI时代的石油。但和石油不同的是，算力的边界还远没有到来，它的提升空间大得惊人。</p>
<h2 id="芯片只是冰山一角">芯片只是冰山一角</h2>
<p>大家都知道英伟达H100很贵，一张卡4万美元起步。但真正让人头疼的不是买卡，而是把这些卡攒起来稳定运行。</p>
<p>一个标准的AI训练集群需要上万张GPU。这些卡不是简单地插在服务器里就能工作，它们之间需要高速互联，数据传输速度直接决定训练效率。英伟达的NVLink、InfiniBand这些互联技术，成本不比GPU本身低多少。</p>
<p>更要命的是功耗。一张H100满载功耗700瓦，一万张就是7兆瓦。这是什么概念？够一个小城市用的。Meta在2024年透露，他们的AI基础设施电费开销已经超过了硬件采购成本。</p>
<p>电力问题不只是钱的问题，还有供应问题。你想建个大型AI数据中心，得先确认当地电网能不能供得上。微软、谷歌这些公司为了AI算力，已经开始和电力公司签长期供电协议，有的甚至直接投资建电厂。</p>
<p>散热更是个硬骨头。传统的风冷散热在高密度GPU集群面前基本废了。一个机柜里塞几十张GPU，热量密度高到风扇根本吹不动。液冷技术为什么火了？因为风扇已经吹不凉AI那颗滚烫的心了。</p>
<p>但液冷也不是万能的。它需要专门的冷却液循环系统，管道设计，温度监控，维护成本比风冷高几倍。有些公司直接把数据中心建在北极圈附近，就是为了省散热成本。</p>
<p>存储和网络传输也在拖后腿。AI训练需要海量数据反复读取，存储系统的IO性能如果跟不上，GPU就得空转等数据。这就像你花大价钱买了辆超跑，结果只能在乡间小路上跑，憋屈。</p>
<p>高速存储设备价格不菲，而且还得考虑可靠性。训练一个大模型动辄几个月，中途要是存储挂了，前面的工作可能就白费了。所以很多公司会做多重备份，这又是一笔开销。</p>
<p>网络带宽也是瓶颈。模型参数越来越大，动辄几千亿参数，这些数据在不同节点之间传输，对带宽要求极高。普通的以太网已经不够用，得上专门的高速网络。</p>
<p>算力的成本结构正在发生变化。以前大家觉得芯片最贵，现在发现，芯片只是入场券，真正烧钱的是把这套系统跑起来。</p>
<h2 id="芯片战还能怎么打">芯片战还能怎么打</h2>
<p>英伟达现在是AI芯片的霸主，但这个格局不会永远持续。</p>
<p>首先是制程工艺还在进步。台积电的3纳米工艺已经量产，2纳米在路上。制程越先进，同样面积的芯片能塞进更多晶体管，性能就越强，功耗还能降低。但问题是，制程每往前走一步，难度和成本都在指数级增长。</p>
<p>光刻机的极限在哪？现在用的极紫外光（EUV）波长13.5纳米，理论上可以做到1纳米制程。但再往下走，可能就得换技术路线了。有人在研究用电子束代替光刻，也有人在搞原子级制造。这些技术还在实验室阶段，离量产还远。</p>
<p>除了制程，芯片架构也在演进。英伟达的GPU架构专门为并行计算优化，训练大模型效率高。但推理场景不一样，不需要那么多并行能力，更看重单次计算的速度和能效。</p>
<p>这就给了其他玩家机会。谷歌的TPU专门为Transformer架构优化，推理性能比GPU强。特斯拉的Dojo芯片专门为视频数据训练设计。苹果、亚马逊、微软都在自研AI芯片，目标是针对自己的业务场景做深度优化。</p>
<p>中国公司也在快速追赶。华为的昇腾、寒武纪的思元、壁仞科技的BR100，性能都在快速提升。虽然和英伟达还有差距，但差距在缩小。</p>
<p>更激进的技术路线也在探索。模拟计算芯片用电压电流直接做计算，理论上能效比数字芯片高几个数量级。光子芯片用光代替电，速度更快，功耗更低。但这些技术都还不成熟，工程化难度很大。</p>
<p>量子芯片是另一个方向。量子计算机擅长某些特定类型的计算，比如优化问题、模拟量子系统。如果能和经典AI算法结合，可能会有突破。但量子计算机现在还处于早期阶段，稳定性、纠错都是大问题。</p>
<p>芯片战的另一个战场是内存。GPU的显存容量直接决定了能训练多大的模型。现在顶级的GPU显存80GB，已经很大了，但对于万亿参数的模型还是不够。怎么办？</p>
<p>一个办法是用更先进的内存技术。HBM（高带宽内存）比传统GDDR内存带宽高几倍，但贵得多。三星、SK海力士在这个领域投入巨大。</p>
<p>另一个办法是分布式训练，把模型拆到多个GPU上。但这会引入通信开销，需要更复杂的并行策略。</p>
<p>还有人在研究存算一体芯片，把计算和存储集成在一起，减少数据搬运。这个方向很有前景，但技术难度也很大。</p>
<p>芯片领域的竞争才刚刚开始。英伟达的优势在于生态，CUDA编程框架、各种优化库，开发者用得顺手。但这个生态不是不可撼动的。如果有新的架构能带来10倍性能提升，开发者是愿意学习新工具的。</p>
<h2 id="传输和存储的隐形战争">传输和存储的隐形战争</h2>
<p>算力强不强，很大程度上取决于数据能不能喂得上。</p>
<p>AI训练就像一条流水线，GPU是工人，数据是原材料。工人干活再快，原材料供不上也白搭。</p>
<p>数据传输的瓶颈在两个地方：一是存储到GPU的路径，二是GPU之间的通信。</p>
<p>从存储到GPU，要经过CPU、内存、PCIe总线、GPU显存。每一环都可能成为瓶颈。PCIe 4.0带宽64GB/s，听起来不少，但对于高速GPU来说还是慢。PCIe 5.0翻倍到128GB/s，但普及还需要时间。</p>
<p>更激进的方案是绕过CPU，让存储直接和GPU通信。英伟达的GPUDirect技术就是干这个的。但这需要硬件和软件的深度配合，不是随便哪个系统都能用。</p>
<p>存储本身也在进化。机械硬盘早就不够用了，现在都是固态硬盘。但普通的SATA固态硬盘还是慢，得用NVMe。顶级的NVMe固态硬盘读写速度能到7GB/s，但价格也是机械硬盘的10倍以上。</p>
<p>对于超大规模训练，单机存储不够，得用分布式存储。这又引入了网络传输的问题。如果网络慢，分布式存储的优势就发挥不出来。</p>
<p>GPU之间的通信更关键。训练大模型时，每个GPU都只处理一部分数据或模型，它们之间需要频繁交换中间结果。这个通信量是巨大的。</p>
<p>英伟达的NVLink就是专门解决这个问题的。NVLink 4.0的双向带宽达到900GB/s，比PCIe快得多。但NVLink只能连接少数几个GPU，要连接成千上万个GPU，还得靠InfiniBand或者以太网。</p>
<p>InfiniBand是目前高性能计算领域的主流，带宽高、延迟低。但贵，而且生态相对封闭。以太网便宜，生态好，但传统以太网的性能不够。所以现在有了RDMA（远程直接内存访问）技术，让以太网也能达到接近InfiniBand的性能。</p>
<p>网络拓扑结构也很重要。怎么把这些GPU连起来，用什么样的交换机，决定了通信效率。常见的有Fat-Tree、Dragonfly等拓扑结构，各有优缺点。</p>
<p>Meta在2024年公布了他们的Grand Teton AI集群，用了定制的网络架构，通信效率比传统方案提升了30%。这种工程优化能力，不是有钱就能做到的，需要大量的技术积累。</p>
<p>存储和传输看起来不性感，但它们是算力的血管和神经。血管堵了，神经传导慢了，再强的大脑也发挥不出来。</p>
<h2 id="电力和散热的极限挑战">电力和散热的极限挑战</h2>
<p>AI数据中心正在成为电老虎。</p>
<p>一个标准的AI训练集群，功耗轻松上兆瓦。一个普通家庭用电1-2千瓦，一个AI集群的功耗相当于几千个家庭。</p>
<p>电从哪来？很多地方的电网容量有限，你想用这么多电，电力公司不一定供得上。</p>
<p>所以大厂开始自己想办法。微软在2024年宣布，他们正在开发小型核反应堆，专门为数据中心供电。听起来科幻，但技术上是可行的。小型模块化反应堆（SMR）功率几十到几百兆瓦，正好适合大型数据中心。</p>
<p>谷歌的办法是买绿电。他们和太阳能、风能公司签长期协议，确保数据中心用的是清洁能源。但可再生能源有个问题，不稳定。没太阳没风的时候怎么办？还是得靠电网或者储能系统。</p>
<p>储能系统又是一笔投资。特斯拉的Megapack电池系统，一个单元3兆瓦时，能支撑数据中心短时间运行。但电池成本高，而且有寿命限制。</p>
<p>有些公司想了更激进的办法。把数据中心建在水电站旁边，直接用水电。或者建在地热资源丰富的地方，用地热发电。冰岛就因为电费便宜、气候寒冷，成了AI数据中心的热门地点。</p>
<p>电力问题解决了，散热问题又来了。</p>
<p>传统数据中心用空调散热，但AI集群的热量密度太高，空调已经不够用。一个机柜功率几十千瓦，空调根本压不住。</p>
<p>液冷技术是现在的主流方案。冷却液直接接触芯片或者热管，带走热量。效率比风冷高几倍，而且噪音小。但液冷系统复杂，需要专门的设计和维护。</p>
<p>液冷又分几种。浸没式液冷把整个服务器泡在冷却液里，散热效果最好，但维护麻烦，而且不是所有硬件都能泡。冷板式液冷用液冷板贴在芯片上，兼容性好，但效率稍差。</p>
<p>还有更激进的，两相液冷。利用液体蒸发吸热，效率更高。但控制难度大，成本也高。</p>
<p>散热不只是技术问题，还是地理问题。在热带建数据中心，散热成本高得吓人。所以很多公司把数据中心建在高纬度地区，利用自然冷却。</p>
<p>Facebook在瑞典建了个数据中心，大部分时间用外面的冷空气散热，省了一大笔电费。微软更狠，他们试验过把数据中心沉到海底，用海水散热。</p>
<p>散热的副产品是热量。一个大型AI数据中心产生的热量，够给一个小城市供暖了。有些地方开始考虑热能回收，把数据中心的废热用来供暖或者发电。但这需要额外的基础设施，不是哪都能做。</p>
<p>电力和散热看起来是工程问题，但本质上是经济问题。你得算账，用最经济的方式获得足够的算力。这个账不是简单的加减法，涉及到地理、气候、能源政策、电价、土地成本一大堆因素。</p>
<h2 id="算力的未来在哪">算力的未来在哪</h2>
<p>算力的边界还远没有到来。从各个维度看，都有巨大的提升空间。</p>
<p>芯片制程还能进步。3纳米之后是2纳米、1纳米。再往后，可能是新材料新技术。硅基芯片的物理极限确实存在，但我们离那个极限还有距离。</p>
<p>芯片架构创新更有想象空间。现在的GPU架构已经很成熟，但不代表不能更好。专用芯片针对特定任务优化，性能可以提升几倍甚至几十倍。</p>
<p>量子计算虽然还在早期，但潜力巨大。一旦实现稳定可控，某些类型的计算能力会有质的飞跃。混合计算系统，经典计算和量子计算配合，可能是未来的方向。</p>
<p>光子芯片、神经形态芯片这些新技术路线，虽然现在还不成熟，但都在快速发展。十年后，我们可能会看到完全不同的计算架构。</p>
<p>传输和存储技术也在进步。PCIe 6.0、DDR6、更快的网络技术都在路上。存算一体、近存储计算这些新架构，可以大幅降低数据搬运的开销。</p>
<p>电力问题会倒逼能源技术创新。核聚变如果实现商业化，能源成本会大幅下降。太阳能、风能的效率还在提升，储能技术也在进步。</p>
<p>散热技术也不会停滞。更高效的液冷系统、相变材料、甚至低温超导，都可能成为未来的选择。</p>
<p>更重要的是，AI本身正在加速这些技术的进步。</p>
<p>摩尔定律可能会失效，但算力增长不会停止。它会换一种方式继续。</p>
<p>十年前，没人想到AI能画画、写文章、写代码。再过十年，AI能做什么？没人知道。但可以确定的是，那时候的算力会比现在强得多。</p>
<p>算力是AI的地基。地基越牢，楼能盖得越高。现在这个地基还在加固，还在扩展，远没有到天花板。</p>
<p>所以，当有人问AI的边界在哪里，算力这个维度的答案是：边界还远着呢。</p>
<h1 id="数据荒当ai把互联网吃干抹净之后">数据荒：当AI把互联网吃干抹净之后</h1>
<p>Meta的首席AI科学家Yann LeCun在2024年说了句话：我们已经把互联网上的高质量文本数据用完了。</p>
<p>这不是危言耸听。GPT-3用了45TB文本数据，GPT-4更多。Llama系列、Claude、Gemini，这些大模型都在疯狂吞噬数据。维基百科、书籍、新闻、论文、代码仓库、问答网站，凡是能找到的高质量文本，基本都被爬了个遍。</p>
<h2 id="什么叫高质量数据">什么叫高质量数据</h2>
<p>AI训练不是什么数据都行。垃圾进垃圾出，这个道理在AI领域格外明显。</p>
<p>高质量数据得有几个特征。首先是准确性。错误的信息会教坏模型，让它一本正经地胡说八道。</p>
<p>其次是多样性。如果训练数据都是某一类内容，模型就会有偏见。比如只用英文训练，模型处理其他语言就会很差。只用新闻训练，模型写小说就不行。</p>
<p>再次是结构化程度。对话数据、问答数据、带标注的数据，这些结构化数据对训练有监督学习模型特别重要。但这类数据比纯文本稀缺得多。</p>
<p>还有就是新鲜度。互联网上的内容每天都在更新，但爬虫不可能实时抓取所有数据。模型的知识截止日期，就是因为训练数据的时效性限制。</p>
<p>大量高质量内容藏在付费墙后面，或者有严格的版权保护。纽约时报起诉OpenAI侵权，就是因为GPT被发现能复述时报的付费文章。</p>
<p>现在的情况是什么？Common Crawl这个公开数据集，包含了几十亿个网页。听起来很多，但经过去重、过滤低质量内容、去除违规信息，能用的数据大幅缩水。</p>
<p>而且互联网上的内容质量本来就参差不齐。大量的垃圾信息、重复内容、自动生成的SEO文章，这些东西不仅没用，还会污染数据集。</p>
<p>有人统计过，互联网上真正有价值的文本内容，可能不到总量的10%。而这10%，已经被各大AI公司扒了个底朝天。</p>
<p>书籍是高质量数据的重要来源。但出版物有版权保护，不能随便用。Google Books项目因为版权问题打了十几年官司。现在一些AI公司和出版商合作，获得授权使用书籍数据，但这需要真金白银。</p>
<p>学术论文质量高，但专业性强，覆盖面有限。而且很多论文藏在付费数据库里，不对外开放。</p>
<p>代码数据是另一个战场。GitHub上有几亿个代码仓库，但大部分是重复的、低质量的、或者根本跑不通的。真正优质的开源项目，就那么多。</p>
<p>社交媒体数据量大，但质量堪忧，充斥着情绪化发言、网络梗、错误信息。用这些数据训练模型，得小心模型学坏了。</p>
<p>视频和音频数据更复杂。YouTube上有海量视频，但要把视频转成有用的训练数据，需要转录、标注、理解上下文。这个成本非常高。</p>
<p>图像数据看起来充足，但要训练好的图像模型，需要高质量的图像和准确的描述标注。ImageNet数据集花了几年时间，动用了大量人工标注才完成。</p>
<p>总之，可用的高质量数据正在接近枯竭。这不是危言耸听，是各大AI公司都在面对的现实问题。</p>
<h2 id="合成数据的机会和陷阱">合成数据的机会和陷阱</h2>
<p>既然真实数据不够，那用AI生成数据行不行？</p>
<p>这个思路听起来很聪明。让强模型生成数据，训练弱模型。或者让模型生成自己不擅长的数据，补齐短板。</p>
<p>OpenAI就这么干过。他们用GPT-4生成大量高质量的对话数据，用来训练后续版本。效果确实不错，模型的对话能力明显提升。</p>
<p>代码生成也是个好场景。让模型写代码，然后检查代码能不能跑通。能跑通的留下，跑不通的丢掉。这样可以批量生成高质量代码数据。</p>
<p>数学题也可以合成。让模型出题，然后验证答案。这样可以生成无限多的数学训练数据。</p>
<p>但合成数据有个致命问题：模型坍塌。</p>
<p>什么意思？如果模型只用合成数据训练，它会逐渐失去对真实世界的理解。就像近亲繁殖一样，几代之后就会出问题。</p>
<p>牛津大学的研究发现，如果持续用AI生成的数据训练AI，模型的多样性会快速下降，最后输出的内容会趋同化、模式化。</p>
<p>这个问题的根源在于，AI生成的数据本质上是对训练数据的某种变换和重组。它不会创造真正新的信息，只是在已有信息空间里做插值。</p>
<p>久而久之，模型会陷入一个信息闭环。它看到的都是自己或者同类模型生成的内容，逐渐忘记真实世界是什么样的，走进了自己的“信息茧房”。</p>
<p>互联网上AI生成的内容正在快速增长。有估算说，到2026年，互联网上超过一半的内容会是AI生成的。未来的AI模型训练数据，会不可避免地包含大量AI生成内容。</p>
<p>有人提出用水印或者标记来区分AI生成内容，但这不现实。内容生成者不会主动标记，检测技术也不够准确。</p>
<p>另一个办法是用2023年之前的数据，那时候AI生成内容还很少。但这样模型的知识就会停留在过去，无法学习新的信息。</p>
<p>AI污染了互联网，互联网又污染了AI的训练数据。合成数据不是不能用，但必须谨慎。</p>
<p>AI也同样增强了人们的创造力，今后越来越多的大量的高质量数据将是AI和人类共同产生，甚至AI自主产生。</p>
<p>有些公司在探索更聪明的合成数据方法。比如用物理仿真生成数据。训练机器人控制模型，可以在模拟环境里生成大量数据，而不依赖真实世界的标注。</p>
<p>医疗影像领域也在用生成对抗网络（GAN）合成病例数据。真实的病例数据因为隐私问题很难获取，合成数据可以缓解这个问题。</p>
<p>但这些方法都有适用边界。物理仿真只能用于有清晰物理规律的场景。医疗数据合成需要专业知识验证。不是所有领域都有这样的捷径。</p>
<h2 id="多模态数据的新战场">多模态数据的新战场</h2>
<p>文本数据快用完了，但其他类型的数据还有空间。</p>
<p>视频是个巨大的数据金矿。YouTube每分钟上传500小时视频，这些视频里包含了大量的视觉信息、动作、场景理解。</p>
<p>但视频数据的利用难度大。首先得转录语音，然后理解画面内容，最后把这些信息整合起来。这需要多模态理解能力。</p>
<p>Sora的成功，很大程度上因为OpenAI搞定了大规模视频数据的利用。他们用了一套复杂的pipeline，从视频中提取时空信息，训练出了强大的视频生成模型。</p>
<p>音频数据也被忽视了很久。播客、音乐、自然声音，这些数据里包含的信息密度不比文本低。</p>
<p>传感器数据是另一个方向。自动驾驶产生的雷达、摄像头数据，工业设备的监测数据，这些数据的量级是文本数据的几百倍。</p>
<p>但这些数据都有个问题：标注成本高。</p>
<p>文本数据可以无监督学习，让模型自己学语言模式。但视频、音频、传感器数据，很多时候需要人工标注才能用。</p>
<p>一个自动驾驶场景的视频，要标注出每一帧里的车辆、行人、交通标志。一段医疗影像，要专业医生标注病灶位置。这些工作耗时耗力，成本极高。</p>
<p>有些公司想了些巧妙的办法。比如用弱监督学习，只标注关键帧，让模型自己学习插值。或者用主动学习，让模型挑出最有价值的数据给人标注。</p>
<p>但这些方法都不能彻底解决问题。标注瓶颈会一直存在，除非AI自己能完成高质量标注。而那需要AI更强，这又是个鸡生蛋蛋生鸡的问题。</p>
<p>多模态数据的融合也是个挑战。文本、图像、音频、视频，这些数据的特性完全不同。怎么把它们统一到一个模型里？</p>
<p>现在的多模态模型，基本上是把不同模态的数据映射到同一个特征空间。但这个映射是不是最优的？信息有没有损失？还有很多研究空间。</p>
<p>有人提出世界模型的概念。让AI从多模态数据中学习物理世界的运行规律，建立对世界的统一理解。这个方向很诱人，但难度极大。</p>
<h2 id="私有数据和数据飞轮">私有数据和数据飞轮</h2>
<p>公开数据快用完了，私有数据成了新战场。</p>
<p>各大公司手里都攒着海量私有数据。谷歌有搜索记录、Gmail、YouTube。Meta有社交网络数据。亚马逊有购物数据。这些数据的价值难以估量。</p>
<p>但私有数据有个问题：用户隐私。不经用户同意就用他们的数据训练AI，法律风险很大。欧盟的GDPR、加州的CCPA，都对数据使用有严格限制。</p>
<p>所以公司们在搞隐私计算技术。联邦学习让数据不出本地就能训练模型。差分隐私在数据里加噪声，保护个人信息不泄露。</p>
<p>但这些技术都会损失一些精度。隐私和性能之间的权衡，是个永恒的难题。</p>
<p>还有个思路是让用户主动贡献数据。OpenAI的ChatGPT对话数据，很多是用户主动分享的。只要设计好激励机制，用户是愿意贡献数据的。</p>
<p>特斯拉的自动驾驶数据就是这么来的。几百万辆特斯拉在路上跑，每天产生海量的驾驶数据。这些数据回传到特斯拉，用于训练自动驾驶模型。</p>
<p>这就是数据飞轮。产品产生数据，数据训练模型，模型改进产品，产品吸引更多用户，产生更多数据。</p>
<p>谁先建立起数据飞轮，谁就有了巨大的竞争优势。因为后来者很难追上，数据的积累是需要时间的。</p>
<p>这也是为什么所有大厂都在拼命做应用。不是为了短期赚钱，而是为了积累数据。</p>
<p>但数据飞轮也有局限。它只能产生特定领域的数据。特斯拉的驾驶数据再多，也帮不了医疗AI。</p>
<p>而且数据飞轮有赢家通吃的倾向。先发优势太大，后来者很难突破。这对整个行业的健康发展不是好事。</p>
<p>有人提出数据共享和数据市场的概念。让不同公司之间交换数据，或者让用户出售自己的数据。但实际操作起来困难重重，涉及到定价、隐私、信任等一系列问题。</p>
<h2 id="ai正在创造新数据">AI正在创造新数据</h2>
<p>最有意思的是，AI本身正在成为数据的来源。</p>
<p>AlphaGo的自我对弈，就是个典型例子。它不需要人类棋谱，自己和自己下，生成训练数据。最后达到了超越人类的水平。</p>
<p>这个思路在很多领域都适用。只要有明确的评价标准，就可以让AI自己探索，生成数据。</p>
<p>代码领域就是这样。让AI写代码，然后运行测试用例。通过测试的代码就是好数据，没通过的就丢掉。通过这种方式，AI可以自己生成大量高质量代码数据。</p>
<p>数学证明也可以。让AI尝试证明定理，用形式化验证工具检查证明是否正确。这样可以生成大量的数学推理数据。</p>
<p>科学实验也在被AI加速。AI设计实验，机器人执行实验，自动记录数据。这个循环比人类科学家快得多。</p>
<p>DeepMind的AlphaFold就是个例子。它预测蛋白质结构，然后用实验验证。验证过的结果又成为新的训练数据。现在AlphaFold已经预测了几乎所有已知蛋白质的结构。</p>
<p>材料科学、药物研发、化学合成，这些领域的AI都在用类似的方法。它们产生的不只是模型，还有海量的高质量科学数据。</p>
<p>这些数据的价值可能超过互联网上的所有文本。因为它们是全新的知识，是人类从未掌握的信息。</p>
<p>更激进的想法是，让AI创造虚拟世界，在虚拟世界里生成数据。就像游戏引擎生成游戏场景一样，AI可以生成各种各样的场景、对话、任务。</p>
<p>OpenAI的GPT-4据说用了这种方法。他们让模型生成虚拟的教学场景，一个AI扮演老师，一个AI扮演学生，通过这种方式生成大量的教育数据。</p>
<p>这个方向的潜力是无限的。只要AI足够强，它可以创造出比现实世界更丰富的数据。</p>
<p>但问题还是那个：这些数据会不会导致模型坍塌？会不会让AI脱离现实？</p>
<p>现在还没有明确的答案。但可以确定的是，这个方向值得探索。</p>
<h2 id="数据的边界在哪里">数据的边界在哪里</h2>
<p>回到最初的问题：数据还有巨大提升空间吗？</p>
<p>答案是肯定的，但提升的方式和我们想象的不一样。</p>
<p>互联网上的文本数据确实快用完了。但这不意味着数据枯竭了。</p>
<p>多模态数据还有巨大的开发空间。视频、音频、传感器数据，这些数据的信息密度远高于文本。</p>
<p>私有数据和用户贡献数据，随着隐私技术的进步，会逐渐释放出来。</p>
<p>最重要的是，AI自己正在成为数据的生产者。它不仅能生成文本、图像、视频，还能通过科学实验、形式化验证，生成全新的知识。</p>
<p>这些新知识不是对现有数据的复制，而是真正的创新。它们扩展了人类的知识边界。</p>
<p>数据的瓶颈会一直存在，但瓶颈会不断被突破。每一次突破，都会带来AI能力的跃升。</p>
<p>十年前，ImageNet是最大的图像数据集，一百万张图片就算海量。现在Stable Diffusion的训练数据是几十亿张图。</p>
<p>再过十年，我们会用什么样的数据？可能是完全不同形式的数据。可能是AI自己生成的、经过验证的、高质量的科学知识。</p>
<p>数据的边界不在数量，在质量和形式。互联网可能被吃干抹净了，但知识的海洋才刚刚开始探索。</p>
<p>所以，当有人担心数据不够用了，真正应该问的问题是：我们怎么利用AI来创造更多、更好的数据？</p>
<p>答案就藏在AI自己身上。它既是数据的消费者，也将成为数据的生产者。这个循环一旦启动，数据的增长速度会超过我们的想象。</p>
<p>数据的边界，还远着呢。</p>
<h1 id="transformer统治五年后ai的智力天花板在哪里">Transformer统治五年后，AI的智力天花板在哪里</h1>
<p>2017年，谷歌发表了那篇改变AI历史的论文：Attention is All You Need。Transformer架构横空出世。</p>
<p>五年后，GPT-3震撼世界。再一年，ChatGPT引爆全球。这些奇迹的背后，都是同一个架构：Transformer。</p>
<p>现在几乎所有的大语言模型，都基于Transformer。图像生成模型Stable Diffusion，视频生成模型Sora，底层也是Transformer的变体。</p>
<p>Transformer就像AI界的x86架构，统治了整个行业。</p>
<p>但一个架构被用到极致，它的缺陷也会暴露无遗。Transformer不是完美的，它有先天性缺陷。而这些缺陷，就是AI的下一道边界。</p>
<h2 id="transformer的三大硬伤">Transformer的三大硬伤</h2>
<p>第一个问题，计算复杂度是平方级的。</p>
<p>Transformer的核心是自注意力机制。简单说，就是让模型在处理每个词的时候，都要看一遍所有其他词，计算它们之间的关系。</p>
<p>这个机制很强大，因为它能捕捉长距离依赖。一句话前面的内容，可以影响后面的理解。这是Transformer比之前的RNN、LSTM强的关键原因。</p>
<p>但代价是什么？如果输入长度是n，计算量就是n的平方。输入长度翻倍，计算量翻四倍。</p>
<p>这意味着处理长文本非常昂贵。GPT-4的上下文窗口是128k tokens，听起来很长。但你要知道，处理这么长的输入，计算量是处理4k输入的1000倍以上。</p>
<p>所以大部分时候，大模型的上下文窗口都用不满。不是不想用，是用不起。</p>
<p>有人提出了各种优化方法。稀疏注意力、局部注意力、线性注意力，试图把平方复杂度降下来。但这些方法都是有损的，要么牺牲精度，要么适用场景有限。</p>
<p>第二个问题，Transformer是个金鱼，只有七秒记忆。</p>
<p>虽然上下文窗口可以很长，但Transformer本质上是无状态的。它没有真正的记忆机制。</p>
<p>什么意思？每次推理，模型都要重新读一遍整个上下文。它不会记住之前的对话，不会积累经验。给它一万轮对话，它还是从零开始处理。</p>
<p>当然，你可以把历史对话塞进上下文。但这又回到了第一个问题，计算量爆炸。而且上下文窗口总有上限，你不可能把所有历史都塞进去。</p>
<p>人类不是这样工作的。我们有短期记忆和长期记忆。重要的事情会存下来，不重要的会忘掉。这是一个动态的过程。</p>
<p>Transformer没有这个机制。它要么记住一切，要么忘掉一切。这种all or nothing的方式，限制了它的长期推理能力。</p>
<p>第三个问题，它缺乏真正的逻辑推理能力。</p>
<p>Transformer本质上是个模式匹配器。它从海量数据里学会了各种模式，然后在新的输入上套这些模式。</p>
<p>这个方法在大部分时候很有效。语言本身就充满了模式，Transformer很擅长学习这些模式。</p>
<p>但逻辑推理不是模式匹配。推理需要符号操作、规则应用、步骤串联。这些能力Transformer有一些，但不够强。</p>
<p>你让GPT-4做复杂的数学题，它经常会出错，因为推理链一长，它就容易走偏。</p>
<p>DeepSeek R1模型出来，专门强化推理能力。怎么做的？让模型在回答之前，先在内部做一大堆思考，写出推理步骤。这样确实提升了推理能力。</p>
<p>但这是个权宜之计，不是根本解决方案。它相当于用更多的计算和更长的上下文，来弥补架构上的不足。</p>
<p>这三个问题不是小毛病，是结构性缺陷。它们限制了Transformer能走多远。</p>
<h2 id="架构创新在哪里">架构创新在哪里</h2>
<p>业界不是没有尝试突破。各种新架构层出不穷。</p>
<p>State Space Models（SSM）是个热门方向。它的计算复杂度是线性的，不是平方级。而且它有真正的状态，可以记住历史信息。</p>
<p>Mamba是SSM的一个实现，在某些任务上的效果接近Transformer，但速度快得多。处理长序列的时候，优势更明显。</p>
<p>问题是，SSM在语言理解任务上还不如Transformer。它擅长处理连续信号，比如音频、时间序列，但处理离散的符号能力还不够强。</p>
<p>有人在尝试混合架构。把Transformer和SSM结合起来，用Transformer处理需要全局注意力的部分，用SSM处理需要长期记忆的部分。</p>
<p>Retentive Networks是另一个方向。它用一种叫做retention的机制代替attention，计算效率更高，而且有记忆能力。</p>
<p>RWKV（Receptance Weighted Key Value）也在尝试线性注意力。它的训练和Transformer一样是并行的，但推理可以是顺序的，效率很高。</p>
<p>这些新架构都很有意思，但都还没有真正挑战Transformer的地位。为什么？</p>
<p>因为Transformer的生态太强大了。无数的优化技巧、工程实现、预训练模型，都是基于Transformer。换一个架构，意味着这些积累都要重来。</p>
<p>而且新架构需要时间验证。Transformer已经在各种任务上证明了自己，新架构还需要更多的实验和数据来证明它们的优势。</p>
<p>但这不意味着Transformer会永远统治。技术的发展不是线性的，总有突破点。</p>
<h2 id="神经符号融合的可能">神经符号融合的可能</h2>
<p>Transformer的推理能力不够，一个思路是把符号推理和神经网络结合起来。</p>
<p>什么是符号推理？就是传统AI的那套，用逻辑规则、知识图谱、推理引擎。这些方法在处理明确的逻辑问题时很强，但灵活性差，难以处理不确定性。</p>
<p>神经网络正好相反。它很灵活，能处理模糊的、不完整的信息，但逻辑推理能力弱。</p>
<p>能不能把两者结合起来？让神经网络负责感知和模式识别，符号系统负责推理和决策。</p>
<p>这个想法不新，但一直没有很好的实现。难点在于，怎么让这两个系统无缝协作。</p>
<p>DeepMind的AlphaGeometry就是个成功案例。它用神经网络生成几何构造的候选，用符号系统验证和推理。在国际数学奥林匹克几何题上，达到了金牌选手的水平。</p>
<p>类似的思路在定理证明、程序合成领域也在尝试。让神经网络提出猜想，符号系统验证证明。</p>
<p>但这些都是特定领域的解决方案，还没有通用的框架。怎么设计一个通用的神经符号架构，是个开放问题。</p>
<p>有人提出可微分的符号推理。把符号操作变成可微分的，这样就能和神经网络一起训练。但这在技术上很困难，因为很多符号操作本质上是离散的。</p>
<p>另一个方向是让神经网络学习符号操作。通过大量的推理数据，让模型隐式地学会逻辑规则。OpenAI的o1就是这个思路。</p>
<p>但这种隐式学习有局限。它能学到常见的推理模式，但面对全新的推理任务，可能就不行了。</p>
<p>真正的突破可能需要新的理论框架。不是简单地把两个系统拼起来，而是设计一个统一的架构，能同时做感知和推理。</p>
<p>这个架构会是什么样？现在还没人知道。但这是个值得探索的方向。</p>
<h2 id="架构搜索和元学习">架构搜索和元学习</h2>
<p>既然人设计架构很难，那让AI自己设计行不行？</p>
<p>神经架构搜索（NAS）就是干这个的。定义一个搜索空间，让算法在里面找最优的架构。</p>
<p>谷歌用NAS设计出了EfficientNet，在图像分类任务上超越了人类设计的架构。</p>
<p>但NAS有个大问题：计算成本太高。搜索一个好的架构，可能需要几千个GPU训练几个月。</p>
<p>而且NAS找到的架构往往很奇怪，可解释性差。你不知道它为什么这么设计，也不知道它能不能泛化到其他任务。</p>
<p>元学习是另一个思路。训练一个模型，让它学会如何快速学习新任务。</p>
<p>这个概念很吸引人。如果模型能学会学习，它就能快速适应各种新场景，不需要每次都从头训练。</p>
<p>但元学习在大模型时代遇到了挑战。因为大模型本身就有很强的few-shot学习能力。GPT-3给几个例子，就能完成新任务，这已经很接近元学习了。</p>
<p>更激进的想法是让模型自我进化。模型训练自己，改进自己的架构，然后训练新的版本。这样可以形成一个自我改进的循环。</p>
<p>但这在技术上非常困难。如何确保进化的方向是对的？如何避免模型走入歧途？如何保证稳定性？</p>
<p>而且这涉及到一个哲学问题：我们真的想要一个能自我进化的AI吗？如果它进化出了我们理解不了的架构，我们还能控制它吗？</p>
<p>这些问题暂时没有答案。但可以确定的是，架构设计不会永远依赖人类直觉。AI参与架构设计，是个必然趋势。</p>
<h2 id="智能体架构的新天地">智能体架构的新天地</h2>
<p>大语言模型只是AI的一种形式。智能体架构正在打开新的可能性。</p>
<p>什么是智能体？简单说，就是能感知环境、做出决策、执行动作的系统。它不只是回答问题，还能主动完成任务。</p>
<p>智能体需要不同的架构。它需要记忆，需要规划，需要工具使用能力，需要和环境交互。</p>
<p>记忆系统是关键。智能体需要记住过去的经验，从中学习。这不只是存储对话历史，而是要提取有用的信息，形成长期知识。</p>
<p>有人在尝试向量数据库加检索的方案。把经验存成向量，需要的时候检索出来。但这种方案还是比较粗糙，它不会主动遗忘无用信息，也不会主动巩固重要记忆。</p>
<p>更好的方案可能是分层记忆系统。短期记忆存最近的信息，长期记忆存提炼过的知识。两者之间有转换机制。</p>
<p>规划能力也很重要。给智能体一个复杂任务，它需要把任务拆解成子任务，安排执行顺序，在执行过程中动态调整。</p>
<p>现在的做法是让大模型生成计划，然后逐步执行。但这种方式缺乏全局优化，容易陷入局部最优。</p>
<p>强化学习可以帮助规划。通过试错，智能体学会什么策略更有效。但强化学习的样本效率很低，需要大量交互才能学好。</p>
<p>有人在研究分层强化学习。高层决策做什么，低层决策怎么做。这样可以加速学习，提高泛化能力。</p>
<p>工具使用是另一个维度。智能体需要会用各种工具：搜索引擎、计算器、数据库、API。甚至写代码，调用其他AI模型。</p>
<p>现在的工具使用还比较初级。模型需要明确的指令才知道用什么工具。更理想的情况是，模型自己判断需要什么工具，然后去学习使用。</p>
<p>多智能体系统也在探索。多个智能体协作完成任务，它们之间可以交流、分工、竞争。</p>
<p>这就像人类社会。每个人都是智能体，大家通过协作产生了群体智能。AI能不能也这样？</p>
<p>技术上是可行的。但挑战在于协调机制。怎么让智能体有效沟通？怎么避免冲突？怎么分配任务？</p>
<p>这些问题人类社会研究了几千年，还没有完美答案。AI领域也需要时间探索。</p>
<p>智能体架构的想象空间很大。它不只是语言模型的扩展，而是一个新的范式。未来的AI，可能更像智能体，而不是问答系统。</p>
<h2 id="底层创新的长期价值">底层创新的长期价值</h2>
<p>架构创新看起来很学术，但它的影响是深远的。</p>
<p>一个好的架构，可以让同样的算力和数据，产生质的飞跃。AlexNet让图像识别进入深度学习时代，Transformer让语言模型进入大规模时代。</p>
<p>下一个突破性架构是什么？现在还不知道。但可以确定的是，它不会从天而降。</p>
<p>它可能来自对现有架构缺陷的深刻理解。Transformer的作者发现，RNN的顺序计算是瓶颈，所以设计了完全并行的注意力机制。</p>
<p>它可能来自跨领域的借鉴。Attention机制最早来自机器翻译，后来发现它在各种任务上都有用。</p>
<p>它也可能来自基础理论的突破。如果我们对智能的理解更深入，就能设计更合理的架构。</p>
<p>神经科学是个重要的灵感来源。人脑不是Transformer，它有完全不同的工作机制。研究人脑，可能启发新的架构设计。</p>
<p>但也不能照搬。人脑很复杂，我们对它的理解还很有限。而且人脑的很多机制，是受生物约束的结果，不一定是最优的。</p>
<p>数学和理论计算机科学也很重要。架构设计不只是工程问题，也是理论问题。什么样的计算模型能有效表达智能？这是个深刻的问题。</p>
<p>业界和学界的分工也在变化。以前学界提出新想法，业界实现和应用。现在很多突破性工作都在业界完成，因为只有大公司才有资源训练超大模型。</p>
<p>但学界的角色还是重要的。小团队可以尝试激进的想法，不用担心短期回报。而大公司更保守，因为它们有商业压力。</p>
<p>理想的状态是两者互补。学界探索各种可能性，业界验证和规模化。但现实中，资源的集中正在打破这个平衡。</p>
<p>开源社区是个重要的力量。DeepSeek、Qwen、Llama、Mistral这些开源模型，让更多人可以参与架构创新。不需要巨大的资源，也能做有意义的实验。</p>
<p>架构创新需要时间。Transformer从2017年提出，到2022年才真正爆发，中间隔了五年。下一个突破性架构，可能也需要类似的时间。</p>
<p>但这个等待是值得的。因为架构的提升，是指数级的。一个好的架构，能让AI的能力跃升一个台阶。</p>
<h2 id="算法边界还远没到">算法边界还远没到</h2>
<p>算法和架构的边界在哪？</p>
<p>从Transformer的统治看，似乎我们已经找到了一个很好的解决方案。但实际上，我们只是爬到了一个局部高点。</p>
<p>更高的山峰还在远方。</p>
<p>计算复杂度可以更低。记忆机制可以更强。推理能力可以质变。多模态融合可以更深入。</p>
<p>这些都不是不可能的。它们需要的是时间、实验、理论突破。</p>
<p>更重要的是，AI本身正在加速这个过程。</p>
<p>用AI设计算法，已经不是科幻。AlphaCode写代码，AlphaTensor发现新的矩阵乘法算法，这些都是真实发生的事情。</p>
<p>AI加速科研，意味着算法创新的速度会越来越快。人类科学家可能需要几年才能想出一个新架构，AI可能几个月就能试遍所有可能性。</p>
<p>当然，这个过程不会一帆风顺。会有死胡同，会有无效的尝试。但整体趋势是明确的。</p>
<p>算法和架构的进步，会和算力、数据的进步互相促进。更好的算法需要更少的算力和数据，这又降低了实验的门槛，让更多人能参与创新。</p>
<p>Transformer统治五年了。它还能再统治五年吗？可能不会。</p>
<p>算法的边界，还远着呢。</p>
<h1 id="工程能力ai军备竞赛中最不性感但最致命的战场">工程能力：AI军备竞赛中最不性感但最致命的战场</h1>
<p>2023年初，Meta发布了Llama模型。参数量650亿，性能接近GPT-3。业界震惊，因为Meta开源了。</p>
<p>但真正懂行的人知道，拿到模型权重只是开始。你得把它跑起来，还得跑得又快又稳，成本还不能太高。这是完全不同的挑战。</p>
<p>OpenAI的GPT-4能服务全球几亿用户，不仅因为模型训练得好，是因为他们的工程系统能抗住这个流量。</p>
<p>工程与系统能力，是AI的第四个边界：你能不能构建大算力、获取高质量数据、并与好的算法和架构整合，产生更强大的AI，从实验室走向应用。</p>
<h2 id="训练系统的隐形战争">训练系统的隐形战争</h2>
<p>训练一个大模型，不是把代码扔到GPU上跑那么简单。</p>
<p>首先是分布式训练框架。几千张GPU怎么协同工作？谁负责哪部分计算？中间结果怎么同步？</p>
<p>PyTorch和TensorFlow提供了基础工具，但要把这些工具用好，需要深厚的工程积累。</p>
<p>数据并行是最简单的方案。每个GPU拿一批数据，算完梯度之后汇总。但当模型大到一张GPU放不下，数据并行就不够了。</p>
<p>模型并行是把模型切开，分到不同GPU上。听起来简单，做起来难。怎么切？切哪里？不同部分之间怎么通信？切不好，通信开销会把性能吃光。</p>
<p>流水线并行是另一个维度。把模型分成几段，像流水线一样处理数据。第一段算完传给第二段，第二段算完传给第三段。这样可以提高GPU利用率。</p>
<p>但流水线有个问题：气泡。前面的阶段算完了，后面的还没准备好，GPU就得空转。怎么设计流水线，让气泡最小？这是个优化难题。</p>
<p>张量并行更复杂。把模型的参数矩阵切开，分到不同GPU上。每个GPU算一部分，然后把结果拼起来。这需要对模型结构有深入理解，知道哪里能切，哪里不能切。</p>
<p>混合并行是把上面这些技术组合起来。数据并行加模型并行加流水线并行，三管齐下。Meta的Llama训练用的就是混合并行，几千张GPU同时工作。</p>
<p>但这还不够。还有通信优化。</p>
<p>GPU之间传数据，用的是NCCL（NVIDIA Collective Communications Library）这样的通信库。怎么让通信最高效？什么时候传？传多少？用什么算法？</p>
<p>Ring-AllReduce是常见的算法。把GPU排成一个环，数据在环上传一圈，每个GPU都能拿到完整的结果。但这个算法在某些情况下不是最优的。</p>
<p>Tree-AllReduce在大规模集群上更快。把GPU组织成树结构，数据先汇总到根节点，再广播下去。但它对网络拓扑有要求。</p>
<p>还有通信压缩。梯度可以压缩，减少传输量。但压缩会损失精度，压缩比和精度怎么平衡？</p>
<p>混合精度训练也是个关键技术。用FP16代替FP32，速度快一倍，显存省一半。但FP16容易溢出，不是所有操作都能用FP16。</p>
<p>哪些操作用FP16？哪些用FP32？梯度怎么缩放？这些细节都会影响训练稳定性。</p>
<p>检查点保存也有讲究。训练几个月，中途要是挂了，之前的工作就白费了。所以得定期保存检查点。</p>
<p>但保存检查点很慢。几百GB的模型参数，写到硬盘要几分钟。这几分钟GPU就得停下来等。怎么办？</p>
<p>异步保存。一边继续训练，一边在后台保存。但这需要额外的内存缓冲，而且要处理好并发问题。</p>
<p>还有错误恢复。几千张GPU跑几个月，总会有硬件故障。一张卡挂了，整个训练就得停。怎么快速检测故障？怎么替换坏卡？怎么从检查点恢复？</p>
<p>这些问题都不难，但都很琐碎。而且它们互相影响，改一个地方可能影响另一个地方。</p>
<p>OpenAI、谷歌、Meta这些公司，有几百个工程师在做这些事情。他们的训练系统，是多年积累的结果。</p>
<p>这就是为什么开源模型权重不够。训练系统不开源，你拿到模型也很难复现，更难改进。</p>
<h2 id="推理系统的性能博弈">推理系统的性能博弈</h2>
<p>训练好模型，只是万里长征第一步。让模型服务用户，是更大的挑战。</p>
<p>推理和训练不一样。训练追求吞吐量，可以慢慢跑。推理追求延迟，用户等不了。</p>
<p>而且推理的量级比训练大得多。ChatGPT每天几亿次请求，这个量级的系统，容不得半点松懈。</p>
<p>首先是模型压缩。GPT-4有几千亿参数，这么大的模型，推理成本很高。能不能压缩一下？</p>
<p>量化是常用方法。把FP32的参数变成INT8甚至INT4。精度降低，但模型变小了，推理变快了。</p>
<p>但量化会损失精度。怎么量化才能保证效果？哪些层可以量化？哪些层必须保留高精度？</p>
<p>剪枝是另一个方法。把不重要的参数删掉。但怎么判断哪些参数不重要？剪多了效果会变差。</p>
<p>知识蒸馏更激进。用大模型训练小模型，让小模型学会大模型的能力。但这个过程很难控制，小模型往往学不到大模型的精髓。</p>
<p>批处理是提高吞吐量的关键。多个请求一起处理，可以提高GPU利用率。但批处理会增加延迟，第一个请求要等最后一个请求处理完。</p>
<p>动态批处理可以缓解这个问题。不等凑够一批，来一个处理一个，处理过程中动态加入新请求。但这需要精细的调度算法。</p>
<p>KV缓存是加速推理的杀手锏。Transformer生成文本时，之前的计算结果可以缓存起来，不用重复计算。这能把推理速度提升几倍。</p>
<p>但KV缓存很吃显存。长文本生成时，缓存会占用大量空间。怎么管理缓存？什么时候清理？这又是个优化问题。</p>
<p>PagedAttention是个聪明的方案。把KV缓存分页管理，像操作系统管理内存一样。这样可以更高效地利用显存。</p>
<p>投机采样是另一个优化。用小模型快速生成候选，大模型验证。大部分时候小模型的结果就够用，只有少数情况需要大模型出马。</p>
<p>但这个方法有风险。小模型如果猜错了，反而浪费计算。什么时候用？怎么用？需要仔细设计。</p>
<p>模型并行在推理时也有用。把模型切到多张卡上，可以处理更大的模型。但切分方式和训练不同，因为推理时的计算模式不一样。</p>
<p>张量并行在推理时效果更好。因为推理是顺序的，流水线并行的气泡问题会很严重。</p>
<p>负载均衡也很关键。用户请求不是均匀分布的，有时候请求很多，有时候很少。怎么动态调整资源？</p>
<p>自动扩缩容可以解决这个问题。请求多的时候加机器，请求少的时候减机器。但扩缩容有延迟，不能等到请求来了再加机器。</p>
<p>预测性扩容更高级。根据历史数据预测请求量，提前准备资源。但预测不准会浪费成本。</p>
<p>还有多模型部署。不同用户可能需要不同的模型。基础版、专业版、定制版，怎么在同一套系统上服务这么多模型？</p>
<p>模型切换需要时间。不能每个请求来了都重新加载模型。所以要做模型缓存，热门模型常驻内存。</p>
<p>但内存有限，不可能把所有模型都缓存。哪些模型缓存？什么时候换出？这又是个LRU缓存的问题，但比普通缓存复杂得多。</p>
<p>推理系统的性能优化，是个无底洞。每提升1%，都可能省下大笔成本。</p>
<p>OpenAI的推理系统，据说经过了上百次迭代。每次迭代都是几个百分点的提升，累加起来就是巨大的优势。</p>
<p>这就是为什么很多创业公司做不起来。他们有好的模型idea，但推理系统跟不上，成本居高不下，最后活不下去。</p>
<h2 id="数据处理的精细活">数据处理的精细活</h2>
<p>AI的数据处理，不是写个爬虫那么简单。</p>
<p>数据清洗是第一关。网上爬来的数据，充斥着垃圾。HTML标签、广告、重复内容、格式错误，这些都要清理。</p>
<p>去重也很重要。互联网上重复内容太多了。同一篇文章被转载无数次，这些重复数据会污染训练集。</p>
<p>但精确去重不够。有些文章只是略微改了几个字，本质上是重复的。这需要模糊去重。</p>
<p>SimHash、MinHash这些算法可以做模糊去重。但它们都有误差，去重率和误删率怎么平衡？</p>
<p>质量过滤更难。什么样的数据是高质量的？没有标准答案。</p>
<p>有人用启发式规则。比如检查标点符号比例、平均句子长度、停用词比例。但这些规则很粗糙，会误伤很多好数据。</p>
<p>有人用分类器。训练一个模型，判断数据质量。但这需要标注数据，而标注数据本身就是个大工程。</p>
<p>OpenAI据说用了GPT-4来过滤训练数据。让GPT-4判断哪些数据值得训练。但这个成本很高，不是所有公司都玩得起。</p>
<p>数据格式转换也有讲究。不同来源的数据，格式千奇百怪。PDF、Word、HTML、Markdown，每种格式的解析都是个坑。</p>
<p>PDF是重灾区。有些PDF是扫描的图片，需要OCR识别。有些PDF有多列排版，解析出来顺序乱了。有些PDF里有表格，表格怎么转成文本？</p>
<p>多模态数据更复杂。图文数据怎么对齐？视频怎么分割？音频怎么转录？</p>
<p>数据增强也是个技术活。训练数据不够怎么办？可以用数据增强技巧人工制造更多数据。</p>
<p>文本可以用回译。翻译成另一种语言，再翻译回来，就得到了变体。但回译会损失一些信息，质量参差不齐。</p>
<p>图像可以旋转、裁剪、调色。但过度增强会引入噪声，影响模型效果。</p>
<p>数据版本管理也很重要。训练数据会不断迭代，新数据加入，旧数据被清理。怎么追踪这些变化？</p>
<p>如果发现模型有问题，要能回溯是哪批数据导致的。这需要完善的数据血缘追踪系统。</p>
<p>数据隐私也是个大问题。训练数据里可能包含敏感信息。怎么检测？怎么脱敏？</p>
<p>欧盟的GDPR规定，用户有权要求删除自己的数据。如果用户提出删除请求，不仅要删除原始数据，还要删除所有衍生数据。</p>
<p>但AI模型已经从这些数据里学到了信息，怎么删除？模型遗忘是个研究热点，但还没有完美的解决方案。</p>
<p>数据处理看起来简单，实际上是个系统工程。每个环节都有细节，每个细节都可能影响最终效果。</p>
<p>大公司有专门的数据工程团队，几十上百人在做数据处理。这些人不写模型代码，但他们的工作决定了模型能有多好。</p>
<h2 id="工程债务的隐形成本">工程债务的隐形成本</h2>
<p>AI系统的工程债务，比传统软件严重得多。</p>
<p>传统软件，代码就是全部。AI系统不一样，代码只是一部分，还有数据、模型、配置。</p>
<p>数据和代码纠缠在一起。改了数据，模型效果可能变差。改了模型，数据处理逻辑可能要跟着变。</p>
<p>配置地狱更严重。学习率、batch size、优化器参数、正则化系数，这些超参数互相影响。改一个参数，可能需要重新调整其他所有参数。</p>
<p>而且AI系统很难测试。传统软件可以写单元测试、集成测试。AI系统怎么测？模型输出是概率性的，没有固定答案。</p>
<p>你可以测模型在标准数据集上的准确率。但标准数据集不能代表真实场景。模型在测试集上效果好，不代表在生产环境也好。</p>
<p>A/B测试是必须的。但A/B测试周期长，成本高。而且A/B测试只能测整体效果，不能定位具体问题。</p>
<p>模型退化是个隐蔽的风险。生产环境的数据分布会变化，模型性能会逐渐下降。但这个下降是缓慢的，不容易察觉。</p>
<p>等你发现的时候，用户已经流失了。所以需要持续监控，但监控什么指标？怎么判断退化？</p>
<p>再训练是解决退化的办法。但再训练要用新数据，新数据从哪来？怎么保证质量？</p>
<p>增量训练可以省成本，但容易出现灾难性遗忘。模型学了新知识，忘了旧知识。</p>
<p>全量重训可以解决遗忘问题，但成本太高。而且全量重训不能保证效果一定更好，可能还会变差。</p>
<p>版本管理也很头疼。模型每次更新都是一个新版本。旧版本要不要保留？保留多久？</p>
<p>如果新版本出问题，怎么快速回滚？回滚的话，之前基于新版本的数据怎么处理？</p>
<p>多版本并存更复杂。有些用户在用旧版本，有些用户在用新版本。两个版本行为不一致，用户体验就会割裂。</p>
<p>技术债务会累积。一开始为了快速上线，可能写了些不太优雅的代码。后来业务扩大，这些代码成了瓶颈。</p>
<p>重构吧，风险大。不重构吧，系统越来越慢，越来越难维护。</p>
<p>这就是工程债务的隐形成本。它不会立刻要你的命，但会慢慢拖累你，让你跑不快。</p>
<p>大厂为什么难被颠覆？不是因为他们模型多好，是因为他们把这些坑都踩过了，知道怎么避免。</p>
<p>创业公司为什么容易失败？不是因为想法不好，是因为工程能力跟不上，最后被工程债务压垮。</p>
<h2 id="系统能力的护城河">系统能力的护城河</h2>
<p>工程与系统能力，是AI公司的真正护城河。</p>
<p>模型可以复制。开源社区已经证明了，给足够的算力和数据，复现一个大模型不是不可能。</p>
<p>但系统能力很难复制。它是无数细节的积累，是无数次试错的结果。</p>
<p>OpenAI的推理系统，谷歌的训练框架，Meta的数据处理pipeline，这些东西都不开源。因为这才是它们的核心竞争力。</p>
<p>Anthropic为什么能快速崛起？因为团队大部分来自OpenAI，把系统能力带过去了。</p>
<p>Mistral为什么能用小团队做出好模型？因为核心成员来自Meta，知道怎么搞工程。</p>
<p>这些人知道哪里会有坑，知道怎么优化性能，知道怎么设计系统架构。这些知识比模型论文值钱得多。</p>
<p>国内的大厂也在快速积累系统能力。阿里的PAI平台，腾讯的TI平台，字节的火山引擎，这些都是多年工程积累的结果。</p>
<p>系统能力需要时间。不是招几个人就能搞定的。它需要在真实的业务场景里不断打磨，不断优化。</p>
<p>这也是为什么AI底层创业越来越难。以前可以靠好的idea突围，现在idea不够了，还得有强大的工程能力。</p>
<p>但这不意味着小公司没机会。差异化竞争还是有空间的。</p>
<p>专注特定场景，可以用定制化的系统。不需要像OpenAI那样服务所有用户，只服务一个领域，系统可以简单很多。</p>
<p>用开源工具降低门槛。vLLM、Triton、DeepSpeed这些开源工具越来越好用，小团队也能搭起不错的系统。</p>
<p>借助云服务降低成本。云厂商提供了训练和推理的托管服务，不需要自己搭系统。虽然灵活性差一些，但省心很多。</p>
<p>工程能力的提升，也在加速。十年前搞一套训练系统，要从零开始。现在有大量开源工具、最佳实践、技术社区。</p>
<p>AI本身也在帮助工程优化。用AI调参，用AI优化系统，用AI写代码。这些都在降低工程的门槛。</p>
<h2 id="工程的边界在哪里">工程的边界在哪里</h2>
<p>工程与系统能力的边界在哪？</p>
<p>从现状看，还有巨大的提升空间。</p>
<p>训练效率还能提高。现在的GPU利用率大概50-60%，还有很多浪费。</p>
<p>推理成本还能降低。通过更好的优化，推理成本可以降到现在的十分之一。</p>
<p>数据处理还能自动化。现在很多工作还需要人工介入，未来可以用AI来做。</p>
<p>系统稳定性还能增强。现在的系统还会出各种故障，未来可以做到接近零故障。</p>
<p>这些提升都是增量的，但累加起来就是质变。</p>
<p>更重要的是，工程能力的提升会降低AI的门槛。当系统越来越好用，越来越稳定，越来越便宜，就会有更多人能用得起AI。</p>
<p>这会形成飞轮。更多人用AI，就有更多反馈，系统就能改进得更快。</p>
<p>十年前，训练一个图像分类模型需要专家。现在，普通开发者用AutoML就能搞定。</p>
<p>再过十年，训练大语言模型可能也会变得很简单。不需要懂分布式训练，不需要调超参数，傻瓜式操作就能完成。</p>
<p>那时候，竞争的重点就不是工程能力了，而是数据、场景、创意。</p>
<p>但在那一天到来之前，工程能力还是核心壁垒。它不性感，但它决定了谁能活下来，谁能走得更远。</p>
<p>所以，当有人问AI的边界在哪里，工程这个维度的答案是：我们才刚刚起步。</p>
<p>最好的系统，还没有被设计出来。最高效的架构，还没有被发现。最稳定的平台，还没有被建造。</p>
<p>工程的边界，还远着呢。</p>
<h1 id="ai的边界在哪里我们可能还没看到起跑线">AI的边界在哪里？我们可能还没看到起跑线</h1>
<p>AI绘画的Stable Diffusion/Midjourney时刻，文本生成的ChatGPT时刻，全球震惊。人们疯狂研究提示词，琢磨怎么让AI更听话。</p>
<p>没多久，DeepSeek R1时刻大幅降低AI使用门槛，不需要复杂提示词，用嘴就能写爽文。</p>
<p>GPT-4o出现，对复杂工作流降维打击，用嘴就能P图。你不需要复杂的咒语和复杂工作流，说人话就行。</p>
<p>刚刚，视频生成的Sora 2时刻诞生，动动嘴就能拍视频。</p>
<p>每一次迭代，都在重新定义可能性。每一次震撼，都让人以为这就是终点。然后下一个震撼又来了。</p>
<p>AI的边界在哪里？答案可能是：我们根本还看不到边界。</p>
<h2 id="四个维度的同步突破">四个维度的同步突破</h2>
<p>算力、数据、算法、工程，这四个边界不是孤立的。它们在互相促进。</p>
<p>算力在快速增长。芯片制程还在进步，新架构不断涌现，能源和散热技术在突破。十年后的算力，可能是现在的一千倍。</p>
<p>这不是线性增长，是指数增长。因为每一代技术都在为下一代打基础。</p>
<p>数据看起来快用完了，但新的数据源在不断打开。多模态数据、科学实验数据、AI生成的验证过的数据，这些才刚刚开始挖掘。</p>
<p>最重要的是，AI正在创造新知识。AlphaFold预测的蛋白质结构、AI发现的数学定理、AI设计的新材料，这些都是全新的数据。</p>
<p>算法和架构的创新空间更大。Transformer统治了五年，但它的继任者已经在路上。混合架构、神经符号系统、记忆增强网络，各种可能性都在探索。</p>
<p>而且AI自己在设计算法。AlphaTensor发现了更快的矩阵乘法，这是人类几十年没做到的。未来会有更多这样的突破。</p>
<p>工程能力在快速成熟。开源工具越来越好用，云服务越来越便宜，最佳实践越来越清晰。十年前需要顶级专家才能做的事，现在普通工程师也能搞定。</p>
<p>这四个维度的进步不是独立的，它们在形成飞轮。</p>
<p>更强的算力能训练更大的模型，更大的模型能更好地利用数据，更好的数据能发现更优的算法，更优的算法能提高工程效率。</p>
<p>然后循环又开始了。更高的工程效率降低了算力成本，更低的成本让更多人能参与，更多人参与产生更多创新。</p>
<p>这个飞轮已经在转了。而且转速在加快。</p>
<h2 id="ai加速ai的临界点">AI加速AI的临界点</h2>
<p>最关键的变化是：AI开始加速自己的进化。</p>
<p>以前，科研是人类的专属。现在，AI在很多领域已经能辅助甚至主导科研。</p>
<p>材料科学是个例子。传统方法是科学家提出假设，做实验验证，分析结果。这个循环可能要几个月。</p>
<p>现在AI可以预测材料性质，筛选候选方案，设计实验。实验由机器人执行，数据自动收集。整个循环可能只要几天。</p>
<p>而且AI不会累，不会有偏见，能同时尝试几千种可能性。</p>
<p>药物研发也是这样。传统新药开发要十年以上。AI辅助后，某些阶段可以缩短到几个月。</p>
<p>Insilico Medicine用AI设计的药物，已经进入临床试验。从零到进入临床，只用了不到三年。</p>
<p>蛋白质工程更激进。现在可以用AI设计全新的蛋白质，具有自然界不存在的功能。这打开了生物技术的新天地。</p>
<p>芯片设计也被AI加速了。谷歌用AI设计TPU芯片的布局，效率比人类工程师高，而且能探索人类想不到的方案。</p>
<p>未来的AI芯片，可能由AI自己设计。它会比人类设计的更高效，更适合AI计算。</p>
<p>算法研究也在被加速。AI可以自动搜索神经网络架构，可以发现新的优化算法，可以找到更好的训练策略。</p>
<p>现在还是人类设定搜索空间，AI在空间里找最优解。未来可能连搜索空间都由AI定义。</p>
<p>意味着AI进化的速度不再受人类认知速度的限制。</p>
<p>以前，每一次算法突破都需要聪明人灵光一现。Transformer的提出者思考了很久，才想到注意力机制。</p>
<p>未来，AI可以在几天内尝试人类几十年才能想到的所有可能性。它不需要灵感，只需要算力。</p>
<p>这是个质变。当AI开始大规模参与自身的研发，进化曲线会从线性变成指数。</p>
<h2 id="架构革命的可能性">架构革命的可能性</h2>
<p>Transformer不是终点。它的局限性已经很明显，而突破的方向也在显现。</p>
<p>计算复杂度的问题有解。线性注意力、状态空间模型、混合架构，这些方向都有希望。</p>
<p>也许未来的架构不是单一的，而是模块化的。不同的任务用不同的模块，灵活组合。</p>
<p>记忆问题也在攻克。外部记忆系统、动态知识图谱、分层记忆机制，这些技术都在快速发展。</p>
<p>未来的AI可能有真正的长期记忆。它能记住几个月前的对话，能从海量历史中提取经验，能像人类一样积累知识。</p>
<p>推理能力的提升更值得期待。神经符号融合、可微分推理、程序合成，这些方向可能带来质的飞跃。</p>
<p>想象一个AI，它既有神经网络的灵活性，又有符号系统的逻辑严密性。它能处理模糊的信息，也能进行严格的推理。</p>
<p>这样的AI能做什么？它可能真正理解因果关系，而不只是相关性。它可能解决需要多步推理的复杂问题。它可能发现人类从未想到的理论。</p>
<p>多模态融合会更深入。现在的多模态模型，基本上是把不同模态的数据映射到同一个空间。未来可能有更本质的融合方式。</p>
<p>世界模型的概念很诱人。AI从多模态数据中学习物理世界的运行规律，建立统一的世界理解。</p>
<p>有了世界模型，AI就能做更复杂的推理。它知道物体会掉落，知道人会说话，知道事件会有后果。这种常识理解，是真正智能的基础。</p>
<p>量子计算可能改变游戏规则。虽然现在还不成熟，但一旦实现稳定可控，某些类型的计算能力会有质的飞跃。</p>
<p>量子机器学习是个新兴领域。量子态可以表示指数级的信息，量子算法可以同时探索多个可能性。</p>
<p>这不意味着量子计算能替代经典计算。它们更可能是互补的。经典计算做大部分工作，量子计算处理特定的难题。</p>
<p>架构的革命可能不止一次。Transformer之后，可能还有好几代架构。每一代都会带来能力的跃升。</p>
<h2 id="应用爆发的连锁反应">应用爆发的连锁反应</h2>
<p>技术突破会带来应用爆发，应用爆发又会推动技术进步。</p>
<p>ChatGPT的成功，引发了全球的AI热潮。无数公司投入AI研发,无数开发者学习AI技术，无数资金涌入这个领域。</p>
<p>这些资源的涌入，加速了整个行业的发展。更多的算力被建设，更多的数据被收集，更多的人才被培养。</p>
<p>应用场景也在快速扩展。从最初的聊天机器人，到代码助手、图像生成、视频制作、音乐创作、科研辅助、医疗诊断、教育个性化。</p>
<p>每一个应用场景，都是一个数据飞轮。产品产生数据，数据改进模型，模型提升产品。</p>
<p>特斯拉的自动驾驶就是个典型案例。几百万辆车在路上跑，每天产生海量数据。这些数据训练模型，模型改进驾驶能力。</p>
<p>随着自动驾驶能力提升，更多人愿意购买特斯拉，车队规模扩大，数据产生速度加快。飞轮越转越快。</p>
<p>类似的飞轮正在各个领域形成。医疗AI、教育AI、设计AI、研发AI，每个领域都有自己的数据闭环。</p>
<p>这些飞轮不是孤立的。它们之间会有协同效应。医疗AI的突破可能帮助生物AI，生物AI的进步可能推动材料AI。</p>
<p>通用AI能力的提升，会让所有垂直领域受益。当GPT-5出来，所有基于GPT的应用都会自动升级。</p>
<p>这种协同效应会加速整个生态的进化。不是一个公司在突破，是整个行业在一起往前跑。</p>
<p>开源社区的作用也很关键。Llama、Stable Diffusion、Whisper这些开源模型，让无数小团队和个人开发者能参与进来。</p>
<p>他们的创新又会反哺整个生态。有些想法可能来自一个学生、一个独立开发者、一个小创业公司。</p>
<p>这种分布式创新的效率，远超传统的中心化研发。因为试错的成本低，探索的空间大，进化的路径多。</p>
<h2 id="不变的是什么">不变的是什么</h2>
<p>在这个飞速变化的时代，什么是不变的？</p>
<p>人的需求是不变的。人们想要更好的生活，想要解决问题，想要理解世界，想要创造价值。</p>
<p>AI只是工具，目的是满足这些需求。无论技术怎么变，这个本质不会变。</p>
<p>真实世界的规律是不变的。物理定律、化学规律、生物机制，这些是客观存在的。AI再强，也要遵守这些规律。</p>
<p>这实际上是好事。因为真实世界的约束，让AI的能力有了锚点。它不会变成不可控的魔法，而是可以被理解、被预测的工具。</p>
<p>人类的创造力是不变的。AI可以辅助创造，但创造的动机和方向来自人类。</p>
<p>AI能写代码，但写什么代码由人决定。AI能画画,但画什么主题由人定义。AI能做实验，但研究什么问题由人选择。</p>
<p>这种人机协作的模式，可能是未来的常态。不是AI替代人，而是AI增强人。</p>
<p>伦理和价值观也是不变的。AI越强大，伦理问题越重要。谁控制AI？AI为谁服务？AI的决策是否公平？这些问题需要社会共识。</p>
<p>技术可以快速迭代，但社会规范的建立需要时间。这个时间差会带来摩擦，但也是必要的调整过程。</p>
<p>学习和适应的需要是不变的。AI在快速进化，人也需要快速学习。</p>
<p>十年前学的技能，现在可能过时了。十年后的工作，现在可能还不存在。终身学习不再是口号，而是生存必需。</p>
<p>但这也是机会。AI降低了学习门槛。你想学编程，AI可以手把手教。你想学设计，AI可以实时反馈。你想学科学，AI可以做你的研究助手。</p>
<h2 id="边界还远着呢">边界还远着呢</h2>
<p>回到最初的问题：AI的边界在哪里？</p>
<p>从算力看，我们还在摩尔定律的延长线上。制程还能进步，架构还能创新，量子计算还在路上。</p>
<p>从数据看，互联网文本只是冰山一角。多模态数据、科学数据、验证过的合成数据，还有巨大空间。</p>
<p>从算法看，Transformer只是开始。更高效的架构、更强的推理能力、更好的记忆机制，都在探索中。</p>
<p>从工程看，系统能力还很粗糙。训练效率、推理成本、部署便利性，都有数量级的提升空间。</p>
<p>更重要的是，这四个维度在互相促进。它们形成的飞轮正在加速。</p>
<p>而AI本身在成为加速器。它在设计芯片，在创造数据，在发现算法，在优化系统。</p>
<p>这是个正反馈循环。AI越强，它加速自己进化的能力就越强。进化速度会越来越快。</p>
<p>有人担心这会失控。AI会不会强大到无法控制？</p>
<p>这个担心有道理，但现在讨论可能还早。我们连通用人工智能（AGI）的门槛都还没摸到。</p>
<p>现在的AI，在特定任务上很强，但没有真正的通用智能。</p>
<p>它们不理解自己在做什么，没有自主意识，没有目标和动机。它们只是强大的模式匹配器。</p>
<p>从AI到AGI，可能还需要几次架构革命。可能需要真正的世界模型，真正的因果推理，真正的自主学习。</p>
<p>这些突破什么时候会来？没人知道。可能五年，可能十年，可能更久。</p>
<p>但可以确定的是，这个方向是明确的。行业在朝着AGI的方向努力，资源在不断投入，突破在不断发生。</p>
<p>AI在进化，而且进化在加速。</p>
<p>所以，AI的边界在哪里？</p>
<p>边界还远没到。我们可能连边界的影子都还没看到。</p>
<p>现在我们觉得重要的事情，再过两年可能也不重要了。因为技术又进化了，门槛又降低了，可能性又扩大了。</p>
<p>这个时代的特点就是：每次你以为看到了天花板，天花板就又高了一截。</p>
<p>别问AI能做什么，问它不能做什么。而不能做的清单在快速缩短。</p>
<p>别问AGI能否到达，问我们每天在进步多少。但每天这疯狂的进步，总有一天会跨过那道门槛。</p>
<p>别问AI会不会取代人类，先和AI一起协作。工具在变强，使用工具的人也在变强。</p>
<p>AI的边界，就是人类想象力的边界。</p>
<p>而人类的想象力，是没有边界的。</p>
<p>所以，AI的边界，还远着呢。</p>
<p>真正的变革，才刚刚开始。</p>

            <footer class="footline">
            </footer>
          </article>
        </div>
      </main>
    </div>
    <aside id="sidebar" class="default-animation">
      <div id="header-wrapper" class="default-animation">
        <div id="header" class="default-animation">
          <a id="logo" href="/">
            <img width="280px" src="/hb.png"></img>
            <br><font face="serif" size="5" color="#FF0000"><b>明 文 视 界</b></font>
          </a>
        </div>
        <div class="searchbox default-animation">
          <label for="search-by"><i class="fas fa-search"></i></label>
          <input data-search-input id="search-by" type="search" placeholder="搜索...">
          <span data-search-clear=""><i class="fas fa-times"></i></span>
        </div>
        <script>
          var contentLangs=['zh'];
        </script>
        <script src="/js/auto-complete.js?1759564411" defer></script>
        <script src="/js/lunr.min.js?1759564411" defer></script>
        <script src="/js/lunr.stemmer.support.min.js?1759564411" defer></script>
        <script src="/js/lunr.multi.min.js?1759564411" defer></script>
        <script src="/js/lunr.zh.min.js?1759564411" defer></script>
        <script src="/js/search.js?1759564411" defer></script>
      </div>
      <div id="content-wrapper" class="highlightable">
        <ul class="topics">
          <li data-nav-id="/04_mwgc/" title="《明文AI观察》" class="dd-item parent"><input type="checkbox" id="section-6a42486e2cada4a0cf485f25f9ca3755" class="toggle" checked/><label for="section-6a42486e2cada4a0cf485f25f9ca3755" ></label><a href="/04_mwgc/">《明文AI观察》</a><ul>
          <li data-nav-id="/04_mwgc/ai-%E7%9A%84%E8%BE%B9%E7%95%8C%E5%9C%A8%E5%93%AA%E9%87%8C%E6%88%91%E4%BB%AC%E5%8F%AF%E8%83%BD%E8%BF%9E%E8%BE%B9%E7%95%8C%E7%9A%84%E5%BD%B1%E5%AD%90%E9%83%BD%E8%BF%98%E6%B2%A1%E7%9C%8B%E5%88%B0/" title="AI的边界在哪里？我们可能连边界的影子都还没看到" class="dd-item active"><a href="/04_mwgc/ai-%E7%9A%84%E8%BE%B9%E7%95%8C%E5%9C%A8%E5%93%AA%E9%87%8C%E6%88%91%E4%BB%AC%E5%8F%AF%E8%83%BD%E8%BF%9E%E8%BE%B9%E7%95%8C%E7%9A%84%E5%BD%B1%E5%AD%90%E9%83%BD%E8%BF%98%E6%B2%A1%E7%9C%8B%E5%88%B0/">AI的边界在哪里？我们可能连边界的影子都还没看到</a></li>
          <li data-nav-id="/04_mwgc/%E7%8E%AF%E5%A2%83%E5%8D%B3%E6%9C%8D%E5%8A%A1%E5%8D%87%E7%BA%A7/" title="环境将是帝国的疆土，智能体则是帝国的生态" class="dd-item"><a href="/04_mwgc/%E7%8E%AF%E5%A2%83%E5%8D%B3%E6%9C%8D%E5%8A%A1%E5%8D%87%E7%BA%A7/">环境将是帝国的疆土，智能体则是帝国的生态</a></li>
          <li data-nav-id="/04_mwgc/ai%E9%A3%9F%E7%89%A9%E9%93%BE/" title="未来AI食物链的三个层级" class="dd-item"><a href="/04_mwgc/ai%E9%A3%9F%E7%89%A9%E9%93%BE/">未来AI食物链的三个层级</a></li>
          <li data-nav-id="/04_mwgc/%E7%8E%AF%E5%A2%83%E5%8D%B3%E6%9C%8D%E5%8A%A1/" title="欢迎来到“环境即服务” (EaaS) 时代" class="dd-item"><a href="/04_mwgc/%E7%8E%AF%E5%A2%83%E5%8D%B3%E6%9C%8D%E5%8A%A1/">欢迎来到“环境即服务” (EaaS) 时代</a></li>
          <li data-nav-id="/04_mwgc/%E5%8D%83%E5%B9%B4%E9%9A%BE%E9%81%87%E7%9A%84%E6%9C%BA%E9%81%87%E4%B8%8E%E5%8F%98%E9%9D%A9/" title="千年难遇的变革和机遇" class="dd-item"><a href="/04_mwgc/%E5%8D%83%E5%B9%B4%E9%9A%BE%E9%81%87%E7%9A%84%E6%9C%BA%E9%81%87%E4%B8%8E%E5%8F%98%E9%9D%A9/">千年难遇的变革和机遇</a></li></ul></li>
          <li data-nav-id="/01_aigc_object/" title="已分类归档AI项目资源集" class="dd-item"><input type="checkbox" id="section-6923aefeee137d3a1b22febe43e9c1b9" class="toggle"/><label for="section-6923aefeee137d3a1b22febe43e9c1b9" ></label><a href="/01_aigc_object/">已分类归档AI项目资源集</a><ul>
          <li data-nav-id="/01_aigc_object/01_github/" title="GitHub 开源项目" class="dd-item"><input type="checkbox" id="section-4850e9adfca824729d998fcbfaa6581c" class="toggle"/><label for="section-4850e9adfca824729d998fcbfaa6581c" ></label><a href="/01_aigc_object/01_github/">GitHub 开源项目</a><ul>
          <li data-nav-id="/01_aigc_object/01_github/01-git%E8%A7%86%E9%A2%91/" title="视频" class="dd-item"><a href="/01_aigc_object/01_github/01-git%E8%A7%86%E9%A2%91/">视频</a></li>
          <li data-nav-id="/01_aigc_object/01_github/02-git%E8%AF%AD%E9%9F%B3/" title="语音" class="dd-item"><a href="/01_aigc_object/01_github/02-git%E8%AF%AD%E9%9F%B3/">语音</a></li>
          <li data-nav-id="/01_aigc_object/01_github/03-git%E5%9B%BE%E5%83%8F/" title="图像" class="dd-item"><a href="/01_aigc_object/01_github/03-git%E5%9B%BE%E5%83%8F/">图像</a></li>
          <li data-nav-id="/01_aigc_object/01_github/04-gitllm/" title="LLM" class="dd-item"><a href="/01_aigc_object/01_github/04-gitllm/">LLM</a></li>
          <li data-nav-id="/01_aigc_object/01_github/05-git3d/" title="3D" class="dd-item"><a href="/01_aigc_object/01_github/05-git3d/">3D</a></li>
          <li data-nav-id="/01_aigc_object/01_github/06-git%E6%8A%80%E6%9C%AF/" title="技术" class="dd-item"><a href="/01_aigc_object/01_github/06-git%E6%8A%80%E6%9C%AF/">技术</a></li>
          <li data-nav-id="/01_aigc_object/01_github/07-git%E6%95%B0%E5%AD%97%E4%BA%BA/" title="数字人" class="dd-item"><a href="/01_aigc_object/01_github/07-git%E6%95%B0%E5%AD%97%E4%BA%BA/">数字人</a></li>
          <li data-nav-id="/01_aigc_object/01_github/08-git%E5%8A%9E%E5%85%AC/" title="办公智能体" class="dd-item"><a href="/01_aigc_object/01_github/08-git%E5%8A%9E%E5%85%AC/">办公智能体</a></li>
          <li data-nav-id="/01_aigc_object/01_github/09-gitmcp/" title="MCP" class="dd-item"><a href="/01_aigc_object/01_github/09-gitmcp/">MCP</a></li>
          <li data-nav-id="/01_aigc_object/01_github/10-git%E8%84%9A%E6%9C%AC%E5%B7%A5%E5%85%B7/" title="脚本工具" class="dd-item"><a href="/01_aigc_object/01_github/10-git%E8%84%9A%E6%9C%AC%E5%B7%A5%E5%85%B7/">脚本工具</a></li>
          <li data-nav-id="/01_aigc_object/01_github/11-git%E9%87%91%E8%9E%8D/" title="金融" class="dd-item"><a href="/01_aigc_object/01_github/11-git%E9%87%91%E8%9E%8D/">金融</a></li>
          <li data-nav-id="/01_aigc_object/01_github/12-git%E7%94%9F%E7%89%A9/" title="生命科学" class="dd-item"><a href="/01_aigc_object/01_github/12-git%E7%94%9F%E7%89%A9/">生命科学</a></li>
          <li data-nav-id="/01_aigc_object/01_github/13-git%E6%95%B0%E5%AD%A6/" title="数学" class="dd-item"><a href="/01_aigc_object/01_github/13-git%E6%95%B0%E5%AD%A6/">数学</a></li>
          <li data-nav-id="/01_aigc_object/01_github/14-git%E5%8C%BB%E7%96%97/" title="医疗" class="dd-item"><a href="/01_aigc_object/01_github/14-git%E5%8C%BB%E7%96%97/">医疗</a></li>
          <li data-nav-id="/01_aigc_object/01_github/15-git%E5%8C%96%E5%AD%A6/" title="化学" class="dd-item"><a href="/01_aigc_object/01_github/15-git%E5%8C%96%E5%AD%A6/">化学</a></li>
          <li data-nav-id="/01_aigc_object/01_github/16-git%E6%9C%BA%E5%99%A8%E4%BA%BA/" title="机器人" class="dd-item"><a href="/01_aigc_object/01_github/16-git%E6%9C%BA%E5%99%A8%E4%BA%BA/">机器人</a></li>
          <li data-nav-id="/01_aigc_object/01_github/17-git%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/" title="编程开发" class="dd-item"><a href="/01_aigc_object/01_github/17-git%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/">编程开发</a></li></ul></li>
          <li data-nav-id="/01_aigc_object/02_closed-cn/" title="国内项目" class="dd-item"><input type="checkbox" id="section-e31223ca567bcd81dc617b5a854df44d" class="toggle"/><label for="section-e31223ca567bcd81dc617b5a854df44d" ></label><a href="/01_aigc_object/02_closed-cn/">国内项目</a><ul>
          <li data-nav-id="/01_aigc_object/02_closed-cn/01-cn%E7%BB%BC%E5%90%88/" title="综合" class="dd-item"><a href="/01_aigc_object/02_closed-cn/01-cn%E7%BB%BC%E5%90%88/">综合</a></li>
          <li data-nav-id="/01_aigc_object/02_closed-cn/02-cn%E8%A7%86%E9%A2%91/" title="视频" class="dd-item"><a href="/01_aigc_object/02_closed-cn/02-cn%E8%A7%86%E9%A2%91/">视频</a></li>
          <li data-nav-id="/01_aigc_object/02_closed-cn/03-cn%E9%9F%B3%E9%A2%91/" title="音频" class="dd-item"><a href="/01_aigc_object/02_closed-cn/03-cn%E9%9F%B3%E9%A2%91/">音频</a></li>
          <li data-nav-id="/01_aigc_object/02_closed-cn/04-cn3d/" title="3D" class="dd-item"><a href="/01_aigc_object/02_closed-cn/04-cn3d/">3D</a></li>
          <li data-nav-id="/01_aigc_object/02_closed-cn/05-cnllm/" title="LLM" class="dd-item"><a href="/01_aigc_object/02_closed-cn/05-cnllm/">LLM</a></li>
          <li data-nav-id="/01_aigc_object/02_closed-cn/06-cn%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/" title="编程开发" class="dd-item"><a href="/01_aigc_object/02_closed-cn/06-cn%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/">编程开发</a></li>
          <li data-nav-id="/01_aigc_object/02_closed-cn/07-cn%E5%8A%9E%E5%85%AC/" title="办公智能体" class="dd-item"><a href="/01_aigc_object/02_closed-cn/07-cn%E5%8A%9E%E5%85%AC/">办公智能体</a></li></ul></li>
          <li data-nav-id="/01_aigc_object/03_closed-en/" title="国外项目" class="dd-item"><input type="checkbox" id="section-89a0ded1aec38a485fdfd5812f7ed880" class="toggle"/><label for="section-89a0ded1aec38a485fdfd5812f7ed880" ></label><a href="/01_aigc_object/03_closed-en/">国外项目</a><ul>
          <li data-nav-id="/01_aigc_object/03_closed-en/01-en%E7%BB%BC%E5%90%88/" title="综合" class="dd-item"><a href="/01_aigc_object/03_closed-en/01-en%E7%BB%BC%E5%90%88/">综合</a></li>
          <li data-nav-id="/01_aigc_object/03_closed-en/02-en%E8%A7%86%E9%A2%91/" title="视频" class="dd-item"><a href="/01_aigc_object/03_closed-en/02-en%E8%A7%86%E9%A2%91/">视频</a></li>
          <li data-nav-id="/01_aigc_object/03_closed-en/03-en%E8%AF%AD%E9%9F%B3/" title="语音" class="dd-item"><a href="/01_aigc_object/03_closed-en/03-en%E8%AF%AD%E9%9F%B3/">语音</a></li>
          <li data-nav-id="/01_aigc_object/03_closed-en/04-en%E5%9B%BE%E5%83%8F/" title="图像" class="dd-item"><a href="/01_aigc_object/03_closed-en/04-en%E5%9B%BE%E5%83%8F/">图像</a></li>
          <li data-nav-id="/01_aigc_object/03_closed-en/05-enllm/" title="LLM" class="dd-item"><a href="/01_aigc_object/03_closed-en/05-enllm/">LLM</a></li>
          <li data-nav-id="/01_aigc_object/03_closed-en/06-en3d/" title="3D" class="dd-item"><a href="/01_aigc_object/03_closed-en/06-en3d/">3D</a></li>
          <li data-nav-id="/01_aigc_object/03_closed-en/07-en%E5%8A%9E%E5%85%AC/" title="办公智能体" class="dd-item"><a href="/01_aigc_object/03_closed-en/07-en%E5%8A%9E%E5%85%AC/">办公智能体</a></li>
          <li data-nav-id="/01_aigc_object/03_closed-en/08-en%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/" title="编程开发" class="dd-item"><a href="/01_aigc_object/03_closed-en/08-en%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/">编程开发</a></li></ul></li>
          <li data-nav-id="/01_aigc_object/04_models_sources/" title="模型资源平台" class="dd-item"><a href="/01_aigc_object/04_models_sources/">模型资源平台</a></li>
          <li data-nav-id="/01_aigc_object/05_waiting/" title="预告项目" class="dd-item"><a href="/01_aigc_object/05_waiting/">预告项目</a></li>
          <li data-nav-id="/01_aigc_object/06_sources/" title="项目合集,学习资源" class="dd-item"><a href="/01_aigc_object/06_sources/">项目合集,学习资源</a></li>
          <li data-nav-id="/01_aigc_object/07_others/" title="其他" class="dd-item"><a href="/01_aigc_object/07_others/">其他</a></li>
          <li data-nav-id="/01_aigc_object/08_robots/" title="机器人" class="dd-item"><a href="/01_aigc_object/08_robots/">机器人</a></li></ul></li>
          <li data-nav-id="/02_comfyui/" title="ComfyUI 资源, 教程" class="dd-item"><input type="checkbox" id="section-297479c0a50f82c26178a9b2105b0d3b" class="toggle"/><label for="section-297479c0a50f82c26178a9b2105b0d3b" ></label><a href="/02_comfyui/">ComfyUI 资源, 教程</a><ul>
          <li data-nav-id="/02_comfyui/01_interface/" title="界面介绍" class="dd-item"><a href="/02_comfyui/01_interface/">界面介绍</a></li>
          <li data-nav-id="/02_comfyui/02_basic/" title="基本概念" class="dd-item"><a href="/02_comfyui/02_basic/">基本概念</a></li>
          <li data-nav-id="/02_comfyui/03_built-in/" title="内置节点" class="dd-item"><input type="checkbox" id="section-fa2ab4935a19466c63d0ea96799ffe85" class="toggle"/><label for="section-fa2ab4935a19466c63d0ea96799ffe85" ></label><a href="/02_comfyui/03_built-in/">内置节点</a><ul>
          <li data-nav-id="/02_comfyui/03_built-in/01-built-in/" title="内置节点 1" class="dd-item"><a href="/02_comfyui/03_built-in/01-built-in/">内置节点 1</a></li>
          <li data-nav-id="/02_comfyui/03_built-in/02-built-in/" title="内置节点 2" class="dd-item"><a href="/02_comfyui/03_built-in/02-built-in/">内置节点 2</a></li>
          <li data-nav-id="/02_comfyui/03_built-in/03-built-in/" title="内置节点 3" class="dd-item"><a href="/02_comfyui/03_built-in/03-built-in/">内置节点 3</a></li></ul></li></ul></li>
          <li data-nav-id="/03_prompt-engineering/" title="提示工程归档" class="dd-item"><input type="checkbox" id="section-12d625156815aa71c293f67ec2af8bea" class="toggle"/><label for="section-12d625156815aa71c293f67ec2af8bea" ></label><a href="/03_prompt-engineering/">提示工程归档</a><ul>
          <li data-nav-id="/03_prompt-engineering/01-prompt-engineering/" title="1. 开胃点心, 从几个案例开始" class="dd-item"><a href="/03_prompt-engineering/01-prompt-engineering/">1. 开胃点心, 从几个案例开始</a></li>
          <li data-nav-id="/03_prompt-engineering/02-prompt-engineering/" title="2. 提示工程日常使用技巧" class="dd-item"><input type="checkbox" id="section-eaaf74ee612e764c8d36f61de7dbd89f" class="toggle"/><label for="section-eaaf74ee612e764c8d36f61de7dbd89f" ></label><a href="/03_prompt-engineering/02-prompt-engineering/">2. 提示工程日常使用技巧</a><ul>
          <li data-nav-id="/03_prompt-engineering/02-prompt-engineering/daily-skills01/" title="2.1. 热身, 熟悉基本概念和编写要点" class="dd-item"><a href="/03_prompt-engineering/02-prompt-engineering/daily-skills01/">2.1. 热身, 熟悉基本概念和编写要点</a></li>
          <li data-nav-id="/03_prompt-engineering/02-prompt-engineering/daily-skills02/" title="2.2. 零样本和少样本提示" class="dd-item"><a href="/03_prompt-engineering/02-prompt-engineering/daily-skills02/">2.2. 零样本和少样本提示</a></li>
          <li data-nav-id="/03_prompt-engineering/02-prompt-engineering/daily-skills03/" title="2.3. 思维链与左右互搏" class="dd-item"><a href="/03_prompt-engineering/02-prompt-engineering/daily-skills03/">2.3. 思维链与左右互搏</a></li>
          <li data-nav-id="/03_prompt-engineering/02-prompt-engineering/daily-skills04/" title="2.4. 角色扮演提示" class="dd-item"><a href="/03_prompt-engineering/02-prompt-engineering/daily-skills04/">2.4. 角色扮演提示</a></li>
          <li data-nav-id="/03_prompt-engineering/02-prompt-engineering/daily-skills05/" title="2.5. 将提示拆分为提示链" class="dd-item"><a href="/03_prompt-engineering/02-prompt-engineering/daily-skills05/">2.5. 将提示拆分为提示链</a></li>
          <li data-nav-id="/03_prompt-engineering/02-prompt-engineering/daily-skills06/" title="2.6. 故事提示" class="dd-item"><a href="/03_prompt-engineering/02-prompt-engineering/daily-skills06/">2.6. 故事提示</a></li></ul></li>
          <li data-nav-id="/03_prompt-engineering/03-prompt-engineering/" title="3. 提示工程日常使用案例大全" class="dd-item"><a href="/03_prompt-engineering/03-prompt-engineering/">3. 提示工程日常使用案例大全</a></li>
          <li data-nav-id="/03_prompt-engineering/04-prompt-engineering/" title="4. 高级提示工程概述" class="dd-item"><a href="/03_prompt-engineering/04-prompt-engineering/">4. 高级提示工程概述</a></li>
          <li data-nav-id="/03_prompt-engineering/05_prompts/" title="提示工程资源, 案例集" class="dd-item"><a href="/03_prompt-engineering/05_prompts/">提示工程资源, 案例集</a></li></ul></li>
        </ul>
        <div id="shortcuts">
          <div class="nav-title"></div>
          <ul>
            <li><a class="padding" href="/about">关注我</a></li>
          </ul>
        </div>
        <div class="footermargin footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter"></div>
        <hr class="default-animation footerLangSwitch footerVariantSwitch footerVisitedLinks footerFooter showFooter"/>
        <div id="prefooter" class="footerLangSwitch footerVariantSwitch footerVisitedLinks">
          <ul>
            <li id="select-language-container" class="footerLangSwitch">
              <a class="padding select-container">
                <i class="fas fa-language fa-fw"></i>
                <span>&nbsp;</span>
                <div class="select-style">
                  <select id="select-language" onchange="location = baseUri + this.value;">
                    <option id="zh-cn" value="/04_mwgc/ai-%E7%9A%84%E8%BE%B9%E7%95%8C%E5%9C%A8%E5%93%AA%E9%87%8C%E6%88%91%E4%BB%AC%E5%8F%AF%E8%83%BD%E8%BF%9E%E8%BE%B9%E7%95%8C%E7%9A%84%E5%BD%B1%E5%AD%90%E9%83%BD%E8%BF%98%E6%B2%A1%E7%9C%8B%E5%88%B0/" selected></option>
                  </select>
                </div>
                <div class="select-clear"></div>
              </a>
            </li>
            <li id="select-variant-container" class="footerVariantSwitch">
              <a class="padding select-container">
                <i class="fas fa-paint-brush fa-fw"></i>
                <span>&nbsp;</span>
                <div class="select-style">
                  <select id="select-variant" onchange="window.variants && variants.changeVariant( this.value );">
                    <option id="black" value="black" selected>Black</option>
                  </select>
                </div>
                <div class="select-clear"></div>
              </a>
              <script>window.variants && variants.markSelectedVariant();</script>
            </li>
            <li class="footerVisitedLinks"><a class="padding" onclick="clearHistory();"><i class="fas fa-history fa-fw"></i> 清理历史记录</a></li>
          </ul>
        </div>
        <div id="footer" class="footerFooter showFooter">       <p><a href="https://aiart.website/">🏠明文视界</a></p>
      <p><a href="https://jupyter.fun/"> 🏠明文氛围编程</a></p>
      <p><a href="https://wuhao.online/"> 🏠明文作品集</a></p>
      <p>©2025 <img src="/MW.png" ></a> 明文</a></p>
        </div>
      </div>
    </aside>
    <script src="/js/clipboard.min.js?1759564411" defer></script>
    <script src="/js/perfect-scrollbar.min.js?1759564411" defer></script>
    <script src="/js/featherlight.min.js?1759564411" defer></script>
    <script>
      function useMathJax( config ){
        if( !Object.assign ){
          
          return;
        }
        window.MathJax = Object.assign( window.MathJax || {}, {
          loader: {
            load: ['[tex]/mhchem']
          },
          startup: {
            elements: [
              '.math'
            ]
          },
          tex: {
            inlineMath: [
              ['$', '$'], 
              ['\\(', '\\)']
            ]
          },
          options: {
            enableMenu: false 
          }
        }, config );
      }
      useMathJax( JSON.parse("{}") );
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="/js/jquery.svg.pan.zoom.js?1759564411" defer></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js" defer></script>
    <script>
      window.themeUseMermaid = JSON.parse("{ \"theme\": \"default\" }");
    </script>
    <script src="https://unpkg.com/rapidoc/dist/rapidoc-min.js" defer></script>
    <script>
      window.themeUseSwagger = JSON.parse("{ \"theme\": \"light\" }");
    </script>
    <script src="/js/theme.js?1759564411" defer></script>
  </body>
</html>
